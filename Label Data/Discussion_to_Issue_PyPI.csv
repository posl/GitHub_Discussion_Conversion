URL,Created,Comment_removeclass,Comment_time,Post_Index,Check_Point,Category
https://github.com/3b1b/manim/discussions/1474,2021/4/15 3:47 PM,"Looks like you are using the community version.
So please ask this question on discord or open an issue in ManimCommunity/manim",2021/6/12 1:13 PM,1,1,(II) External Repository
https://github.com/3b1b/manim/discussions/1519,2021/5/20 8:28 AM,"I think you are using the community version of manim.
So you're supposed to ask this question on discord of ManimCommunity or open an issue in ManimCommunity/manim",2021/6/12 12:28 PM,1,1,(II) External Repository
https://github.com/3b1b/manim/discussions/1548,2021/6/16 5:18 PM,"I think you are using the community version. So please ask this question on there discord channel or open an issue in ManimCommunity/manim, instead of here.",2021/6/16 11:16 PM,1,1,(II) External Repository
https://github.com/3b1b/manim/discussions/1708,2022/1/14 9:41 PM,"you are using CE version, so you are supposed to ask this question on their discord channel or open an issue in their repo instead of here.",2022/1/15 7:07 AM,1,1,(II) External Repository
https://github.com/aio-libs/aiohttp/discussions/5786,2021/6/8 2:35 PM,Show us the code.,2021/6/8 3:19 PM,1,,(IV) Reporting a Clarification Request
https://github.com/aio-libs/aiohttp/discussions/5786,2021/6/8 2:35 PM,"
May I know what parameters I have to use to turn on or off the SSL verification.

Well, the documentation you referred to describes the valid arguments as:

SSL validation mode. None for default SSL check (ssl.create_default_context() is used), False for skip SSL certificate validation, aiohttp.Fingerprint for fingerprint validation, ssl.SSLContext for custom SSL certificate validation.
https://docs.aiohttp.org/en/stable/client_reference.html#client-session

If you're getting a TypeError while passing in one of these, then feel free to file a bug report, and include the code you are trying.",2021/6/8 5:43 PM,2,1,(IV) Reporting a Clarification Request
https://github.com/allenai/allennlp/discussions/5567,2022/2/14 1:46 PM,We are discussing this at #5565.,2022/2/26 12:51 AM,1,1,(III) Reporting an Enhancement
https://github.com/ansible-community/molecule/discussions/3111,2021/5/13 9:34 AM,Move to issues board.,2021/5/13 9:43 AM,1,1,(IV) Reporting a Clarification Request
https://github.com/apache/airflow/discussions/13849,2021/1/22 5:28 PM,I've opened an issue for you on the Infra project on Jira - https://issues.apache.org/jira/browse/INFRA-21388,2021/2/5 12:27 PM,1,1,(II) External Repository
https://github.com/apache/airflow/discussions/13849,2021/1/22 5:28 PM,We can not delete the account as it has reported and been assigned a ticket. But I can disable it,2021/2/5 1:05 PM,2,,(II) External Repository
https://github.com/apache/airflow/discussions/14041,2021/2/2 10:08 PM,"Right now that isn't possible, at least not with some heavy hacking.
Could you open a feature request issue for this?",2021/2/5 12:15 PM,1,1,(III) Reporting an Enhancement
https://github.com/apache/airflow/discussions/14315,2021/2/19 8:24 AM,Its also happening in Airflow 2.0.1. What I observed is that it happens when there is a long-running airflow step.,2021/3/9 7:21 AM,1,,(IV) Reporting a Clarification Request
https://github.com/apache/airflow/discussions/14315,2021/2/19 8:24 AM,"Please open a bug report. It would be best if you could provide a DAG which can replicate the issue. From what you told it should be simple sleep task.
There are some other issues related to state updated when using k8s operators:
#10325
#11190",2021/3/9 9:12 PM,2,1,(IV) Reporting a Clarification Request
https://github.com/apache/airflow/discussions/16300,2021/6/7 1:12 PM,Maybe you can open an issue for that describing version etc. ?  Did you try 2.1.0 ? There were some similar issues fixed there.,2021/6/13 4:37 PM,1,1,(IV) Reporting a Clarification Request
https://github.com/apache/airflow/discussions/16300,2021/6/7 1:12 PM,"I'm having the same problem, airflow version 2.2.4
Do you find any solution/workaround ?",2022/12/6 3:17 PM,2,,(IV) Reporting a Clarification Request
https://github.com/apache/airflow/discussions/18270,2020/6/15 2:05 PM,@nullhack @retornam @CodingJonas @CaptainCuddleCube @nalepae @akki Can you look at it? It may be interesting for you.,2020/6/15 5:24 PM,1,,(IV) Reporting a Clarification Request
https://github.com/apache/airflow/discussions/18270,2020/6/15 2:05 PM,"Sure, I'll put on my list, after reviewing the other PR",2020/6/21 2:23 PM,2,,(IV) Reporting a Clarification Request
https://github.com/apache/airflow/discussions/18270,2020/6/15 2:05 PM,"I currently using the workaround with a subprocess without issues. Not saying it is perfect, but I can make a pull request out of if, since it seems to me like a sufficient solution.",2020/6/22 8:27 AM,3,,(IV) Reporting a Clarification Request
https://github.com/apache/airflow/discussions/18270,2020/6/15 2:05 PM,"@CodingJonas Just curious if you asked upstream why docker-py behaves that way?
It might be worth asking them to know if they can fix the root cause itself.",2020/7/23 7:39 AM,4,,(IV) Reporting a Clarification Request
https://github.com/apache/airflow/discussions/18270,2020/6/15 2:05 PM,"That's a good point, I see that I open an issue on their side today and come around to polish my changes for a at least WIP merge request to see if my current solution is feasible :)",2020/7/23 8:01 AM,5,,(IV) Reporting a Clarification Request
https://github.com/apache/airflow/discussions/18270,2020/6/15 2:05 PM,"@CodingJonas you are hitting a known bug in docker-py where is is_tty is set and there isn't any streaming output for about 60 seconds, the connection is closed  see docker/docker-py#931 (comment), there is a fix for it  in docker/docker-py#1959",2020/7/23 10:48 PM,6,,(IV) Reporting a Clarification Request
https://github.com/apache/airflow/discussions/18270,2020/6/15 2:05 PM,I'm not quite sure if this is an Airflow issue?,2021/5/6 1:07 PM,7,,(IV) Reporting a Clarification Request
https://github.com/apache/airflow/discussions/18270,2020/6/15 2:05 PM,"The issue docker/docker-py#931  is still not yet fixed and the DockerSwarmOperator still have the 60s delay before finishing a completed service.
Any updated workaround you are using to prevent this delay ?",2021/8/10 9:54 AM,8,,(IV) Reporting a Clarification Request
https://github.com/apache/airflow/discussions/18270,2020/6/15 2:05 PM,"Sorry for not following up on my workaround, we moved to Kubernetes, so we did not finish polishing the workaround properly. I can still add the main code parts we used to try to fix it. Perhaps it helps you!

The only addition we did is wrapping the _stream_logs_to_output method in a Thread.",2021/9/6 2:36 PM,9,,(IV) Reporting a Clarification Request
https://github.com/apache/airflow/discussions/18270,2020/6/15 2:05 PM,"FYI, docker/docker-py#931 has got fixed.
So we should not see this issue once we upgrade our docker-py dependency to their next release.
Also, we can remove this exception handling as per the comment.",2021/9/17 1:03 PM,10,,(IV) Reporting a Clarification Request
https://github.com/apache/airflow/discussions/18270,2020/6/15 2:05 PM,"docker-py version 5.0.3 was released with a the fix of docker/docker-py#931
https://github.com/docker/docker-py/releases/tag/5.0.3
@akki @potiuk @CodingJonas",2021/10/8 11:55 AM,11,,(IV) Reporting a Clarification Request
https://github.com/apache/airflow/discussions/18270,2020/6/15 2:05 PM,"I opened #18867 as followup
FYI @akki @HaloKo4 @CodingJonas if any one of you is interested in working on it.",2021/10/10 7:36 AM,12,1,(IV) Reporting a Clarification Request
https://github.com/apache/airflow/discussions/18290,2021/9/16 9:31 AM,Thanks for opening your first issue here! Be sure to follow the issue template!,2021/9/16 9:31 AM,1,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/18290,2021/9/16 9:31 AM,"Not sure what changed this behaviour, but do you consider this a bug? I'd argue if you have LDAP enabled, you would want all your users to live in your LDAP directory and not be able to create any local users.",2021/9/16 9:42 AM,2,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/18290,2021/9/16 9:31 AM,"Yeah. @pawsok  - were you atually ABLE to add new users in case of LDAP authentication before (and they Landed in LDAP)? Unless  you have custom authentication module, I believe there is no code for that functionality in Airflow so I'd also be quite surprised. Maybe that was a bug and when you added the users they landed in Airflow DB instead?
Can you please explain what was the behaviour you observed before and where the users landed (converting that into discussion)",2021/9/16 10:17 AM,3,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/18290,2021/9/16 9:31 AM,"@potiuk Yes, I'm still able to add LDAP users from Airflow 2.0.1. Here is an exemplary add user view:

I have added many users in this way and they can log in Airflow, as:
username: domain/user_domain_name
password: domain_password
In Airflow webserver config file there are three variables set as the below:

EDIT:
Maybe it's something related to a newer version of Flask AppBuilder? In Airflow 2.0.1 we have Flask-AppBuilder==3.1.1, now it's Flask-AppBuilder==3.3.2.",2021/9/16 10:35 AM,4,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/18290,2021/9/16 9:31 AM,@pawsok Those users aren't stored in your LDAP directory are they (only in the Airflow DB)?,2021/9/16 10:50 AM,5,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/18290,2021/9/16 9:31 AM,That's also my thinking - that they are just in the DB and you won't find them in your LDAP - can you please double-check that?,2021/9/16 10:52 AM,6,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/18290,2021/9/16 9:31 AM,"Users exist in Airlow DB and also in LDAP directory, otherwise I think that users are not able to log in to Airflow.",2021/9/16 11:12 AM,7,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/18290,2021/9/16 9:31 AM,"But did you actually check if they are in LDAP directory after you add them in Airflow manually (and whethere they were not there before)? Just add a new user in airflow and see if it appears in LDAP.
As @BasPH mentioned - the LDAP syncrhronisation works in the way that LDAP users are synchronized from LDAP to Airflow DB (and this should be refreshed either periodically or at login). I highly doubt there is a way Airflow could create an LDAP user - it must have been in LDAP already  when you added it. And in this case you should not ""add"" the users manually but you should run synchronisation to bring the LDAP users to Airflow.
Eventually those users will end-up in Airflow DB but what @BasPH and myself are trying to say is that you should not need to add them manually - they should be automatically synchronized by Airflow.",2021/9/16 11:20 AM,8,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/18290,2021/9/16 9:31 AM,"I do not have access to check LDAP directory, but so far it has worked this way - if the user added doest not exist in LDAP it was just impossible to log in to Airflow. So I don't expect that when adding a user in Airflow, user will also be added to LDAP automatically. That was the way it worked flawlessly.
What I did add additionally (I will remind you that I have version 2.0.1 now):

install 2.0.2 (button ""add"" is still visible)
install 2.1.0, as the next version after ""working"" one (button ""add"" is not visible)
create a fresh installation on my local laptop 2.1.3 (button ""add"" is not visible)
compare LDAP permissions between 2.0.1 and 2.1.0:

2.0.1:
can_add UserLDAPModelView
can_delete UserLDAPModelView
can_download UserLDAPModelView
can_edit UserLDAPModelView
can_list UserLDAPModelView
can_show UserLDAPModelView
can_userinfo UserLDAPModelView
userinfoedit UserLDAPModelView
2.1.0:
can_add UserLDAPModelView
can_delete CustomUserLDAPModelView
can_delete UserLDAPModelView
can_download UserLDAPModelView
can_edit CustomUserLDAPModelView
can_edit UserLDAPModelView
can_list UserLDAPModelView
can_read CustomUserLDAPModelView
can_show UserLDAPModelView
can_userinfo UserLDAPModelView
userinfoedit UserLDAPModelView
As we can see here (and also in the source code) something has changed about LDAP settings.",2021/9/20 6:58 AM,9,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/18290,2021/9/16 9:31 AM,"Did some simple testing but haven't found the cause. Granted all possible permissions to the Admin role:

But no button when logged in with Admin role.
Between Airflow 2.0.1 and 2.1.3 the Flask-AppBuilder version changed from 3.1.1 to 3.3.2. There were some extensive changes to the LDAP authentication mechanism (PR), but I wasn't able to quickly pinpoint any potential changes with regards to falling back to local users.

Regardless, I'd argue that this is the intended way it should work. If there is only one authentication mechanism (LDAP), then there shouldn't be a second place for users to live in. From a security perspective, having two places for user accounts to live in, increases the attack surface.
You could ask your LDAP admin if it's possible for yourself/your team to create new accounts in your LDAP directory. Assuming you were using the local users for debugging purposes only, you might also want to look at account or password expiration options in your LDAP.",2021/9/20 8:37 AM,10,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/18290,2021/9/16 9:31 AM,"Hi, it turned out that this is a problem related to missing permissions in Airflow. Class CustomUserLDAPModelView inherits from MultiResourceUserMixin and I noticed there isn't can_create action, so what I did:

Edit /www/views.py and class MultiResourceUserMixin

from:

to:


Run airflow sync-perm
Button (to add user) is visible now in Users View.
My colleague is able to log in to Airflow once I added him (he is of course in LDAP directory)

Everything was done on Airflow 2.1.3 version.
",2021/9/24 8:15 AM,11,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/18290,2021/9/16 9:31 AM,But will it work with sync without adding the user ?,2021/9/25 7:25 PM,12,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/18290,2021/9/16 9:31 AM,"@potiuk No, This works only if I add a new user directly from Airflow who is already in LDAP. Users existing in LDAP do not appear automatically in Airflow.  This approach is right for me because it gives me an extra layer of authentication that I can manage myself.
So I only specify one parameter, the path to LDAP server: AUTH_LDAP_SERVER = ""ldap://xxxx.xxxx.xxxxx"" in webserver_config.py.",2021/9/27 5:44 AM,13,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/18290,2021/9/16 9:31 AM,I see - I created the issue back then #18545  and I understand where it came from - you simply do not want automated user registration with LDAP. That's fine and there are others with similar workflow.,2021/9/27 8:57 AM,14,1,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/18290,2021/9/16 9:31 AM,Is there a similar fix for OAUTH? The register user button is not visible.,2022/4/6 2:52 PM,15,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/19006,2021/10/15 5:05 AM,Thanks for opening your first issue here! Be sure to follow the issue template!,2021/10/15 5:05 AM,1,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/19006,2021/10/15 5:05 AM,"Why and how do you run mypy?  Which version? What are the exclusions you make ? How does it relate to mypy configuration that is part of Airflow itsefl?
Just to explain: Our Mypy is working perfectly fine for airflow - It's part of the static checks for every commit. There is no ""guarantee"" that all versions of mypy will be running always with all configuration and without exclusions - as usual with any static checkers.
I would love to know what you do and what your configuration you use, because I am genuinly interested, but it is hardly an issue with Airflow - this is a discussion really - that's why I converted it.",2021/10/15 8:02 AM,2,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/19006,2021/10/15 5:05 AM,"We are using 0.770 
 and since we are using namespace packages we had to do some workarounds https://github.com/apache/airflow/blob/main/scripts/in_container/run_mypy.sh
Also you have to remember that you have to have alll dependende packages installed to make sure that mypy runs in a repeatable fashion. Airflow has > 500 dependent packages and you need to have them installed all via ci_all extra wtth the same versions that are ""golden"" set of dependencies (pip install apache-airflow[ci_all] --constraint ... - see https://airflow.apache.org/docs/apache-airflow/stable/installation/installing-from-pypi.html ). Only then you might get repeatable mypy experience.",2021/10/15 11:52 AM,3,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/19006,2021/10/15 5:05 AM,"@potiuk Please, can you reopen issue since this type comment is incorrect?
spec.setdefault('consumes', ['application/json'])  # type: List[str]
Should be:
consumes = spec.setdefault('consumes', ['application/json'])  # type: List[str]
or completely remove type comment:
spec.setdefault('consumes', ['application/json'])",2021/10/18 4:03 PM,4,1,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/19006,2021/10/15 5:05 AM,"@brain-buster you beat me to it __
#19065",2021/10/23 1:23 AM,5,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/19006,2021/10/15 5:05 AM,Yeah. I see the problem was with running 'mypy` when checking your own 'DAGs' wth mypy. Merged I hope we can cherry-pick it to 2.2.1.,2021/10/23 9:36 AM,6,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/19366,2021/11/2 12:52 PM,Thanks for opening your first issue here! Be sure to follow the issue template!,2021/11/2 12:52 PM,1,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/19366,2021/11/2 12:52 PM,"You should provide more reproducible examples (dags that you use), logs detailed information about your deployment. - otherwise it is impossible to act on this. I will convert it to discussion now until this information is provided - then we can try to asses if the eror is real or maybe there is somethign wrong with your deployment.",2021/11/2 1:15 PM,2,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/19366,2021/11/2 12:52 PM,Created an issue back #19477,2021/11/8 6:32 PM,3,1,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/19371,2021/11/2 2:43 PM,It's been fixed in 2.2.0 https://github.com/apache/airflow/pull/18516/files,2021/11/8 12:05 AM,1,1,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/19745,2021/11/22 12:53 PM,I think you should open an issue for that one.,2021/12/4 3:46 PM,1,1,(IV) Reporting a Clarification Request
https://github.com/apache/airflow/discussions/21047,2022/1/19 9:12 AM,Thanks for opening your first issue here! Be sure to follow the issue template!,2022/1/19 9:12 AM,1,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/21047,2022/1/19 9:12 AM,"I do not think there is a clear reproduction path, and this is not a problem that we woudl be aware of. Maybe someone will be able to help with that - but maybe try to provide more information and try to see if there are no more logs/errors in your kubernetes logs? Check for any ""resources"" (memory) related problems and similar. I heartily recommend using k9s tool for that - it is really helpful to anylyse logs and see problems with your pods/configuration/resources..
If this is something fully reproducible, please specify how exactly you run your backfill - including the commands you issue and what the backfill command will print you. Ideally in the way that will be possible by anyone to reproduce it.",2022/1/23 5:26 PM,2,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/21047,2022/1/19 9:12 AM,Converting it into discussion until more information is available,2022/1/23 5:26 PM,3,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/21047,2022/1/19 9:12 AM,"Thank you for your kind reply.
The more information attached as below.
Start backfilling job with command airflow dags backfill echo -s 20220110 -e 20220110 and the logs:

scheduler logs:

scheduler pod config

backfill task pod config

Please let me know if anything is unclear.
Thank you again for you help.",2022/1/24 3:27 AM,4,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/21047,2022/1/19 9:12 AM,"Really helpful. I think this is duplicate of #20982
",2022/1/24 1:26 PM,5,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/21047,2022/1/19 9:12 AM,"I have met the same issue with Airflow 2.2.4. I was running the airflow backfill cmd airflow dags backfill test_dag_2 -s 2022-02-25 -e 2022-03-01 -v from the schduler pod in our k8s cluster. And it finished the first dagrun2022-02-25 and stuck in the second dagrun whose task pods actually haven been completed in the k8s cluster but still showing 'scheduled' in the airflow GUI and the backfill was stuck from this point.

The logs:

I tried to run the backfill command using subprocesshook in a dag and it has no this issue but after a few successful backfill dagruns, some tasks got stuck forever to 'scheduled' state and not run anymore. I created an issue about this in #23145",2022/4/21 12:49 PM,6,1,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/21047,2022/1/19 9:12 AM,this issue seems to be similar to the issues mentioned in the PR: #23720,2022/5/17 9:14 PM,7,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/21068,2022/1/24 4:31 PM,"This was a bug-fix - you are not supposed to run triggerer on Python 3.6 - it would not work anyway (because of lack of async-io support for Python 3.6).
This is a new feature in Airflow 2.2: https://airflow.apache.org/docs/apache-airflow/stable/concepts/deferring.html
I would recommend you to migrate to Python 3.7 at least becaue Python 3.6 reached end of life in December and Airflow 2.3.0 will not support Python 3.6. so you will have to move to higher python version anyway: https://github.com/apache/airflow/blob/main/README.md#requirements
And yeah. You are right. The graph needs updating.",2022/1/24 4:46 PM,1,,(III) Reporting an Enhancement
https://github.com/apache/airflow/discussions/21068,2022/1/24 4:31 PM,I opened issue to update the overview #21071,2022/1/24 4:48 PM,2,1,(III) Reporting an Enhancement
https://github.com/apache/airflow/discussions/21068,2022/1/24 4:31 PM,"Thanks so much for your quick response, I am a little confused by what you mean by migrate to python 3.7, I havent altered any of the default settings for the helm chart so I would expect this is pulling the most recent version of the airflow image, which would use python 3.7 or later no? Is there a version I should be pinning in my values file?",2022/1/24 5:10 PM,3,,(III) Reporting an Enhancement
https://github.com/apache/airflow/discussions/21613,2022/2/16 11:55 AM,I think it's missing - it's likely a bug when execution_date was replaced with dag_ru_id. Can you please open an issue for (or maybe even better make a PR for it?). I think in this case using execution_date might be the closest you can to use to do any kind of filtering (not perfect  but should work in most cases).,2022/2/21 4:54 PM,1,1,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/21846,2022/1/20 5:21 PM,Thanks for opening your first issue here! Be sure to follow the issue template!,2022/1/20 5:21 PM,1,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/21846,2022/1/20 5:21 PM,Could you provide a simple DAG to reproduce this behaviour? I have tried setting tags=None but I couldn't get the error,2022/2/24 4:58 PM,2,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/21846,2022/1/20 5:21 PM,Converting it to a discussion until more info is provided allowing to reproduce it.,2022/2/27 12:56 AM,3,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/21846,2022/1/20 5:21 PM,"This happened to our 2.2.2 deployment. We've had some DAGs with tags=[...] and when we completely removed that line, those DAGs caused this error at the scheduler.
The issue is that for some reason this did not result in import error that was visible anywhere, we had to be alerted by a partner that data was no longer being processed.
Another quick fix is to manually remove those entries from dag_tag in the matadb.",2022/3/15 2:04 PM,4,,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/21846,2022/1/20 5:21 PM,Created an issue #22289 - thanks for providing reproducible steps.,2022/3/15 2:47 PM,5,1,(I) Reporting a Bug
https://github.com/apache/airflow/discussions/22992,2022/4/13 3:39 PM,This looks lie deployment issue - I think you should open support request to Astronomer.,2022/4/13 4:35 PM,1,1,(II) External Repository
https://github.com/apache/airflow/discussions/22992,2022/4/13 3:39 PM,"I am seeing the same problem on my test instance with 2.3.0, Standard Upgrade vom 2.2.4, no errors on the DB migration.
As far as i could reverse engineer it, it seems that there is only one entry in the log_template table and this one contains the new filename format
dag_id={{ ti.dag_id }}/run_id={{ ti.run_id }}/task_id={{ ti.task_id }}/{% if ti.map_index >= 0 %}map_index={{ ti.map_index }}/{% endif %}attempt={{ try_number }}.log
Based on this line of code https://github.com/apache/airflow/blob/main/airflow/models/dagrun.py#L1070 i would have expected, that the original filename template {{ ti.dag_id }}/{{ ti.task_id }}/{{ ts }}/{{ try_number }}.log should also be present, but with a lower id. I tried to add it to the table, but this did not solve the problem at hand. Will try to debug this a little bit more.",2022/5/2 4:29 PM,2,,(II) External Repository
https://github.com/apache/airflow/discussions/22992,2022/4/13 3:39 PM,"I also ran into this after upgrading airflow using the default config before and after the upgrade (like @wbg). Managed to migrate to the new logs folder structure using this quick and dirty script:
https://gist.github.com/pspeter/13c18ee6cf247a5ee2b3e3b2ee8a5470
Backup your logs before running this on the system (e.g. using kubectl exec -it <webserver> python)",2022/5/16 12:00 PM,3,,(II) External Repository
https://github.com/apache/airflow/discussions/22992,2022/4/13 3:39 PM,It looks like backward compatibility bug.,2022/5/17 10:37 PM,4,,(II) External Repository
https://github.com/apache/airflow/discussions/24008,2020/11/10 9:37 AM,Thanks for opening your first issue here! Be sure to follow the issue template!,2020/11/10 9:37 AM,1,,(II) External Repository
https://github.com/apache/airflow/discussions/24008,2020/11/10 9:37 AM,"I have same issue with remote logging:
Apache Airflow version: 2.0.0
Environment:

Cloud provider or hardware configuration: AWS S3
OS (e.g. from /etc/os-release): Ubuntu 20.10 (Groovy Gorilla) [1PC] and Ubuntu 18.04.4 LTS (Bionic Beaver) [2PC]
Kernel (e.g. uname -a): 5.8.0-36-generic (Ubuntu 20.10) [1PC] and 5.3.0-62-generic (Ubuntu 18.04) [2PC]
Install tools: airflow-quick-start and airflow-config and airflow-Example Pipeline definition
Others: Setup logging to s3, by env vars and airflow.cfg
env:

airflow.cfg


Python: 3.7.9 [1PC] and 3.6.9 [2PC]

What happened:
With Example Pipeline definition remote logging work fine, but after add import mlflow to dag code, airflow doesn't send logs to s3 storage.
What you expected to happen:
Remote logging works fine with import mlflow
How to reproduce it:

Install airflow airflow-quick-start;
Install mlflow mlflow-quick-start;
Setup config with abowe env vars or airflow.cfg;
Add s3 connection to airflow;
Paste dag code airflow-Example Pipeline definition to dag dir;
Add import mlflow to dag code;
Run dag;

Anything else we need to know: Tested on 2 PC with different os and hardware",2021/1/11 11:00 AM,2,,(II) External Repository
https://github.com/apache/airflow/discussions/24008,2020/11/10 9:37 AM,"This sounds like mlflow is doing something to the python loggers on import that it shouldn't be doing, and is a bug in that library.",2021/1/11 11:19 AM,3,,(II) External Repository
https://github.com/apache/airflow/discussions/24008,2020/11/10 9:37 AM,"There also might be another problem:
Do you also use/import snowflake provider as well? We have the ongoing problem with #12881 and that might be the root cause of the problem.
If that's the case, for now you might remove the provider (and snowflake-connector-python). We are working with snowflake team ( they just merged snowflakedb/snowflake-connector-python#591 and snowflakedb/snowflake-connector-python#592) and as soon as they release new version of the connector, this problem should be gone.
If you have it can you remove the snowflake import/library and let us know if it fixes the problem?
But if you do not import snowflake anywhere:
Solution to this 'snowflake' problem will also unblock upgrade to a newer version of requests and urrlib3 libraries which might be another reason why mlflow does not work.
But you should be able to manually upgrade requests library and urllib3 libraries to latest versions (even if they will tell that there is a  'requests/urllib3 conflict'. In the upcoming bugfix 1.10.15 release, this limitation will be gone, regardless if snowflake manages to release a new library or not, but for now you would have to upgrade those manually.
Could try it and let us know ?",2021/1/11 11:20 AM,4,,(II) External Repository
https://github.com/apache/airflow/discussions/24008,2020/11/10 9:37 AM,"i can confirm it doesn't work if you add from mlflow.tracking import MlflowClient to any dag.
mlflow version: 1.19.0
airflow: 1.10.15",2021/7/30 4:48 PM,5,,(II) External Repository
https://github.com/apache/airflow/discussions/24008,2020/11/10 9:37 AM,"Just ran into this issue as our team is starting to use MLFlow:
airflow: 2.1.3 (kubernetes executor)
mlflow: 1.20.0
All of our DAGs are able to send logs up to S3 but any DAGs that import MLFlow silently fail to upload the logs to s3. Tasks in the DAGs behave normally and can even sync other data to s3 just fine but the logging code does not appear to be running.
It feels like the MLFlow code is overriding the task log handler that we use to write the logs to s3. MLFlow init file does load a logging config (init file + logging config)
Could be related? I'll be filing an issue with MLFlow's project.",2021/10/27 10:56 PM,6,1,(II) External Repository
https://github.com/apache/airflow/discussions/24008,2020/11/10 9:37 AM,"I opened an issue with the mlflow project as it is likely an issue with their logging config. I did however find a work around which is to import mlflow inside of a function so that the import doesn't happen until the task's run time.
",2021/10/28 4:28 PM,7,,(II) External Repository
https://github.com/apache/mxnet/discussions/19107,2020/9/9 11:30 PM,"Hi @Arhamna. What's likely happening is that some of the variables/arrays are shared between these two models, while each NDArray only supports one entry for autograd tracing. As a result, the gradient tape in the first backward is overwritten by the second. Sorry that the error message is unclear and it would be really helpful if you could create a bug report for it.
A workaround I'd recommend is adding the losses together and do backward together. Since derivative is a linear function you can get the same result as doing two backward steps separately.",2020/9/10 3:33 PM,1,1,(IV) Reporting a Clarification Request
https://github.com/apache/superset/discussions/18458,2021/3/10 4:16 PM,"I was just about to submit an issue for this exact issue. WKT point, polygon, and linestring should all be supported for any of the deckGL spatial visualizations.",2021/3/11 4:48 AM,1,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/18458,2021/3/10 4:16 PM,tracking related issue #13573 here,2021/3/31 7:44 AM,2,1,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/18544,2022/1/10 12:58 PM,"I think the idea of expanding this concept and providing a way to categorize dashboards is the way to go. #17408 (comment)
I can understand that being able to set a Dashboard as an example might be useful to some, but the level of abstraction that categorization would bring is a big big plus. The only downside is that it might come with some complexity and design considerations.
I believe the best approach to get attention and consensus is to write a SIP #5602. I can help with that @EBoisseauSierra",2022/1/10 4:24 PM,1,,(IV) Reporting a Clarification Request
https://github.com/apache/superset/discussions/18544,2022/1/10 12:58 PM,"For reference, I think categorization might help satisfying the requirement shared in this other issue #18005",2022/1/13 5:19 PM,2,,(IV) Reporting a Clarification Request
https://github.com/apache/superset/discussions/18544,2022/1/10 12:58 PM,@betodealmeida implemented something with customizing examples that may help here.,2022/1/13 8:55 PM,3,,(IV) Reporting a Clarification Request
https://github.com/apache/superset/discussions/18544,2022/1/10 12:58 PM,I am not sure if this the right place to bring this up but a business user one of the biggest issue we have is the option to customize the landing page. Like 90% of the users may only use one dashboard so why not let them configure it to be their landing page?,2022/1/25 8:24 PM,4,,(IV) Reporting a Clarification Request
https://github.com/apache/superset/discussions/18544,2022/1/10 12:58 PM,Hey @Bottlecapps why not creating a new issue with more information about the feature and how you envision that?,2022/1/27 4:15 PM,5,1,(IV) Reporting a Clarification Request
https://github.com/apache/superset/discussions/18553,2022/1/31 3:27 PM,"Hello @bluepython508 I am not sure if I should mark this issue as a bug or enhancement request at the moment. Would you please provide more information concerning the Superset version that you are running and your configuration so that I can try to reproduce the problem? Any additional information, such as videos showing the issue would be immensely helpful!",2022/2/1 2:38 PM,1,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/18553,2022/1/31 3:27 PM,"It's probably an enhancement request.
I'm running Superset 1.4 with some patches applied, though that screenshot was taken in a straight install of superset master. The issue arises when setting PUBLIC_ROLE_LIKE to Gamma, but that is the only config change necessary to reproduce the screenshot. I set PUBLIC_ROLE_LIKE to Gamma, then added some datasource access to Gamma, and tried to make and save a chart.
I'm not really sure what you're asking for video of.",2022/2/1 2:46 PM,2,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/18553,2022/1/31 3:27 PM,"OK that makes it clearer. From reading your issue the first time I had the impression there was an actual bug. I'll mark it as an enhancement request, even though, as you correctly wrote, creating the role manually is the best option right now. Thank you!",2022/2/2 6:37 AM,3,1,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/18553,2022/1/31 3:27 PM,Related #18210,2022/2/2 6:39 AM,4,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,"Did you see SIP-34.
A lot of changes in the UI are happening.  Check there and add your comments",2020/4/16 3:27 AM,1,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,"Thanks @eugeniamz! That proposal is really impressive and I look forward to seeing the results. There's a lot there and I may have missed something but I didn't see any impact on grouping charts/dashboards although it looks like search in general is improved. What I would like (and don't see in that proposal) is a way for me to put charts/dashboards for, say ""Marketing"" or ""Finance"" in one directory, or apply different tags, so that I can limit my search/list display appropriately. Even though Search is improved in that proposal I don't see a way to limit to a cross-cutting subset of my charts/dashboards. Maybe this could be done by artificially creating duplicates of underlying data references, one per discriminating category value, but that would be sub-optimal.",2020/4/16 5:17 PM,2,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,Great feedback!! I will share this with Preset designers team.,2020/5/9 2:24 AM,3,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,"This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions. For admin, please label this issue .pinned to prevent stale bot from closing the issue.",2020/7/11 1:23 AM,4,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,"+1 to the @kevinpostlewaite feature request.
This is smth we would love to see as well",2020/7/14 8:20 PM,5,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,"+1, this is important to our team.",2020/8/13 9:02 PM,6,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,"What @kevinpostlewaite said is really what we need now, folders to organize our dashboards",2020/8/14 8:46 AM,7,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,__search,2020/8/14 4:47 PM,8,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,"We are exploring global search which will be able solve the problem you have -
It's difficult to find specific charts and dashboards that I've created. tag and folder certainly could be alternative solutions. we would love to hear more about the use cases from you. @kevinpostlewaite @isunix @rubypollev @betodealmeida",2020/8/14 4:50 PM,9,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,"Tags more useful at this time than folders, but folders would be great.  Many tags to one chart / query for analytics approved queries, OKR queries, marketing-related / product-related queries, etc. would be soo helpful.",2020/8/14 8:33 PM,10,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,1,2020/8/28 2:35 AM,11,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,"@junlinc Having directories would help __ashboard consumers_ to easily find/explore available dashboards. This way has _ imho _ a few advantages over tags:

Directories can be nested (what has pros and cons compared to multiple same-level-tags).
It's __ush_ rather than __ull_ exploration: users are shown the various directories they can access, rather than having to guess what it the right tag to search for (is it __inance_, __inances_, __inancial_, __evenue_, _?).
At start (blank search), you're not overwhelmed with all the dashboards you have access to; you're shown the top-level directories instead.

That's how Metabase does it and our novice users have found it _ except the fact they confusingly call directories __ollections_ _ quite convenient.",2020/8/29 11:13 AM,12,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,"+1, this is important to our team.",2020/11/25 3:46 AM,13,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,"@EBoisseauSierra thanks for elaborating your business needs for folders/directories, and the pros and cons of different solutions. we were gonna implement global search for Superset 1.0 but the project has been reprioritized. it's good to know how other BI tools are solving content exploration challenge and how their solution is meeting your needs.
we should reconsider different options for content discoverability next year. @Steejay",2020/11/25 4:54 AM,14,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,"__ this our team is also bumping into so many dashboards. The search of course helps a bit, but the problem often is that the search only helps if you know what you're searching for.
Thus, having tags would be really helpful, as they can be used in all kinds of ways and are more flexible than folders, as you can form multiple parallel flexible hierarchies which folders do not enable. Github Issues' labels are a great example: you can have ""categories of labels"" just by using a colon, such as how this project uses them: enhancement:committed or enhancement:request
So in a similar way you could have for example: department:marketing and project:supersecretproject or whatever you like",2021/5/25 1:09 PM,15,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,"Hello Guys,
Any news about this?
It is a great feature",2021/7/1 4:28 AM,16,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,"As the number of charts and dashboards growing day by day in our organization, without this feature, we are struggling a lot.
Either of this search / tags would help us.",2021/8/27 6:58 AM,17,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,"Just commenting to add my support for this feature.
As we have added hundreds of dashboards, navigating and searching for relevant data has become a hassle for our analyst teams. We have had to resort to naming convention strategies, which are difficult to enforce and don't work very well.
A folder or tagging solution supported by  Superset itself seems like it would help a lot, so I'd appreciate any comments regarding the viability of implementing a feature like this. Thanks!",2021/9/21 12:31 PM,18,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,+100 from my side as well. This is such an important feature that would leverage the product immensly.,2022/1/11 5:03 PM,19,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,1,2022/2/2 12:14 AM,20,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,+1 would love to see this feature in a future implementation of superset,2022/2/6 3:00 PM,21,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,1,2022/2/8 8:00 PM,22,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,"my Organization gives priority to chart over dashboard for the user.
because they are simple then dashboard and gives exploration and less overhead for the simple user.
So having tags helps the user to get the chart what needed directly and see the result.",2022/2/11 7:39 AM,23,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,@graceguo-supercat Can you give some reasoning about and impact of moving this from an issue to a discussion?  Thank you!,2022/3/16 5:47 PM,24,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,@graceguo-supercat I'm inclined to move this back to issues unless there's a reason to move this to discussion.,2022/3/24 6:05 PM,25,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,"This has been re-submitted as an issue:
#19398",2022/3/28 6:17 PM,26,1,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,"Any thoughts on tagging approaches used for back-end and mimic the same approach of tagging feature ( which was closed) in front-end.
I am trying to understand these code for tagging for back-end and front-end( which  is closed) can we try to implement in our private repo.",2022/3/30 5:19 AM,27,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,1,2022/6/17 2:36 AM,28,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,"+1
We have several teams. They produce a lot of charts and dashboards all of which contain data about different business areas and so on. Now it's just a mess. Business users can't sort it all out and find dash/chart on their own.",2022/8/19 6:14 AM,29,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,"I have a work-a-round. I created a directory dashboard filtering on a prefix... sort of acts like a folder.
Here's the simplified components:

Organize your dashboard titles like so: <CATEGORY_NAME>: <DASHBOARD_NAME>
Create a dataset on your Superset metadata database with this in the SELECT... it should also have any additional metadata on dashboards you need in your SELECT:



Add a calculated column like so: CONCAT('<a href=""https://<SUPERSET_ROOT>/superset/dashboard/', dashboard_id, '"">', dashboard_title, '</a>') . I've named this Dashboard Title /w URL
Create a table chart listing all dashboards SELECTing the URL column (and any other metadata).
Create a dashboard with this chart and the prefix as a filter

Now you can filter your dashboards on a category, and navigate to them easily.
Not great, but it works.",2022/8/19 6:05 PM,30,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,"+100 from my side. We have dozens of dashboards and it's very inefficient to navigate through them on Superset. We have some workarounds too such as adding a prefix in the dashboard's name.  It's such a basic feature, I don't understand why it's not been implemented yet??",2022/11/30 4:09 PM,31,,(III) Reporting an Enhancement
https://github.com/apache/superset/discussions/19194,2020/4/16 1:22 AM,"Hi, are there any news about this feature?",2023/1/18 8:56 AM,32,,(III) Reporting an Enhancement
https://github.com/assimp/assimp/discussions/3861,2021/5/4 3:16 AM,You can use the git-hub project to add an issue report.,2021/5/16 3:58 PM,1,1,(I) Reporting a Bug
https://github.com/assimp/assimp/discussions/3861,2021/5/4 3:16 AM,Fixed!,2021/5/27 8:26 AM,2,,(I) Reporting a Bug
https://github.com/assimp/assimp/discussions/4004,2021/7/28 12:25 PM,Thanks for the hint. I have generated an issue report out of this.,2021/8/10 6:28 PM,1,1,(IV) Reporting a Clarification Request
https://github.com/assimp/assimp/discussions/4004,2021/7/28 12:25 PM,The problem is fixed on the current master. The handling for empty XML-nodes with irrXML was broken. With pugixml it works.,2021/9/5 10:28 AM,2,,(IV) Reporting a Clarification Request
https://github.com/aws/aws-cdk/discussions/19868,2022/4/11 8:04 PM,"UPDATE: merged a fix for this, you should be able to use json for this property next version release #19885
Original body: Since you asked this again, I decided to try deploying a stack and yeah you're right, you can do this with CloudFormation. I'm curious what the serverless docs are trying to indicate when they reference how certain properties aren't compatible with CloudFormation.
Anyway, the typing the CDK forces doesn't allow you to directly input the GatewayResponses property. You can get around this by using escape hatches to override the generated template. Here's an example which works __

I've created a bug report here so that CDK can address this to natively use these properties without workarounds",2022/4/12 12:30 AM,1,1,(I) Reporting a Bug
https://github.com/aws/sagemaker-python-sdk/discussions/2451,2021/6/15 4:48 PM,"AWS credentials are required so you can download the inference image used in LocalMode. - https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/local/image.py#L150
As for SAGEMAKER_SUBMIT_DIRECTORY, the model shouldn't upload the code to S3 in localmode - https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/model.py#L1114. I will do more digging.",2021/6/15 7:38 PM,1,,(I) Reporting a Bug
https://github.com/aws/sagemaker-python-sdk/discussions/2451,2021/6/15 4:48 PM,"@icywang86rui  I just tried the same code again, but with a much larger mordel, completely local again, but I got the exception shown below which indicates the there was an attempt to upload the model to S3 although that would be completely useless and unnecessary (probably the deepest stack trace I ever got).
I double checked my S3 console and found that there is a bucked I do not remember creating with the name schema
sagemaker-us-west-2-999999999999 which contains a directory pytorch-inference-2021-06-14-14-51-56-049/ for every
local deployment that succeeded.
The other issue of course is, if I would instead not want to deploy the image locally, but instead use an AWS instance by specifying the instance type with the instance_type parameter, why would I then get that error?
Finally, even when running on SageMaker, why would every deploy invocation save the model into a separate new directory, even when the model does not change? A simple approach of fingerprinting the tar.gz file could prevent this.
",2021/6/17 8:59 AM,2,,(I) Reporting a Bug
https://github.com/aws/sagemaker-python-sdk/discussions/2451,2021/6/15 4:48 PM,"I have updated the bug report, the upload clearly happens because the PyTorchModel overrides the prepare_container_def method which is invoked as part of deploy() and that code always uploads the model and does not respect the local settings in the configuration.
#2463",2021/6/20 12:24 PM,3,1,(I) Reporting a Bug
https://github.com/buildbot/buildbot/discussions/5954,2021/3/26 9:53 PM,"Git step no longer derives from LoggingBuildStep and no longer supports lazylogfiles. Is this something you require for the Git step?
As for ShellCommand you've found a bug, could you file a bug report?
Thanks a lot for raising these issues.",2021/3/27 9:01 AM,1,1,(I) Reporting a Bug
https://github.com/buildbot/buildbot/discussions/5954,2021/3/26 9:53 PM,"Thanks, I've opened a bug: #5957",2021/3/29 4:42 PM,2,,(I) Reporting a Bug
https://github.com/celery/celery/discussions/7017,2020/11/4 12:51 PM,"I'm sorry that you feel that way.
We're fully aware of the status of this project and we're working to make it better.
Do you have the issue numbers we need to prioritize?",2020/11/4 12:57 PM,1,,(I) Reporting a Bug
https://github.com/celery/celery/discussions/7017,2020/11/4 12:51 PM,"I did some PR when I found BUGS but seems out of control. Actually from my list, point 1 and 2 are the killing one. Compromises the base usage of Celery.",2020/11/4 1:19 PM,2,,(I) Reporting a Bug
https://github.com/celery/celery/discussions/7017,2020/11/4 12:51 PM,"If you'd like us to fix the problems we need to know which are the most urgent.
Are these issues which were not reported to us as of yet?
If not, please provide issue numbers.",2020/11/5 7:04 AM,3,,(I) Reporting a Bug
https://github.com/celery/celery/discussions/7017,2020/11/4 12:51 PM,Made a BUG report for most important one,2020/11/5 9:50 AM,4,1,(I) Reporting a Bug
https://github.com/celery/celery/discussions/7017,2020/11/4 12:51 PM,And the rest?,2020/11/5 1:43 PM,5,,(I) Reporting a Bug
https://github.com/celery/celery/discussions/7017,2020/11/4 12:51 PM,Updated.,2020/11/5 4:47 PM,6,,(I) Reporting a Bug
https://github.com/celery/celery/discussions/7017,2020/11/4 12:51 PM,I suppose that we need to improve tests of Celery because otherwise new bugs will pop out again and again... Mainly for such difficult code-base as Celery has.,2020/11/24 7:57 AM,7,,(I) Reporting a Bug
https://github.com/celery/celery/discussions/7017,2020/11/4 12:51 PM,"
I know it'll be closed but, I can't handle 1 BUG patched and 10 new BUGS introduced, so I'm going to give up Celery probably. Those are new BUGS I found that want report for your future progress(I'm on 5.0.2 from source actually cause it has my PR that i needed):


we are sorry you felt that way. distributed programming, in general, is a tough domain. as celery provides many things and the code base is big it's natural to have some edge cases which need a lot of effort & time to track & fix.",2021/1/2 2:48 PM,8,,(I) Reporting a Bug
https://github.com/celery/celery/discussions/7038,2021/9/17 6:30 PM,"Hey @newearthmartin __,
Thank you for opening an issue. We will get back to you as soon as we can.
Also, check out our Open Collective and consider backing us - every little helps!
We also offer priority support for our sponsors.
If you require immediate assistance please consider sponsoring us.",2021/9/17 6:30 PM,1,,(III) Reporting an Enhancement
https://github.com/celery/celery/discussions/7038,2021/9/17 6:30 PM,"the settings were changed in version 4, v5 just removed the deprecated old settings",2021/9/19 6:25 AM,2,,(III) Reporting an Enhancement
https://github.com/celery/celery/discussions/7038,2021/9/17 6:30 PM,"anyway I am closing this for now. if any future consensus is reached to rechange it, will reopen.",2021/9/19 4:17 PM,3,,(III) Reporting an Enhancement
https://github.com/celery/celery/discussions/7038,2021/9/17 6:30 PM,"I guess it's not going to look good to go back to the pre v4 settings.
I am concerned that this breaks the convention for Django settings. And as I said it does not play well with other apps. Imagine if all apps that use timezones added a plain timezone setting.",2021/9/19 4:50 PM,4,,(III) Reporting an Enhancement
https://github.com/celery/celery/discussions/7038,2021/9/17 6:30 PM,All apps prefix their settings with the app name AFAIK. And all apps use uppercase. If there was consensus about that it would be great. It used to be the case with Celery and I'm not sure why it was changed in the first place.,2021/9/19 5:09 PM,5,,(III) Reporting an Enhancement
https://github.com/celery/celery/discussions/7038,2021/9/17 6:30 PM,"@newearthmartin you can still use upper case name with a CELERY_ prefix.
See https://docs.celeryproject.org/en/stable/history/whatsnew-4.0.html#latentcall-django-admonition
and https://docs.celeryproject.org/en/stable/django/first-steps-with-django.html#using-celery-with-django",2021/11/3 6:16 AM,6,,(III) Reporting an Enhancement
https://github.com/celery/celery/discussions/7038,2021/9/17 6:30 PM,"I'm still confused as to what I'm supposed to be doing.
The release for 4.0 said:

But the current config docs say:

So, which is it?",2022/2/17 1:57 PM,7,,(III) Reporting an Enhancement
https://github.com/celery/celery/discussions/7038,2021/9/17 6:30 PM,These name changes for settings only make sense when you add the namespace setting. Wonder why documentation is not clear about this.,2022/2/18 8:33 PM,8,,(III) Reporting an Enhancement
https://github.com/celery/celery/discussions/7038,2021/9/17 6:30 PM,I created another issue to update the documentation #7309,2022/2/21 2:52 AM,9,1,(III) Reporting an Enhancement
https://github.com/celery/celery/discussions/7048,2020/11/30 9:32 PM,can you contribute to this?,2021/1/20 8:57 AM,1,,(III) Reporting an Enhancement
https://github.com/celery/celery/discussions/7048,2020/11/30 9:32 PM,"
can you contribute to this?

Sure.
Opened as an issue to gather some feedback on the proposal.
Can I consider it as accepted in design?",2021/1/22 11:33 PM,2,1,(III) Reporting an Enhancement
https://github.com/celery/celery/discussions/7048,2020/11/30 9:32 PM,"

can you contribute to this?

Sure.
Opened as an issue to gather some feedback on the proposal.
Can I consider it as accepted in design?

it seems OK as per your description to come with a Proof of concept. yet some more thoughts could be shared when the implementation can be seen. I am personally OK to give the POC a try. @celery/technical-board & @celery/core-developers will also chime in where necessary. But in general please go for it as it seems a useful influsion.",2021/1/23 8:12 AM,3,,(III) Reporting an Enhancement
https://github.com/celery/celery/discussions/7063,2021/11/9 2:56 PM,"@swuecho I'm checking, will get back to you by tomorrow morning.
I opened this as an issue - #7064",2021/11/9 4:27 PM,1,1,(IV) Reporting a Clarification Request
https://github.com/celery/celery/discussions/7063,2021/11/9 2:56 PM,"@swuecho I was unable to reproduce the issue, we're closing the issue for now.
If you can produce more stack traces or steps to reproduce, we will revisit the issue.",2021/11/9 5:47 PM,2,,(IV) Reporting a Clarification Request
https://github.com/celery/celery/discussions/7063,2021/11/9 2:56 PM,Thanks for the quick feedback. I will try to isolate the code to a small public repo if possible.,2021/11/9 11:28 PM,3,,(IV) Reporting a Clarification Request
https://github.com/celery/celery/discussions/7063,2021/11/9 2:56 PM,,2021/11/10 12:15 AM,4,,(IV) Reporting a Clarification Request
https://github.com/celery/celery/discussions/7255,2022/1/23 7:59 PM,Feel free to file a bug report about it. This should be easy to fix.,2022/1/27 11:25 AM,1,1,(I) Reporting a Bug
https://github.com/chartjs/Chart.js/discussions/10050,2022/1/6 5:24 AM,"This will have to be added to the typings file so this will be fixed before next release, (I should have time tonight to fix it)",2022/1/6 10:37 AM,1,,(I) Reporting a Bug
https://github.com/chartjs/Chart.js/discussions/10050,2022/1/6 5:24 AM,Thanks @LeeLenaleee . Do you want me to create an issue from this discussion for tracking the change?,2022/1/6 8:18 PM,2,1,(I) Reporting a Bug
https://github.com/ColorlibHQ/AdminLTE/discussions/3514,2021/3/16 9:26 AM,Convert this as issue __,2021/3/16 12:46 PM,1,1,(I) Reporting a Bug
https://github.com/ColorlibHQ/AdminLTE/discussions/3514,2021/3/16 9:26 AM,@danny007in - How do I convert it to an issue?,2021/3/17 1:14 PM,2,,(I) Reporting a Bug
https://github.com/ColorlibHQ/AdminLTE/discussions/3514,2021/3/16 9:26 AM,"Only Update the Jquery version and all function good
<script src=""https://ajax.aspnetcdn.com/ajax/jQuery/jquery-3.6.0.min.js"" type=""text/javascript""></script>",2021/9/8 11:12 PM,3,,(I) Reporting a Bug
https://github.com/ColorlibHQ/AdminLTE/discussions/3514,2021/3/16 9:26 AM,"Hello !
I have the exact same issue and I have alreay Jquery 3.6.0, Poppers and Bootstrap 4 are up to date. I try with the code from the demo, I also have the issue.",2022/3/17 9:46 AM,4,,(I) Reporting a Bug
https://github.com/ColorlibHQ/AdminLTE/discussions/3699,2021/5/16 6:39 PM,create this as issue,2021/5/16 6:49 PM,1,1,(IV) Reporting a Clarification Request
https://github.com/coqui-ai/TTS/discussions/603,2021/6/30 6:18 AM,"you can access the methods as you like by importing the module.
The latest docs might help https://tts.readthedocs.io/en/dev/",2021/7/1 12:32 AM,1,,(IV) Reporting a Clarification Request
https://github.com/coqui-ai/TTS/discussions/603,2021/6/30 6:18 AM,All further discussion occurs at issue #633.,2021/7/10 7:51 AM,2,1,(IV) Reporting a Clarification Request
https://github.com/dask/dask/discussions/7316,2021/3/3 9:50 PM,This looks like an issue with dask-yarn. I suggest you open a bug report in that repository https://github.com/dask/dask-yarn/issues,2021/3/5 3:47 PM,1,1,(II) External Repository
https://github.com/dask/dask/discussions/7411,2021/3/17 7:19 AM,"I would recommend filing an issue in dask-labextension repo.  However, before doing that I would look through dask/dask-labextension#87 and see if information there resolves your issue",2021/3/17 2:16 PM,1,1,(II) External Repository
https://github.com/dask/dask/discussions/7477,2021/3/27 5:19 PM,"
Now reading parquet files does not work anymore which is a serious issue.

Sorry to hear that -- if you're able to open a bug report, that would be welcome
Something like:

should allow you to downgrade to 2021.2.0 appropriately",2021/3/27 6:16 PM,1,1,(I) Reporting a Bug
https://github.com/deepset-ai/haystack/discussions/1617,2021/10/19 5:47 PM,"Also had an issue with testing Docker on a fresh download of the repo and Docker images (followed exact commands on README).
Log files:
haystack-api_1   | ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.
haystack-api_1   | [2021-10-19 19:16:54 +0000] [10] [INFO] Started server process [10]
haystack-api_1   | [2021-10-19 19:16:54 +0000] [10] [INFO] Waiting for application startup.
haystack-api_1   | [2021-10-19 19:16:54 +0000] [10] [INFO] Application startup complete.
haystack-api_1   | [2021-10-19 19:16:54 +0000] [10] [ERROR] Exception in ASGI application
haystack-api_1   | Traceback (most recent call last):
haystack-api_1   |   File ""/usr/local/lib/python3.7/site-packages/uvicorn/protocols/http/httptools_impl.py"", line 375, in run_asgi
haystack-api_1   |     result = await app(self.scope, self.receive, self.send)
haystack-api_1   |   File ""/usr/local/lib/python3.7/site-packages/uvicorn/middleware/proxy_headers.py"", line 75, in call
haystack-api_1   |     return await self.app(scope, receive, send)
haystack-api_1   |   File ""/usr/local/lib/python3.7/site-packages/fastapi/applications.py"", line 208, in call
haystack-api_1   |     await super().call(scope, receive, send)
haystack-api_1   |   File ""/usr/local/lib/python3.7/site-packages/starlette/applications.py"", line 112, in call
haystack-api_1   |     await self.middleware_stack(scope, receive, send)
haystack-api_1   |   File ""/usr/local/lib/python3.7/site-packages/starlette/middleware/errors.py"", line 181, in call
haystack-api_1   |     raise exc
haystack-api_1   |   File ""/usr/local/lib/python3.7/site-packages/starlette/middleware/errors.py"", line 159, in call
haystack-api_1   |     await self.app(scope, receive, _send)
haystack-api_1   |   File ""/usr/local/lib/python3.7/site-packages/starlette/middleware/cors.py"", line 84, in call
haystack-api_1   |     await self.app(scope, receive, send)
haystack-api_1   |   File ""/usr/local/lib/python3.7/site-packages/starlette/exceptions.py"", line 82, in call
haystack-api_1   |     raise exc
haystack-api_1   |   File ""/usr/local/lib/python3.7/site-packages/starlette/exceptions.py"", line 71, in call
haystack-api_1   |     await self.app(scope, receive, sender)
haystack-api_1   |   File ""/usr/local/lib/python3.7/site-packages/starlette/routing.py"", line 656, in call
haystack-api_1   |     await route.handle(scope, receive, send)
haystack-api_1   |   File ""/usr/local/lib/python3.7/site-packages/starlette/routing.py"", line 259, in handle
haystack-api_1   |     await self.app(scope, receive, send)
haystack-api_1   |   File ""/usr/local/lib/python3.7/site-packages/starlette/routing.py"", line 61, in app
haystack-api_1   |     response = await func(request)
haystack-api_1   |   File ""/usr/local/lib/python3.7/site-packages/fastapi/routing.py"", line 227, in app
haystack-api_1   |     dependant=dependant, values=values, is_coroutine=is_coroutine
haystack-api_1   |   File ""/usr/local/lib/python3.7/site-packages/fastapi/routing.py"", line 161, in run_endpoint_function
haystack-api_1   |     return await run_in_threadpool(dependant.call, **values)
haystack-api_1   |   File ""/usr/local/lib/python3.7/site-packages/starlette/concurrency.py"", line 39, in run_in_threadpool
haystack-api_1   |     return await anyio.to_thread.run_sync(func, *args)
haystack-api_1   |   File ""/usr/local/lib/python3.7/site-packages/anyio/to_thread.py"", line 29, in run_sync
haystack-api_1   |     limiter=limiter)
haystack-api_1   |   File ""/usr/local/lib/python3.7/site-packages/anyio/_backends/_asyncio.py"", line 805, in run_sync_in_worker_thread
haystack-api_1   |     return await future
haystack-api_1   |   File ""/usr/local/lib/python3.7/site-packages/anyio/_backends/_asyncio.py"", line 743, in run
haystack-api_1   |     result = func(*args)
haystack-api_1   |   File ""/home/user/rest_api/controller/search.py"", line 48, in query
haystack-api_1   |     result = _process_request(PIPELINE, request)
haystack-api_1   |   File ""/home/user/rest_api/controller/search.py"", line 66, in _process_request
haystack-api_1   |     result = pipeline.run(query=request.query, params=params)
haystack-api_1   |   File ""/home/user/haystack/pipeline.py"", line 300, in run
haystack-api_1   |     raise ValueError(f""No node(s) or global parameter(s) named {', '.join(invalid_keys)} found in pipeline."")
haystack-api_1   | ValueError: No node(s) or global parameter(s) named ESRetriever found in pipeline.
ui_1             | 2021-10-19 19:16:54.134 Expecting value: line 1 column 1 (char 0)
ui_1             | Traceback (most recent call last):
ui_1             |   File ""/home/user/webapp.py"", line 134, in main
ui_1             |     results, raw_json = retrieve_doc(question, top_k_reader=top_k_reader, top_k_retriever=top_k_retriever)
ui_1             |   File ""/usr/local/lib/python3.7/site-packages/streamlit/caching.py"", line 545, in wrapped_func
ui_1             |     return get_or_create_cached_value()
ui_1             |   File ""/usr/local/lib/python3.7/site-packages/streamlit/caching.py"", line 527, in get_or_create_cached_value
ui_1             |     return_value = func(*args, **kwargs)
ui_1             |   File ""/home/user/utils.py"", line 30, in retrieve_doc
ui_1             |     response_raw = requests.post(url, json=req).json()
ui_1             |   File ""/usr/local/lib/python3.7/site-packages/requests/models.py"", line 910, in json
ui_1             |     return complexjson.loads(self.text, **kwargs)
ui_1             |   File ""/usr/local/lib/python3.7/json/init.py"", line 348, in loads
ui_1             |     return _default_decoder.decode(s)
ui_1             |   File ""/usr/local/lib/python3.7/json/decoder.py"", line 337, in decode
ui_1             |     obj, end = self.raw_decode(s, idx=_w(s, 0).end())
ui_1             |   File ""/usr/local/lib/python3.7/json/decoder.py"", line 355, in raw_decode
ui_1             |     raise JSONDecodeError(""Expecting value"", s, err.value) from None
ui_1             | json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
Seems to be some sort of JSON issue between the search.py and pipeline.py files with the UI?",2021/10/19 7:19 PM,1,,(I) Reporting a Bug
https://github.com/deepset-ai/haystack/discussions/1617,2021/10/19 5:47 PM,"Hi @sieu-tran and @grahamschuckman, thanks for the bug report! I can see from your stacktrace that this is due to a new procedure for the validation of pipeline parameters tha we merged to master yesterday. I'm going to bugfix this soon and let you know when the fix is out.
Thanks @grahamschuckman for creating the issue (#1618) , let's continue the discussion there :)",2021/10/20 7:57 AM,2,1,(I) Reporting a Bug
https://github.com/deepset-ai/haystack/discussions/2014,2022/1/18 12:19 AM,"Hello @asharm0662, I'll admit this sounds like a bug. I'm now trying to replicate this behavior, so I can have a closer look at what's going on.
Do you mind if I convert this discussion into an issue? This way we can track it better, especially if it ends up being a real bug.",2022/1/19 9:35 AM,1,1,(IV) Reporting a Clarification Request
https://github.com/encode/httpx/discussions/1528,2020/8/15 10:17 AM,"At the moment it feels like the right thing, yup.
I'm not even against us thinking about if we should just be maintaining it all as a single package, but with a really clearly defined interface split at the transport API level.

Pros: Easier release management our side, less potential for versioning issues when users report issues / trying to figure out when something was fixed/broken etc.
Cons: Not having a strict package split makes it less obvious to users/devs that each part can be treated strictly in isolation, when trying to understand things under the hood. Easier for us to fall into bad separation of concerns. Perhaps harder to convince other projects to adopt our transport layer?
",2020/8/20 9:47 AM,1,,(III) Reporting an Enhancement
https://github.com/encode/httpx/discussions/1528,2020/8/15 10:17 AM,"@tomchristie Dunno about the package split, I think it really nicely enforces the interface split (eg by making it harder to sneak network features in HTTPX and vice versa). But that's something we can discuss separately if we feel it. :-)
So as for unifying issue trackers on this HTTPX repo, a clear yes it seems? Curious what the migration process would look like. I guess something like this?

 Create an httpcore label in this repo.
 Transfer issues from HTTPCore to this repo. - Example here: #1245
 Add a note in the HTTPCore README that the issue tracker is located on the HTTPX repo.
 Disable issues in the HTTPCore repo.
",2020/9/1 9:23 PM,2,,(III) Reporting an Enhancement
https://github.com/encode/httpx/discussions/1528,2020/8/15 10:17 AM,"I transfered #1245 here and applied the httpcore label on it. Does this feel enough for clearly identifying what belongs to HTTPX, and what belongs to HTTPCore?",2020/9/1 9:28 PM,3,1,(III) Reporting an Enhancement
https://github.com/encode/httpx/discussions/1611,2021/4/28 4:56 PM,"Thanks for raising this. I confirmed by downloading a large file, and then disconnecting wi-fi midway through the download.
And, as you say, the request then raised a timeout error after 5 seconds. (Despite the timeout=None parameter.)
I've tracked this down to a bug introduced in this pull request #1577 and have now resolved in #1613. A new release should be incoming fairly shortly.",2021/4/29 10:07 AM,1,1,(I) Reporting a Bug
https://github.com/encode/httpx/discussions/1747,2021/7/12 4:26 AM,#1439 seems related to this but as random input i've also had a similar issue with having to silence type warnings when wrapping the AsyncClient,2021/7/14 9:05 PM,1,,(I) Reporting a Bug
https://github.com/encode/httpx/discussions/1747,2021/7/12 4:26 AM,"I mean it's a real mixed bag. Yeah we could but it'd add an awful lot of extra noise to the codebase.
I guess I'd be happy to review how the change looked if someone wanted to go ahead and issue a pull request that changed all those signatures, and switched up our own mypy rules to enforce it, but I certainly wouldn't be able to say if we'd accept the pull request or not, so it'd need someone who's willing to put in that time, without having any guarantees that it'd make it in.",2021/7/15 9:34 AM,2,1,(I) Reporting a Bug
https://github.com/encode/httpx/discussions/2036,2022/1/18 4:57 PM,Thanks for mentioning this. I've raised an issue at #2042,2022/1/22 3:54 PM,1,1,(IV) Reporting a Clarification Request
https://github.com/encode/httpx/discussions/2052,2022/1/27 8:54 PM,"Gotcha thanks for the feedback - escalated as #2053.
I expect(?) it'll be an easy one to resolve, but let's see.",2022/1/28 10:50 AM,1,1,(I) Reporting a Bug
https://github.com/encode/httpx/discussions/2077,2022/2/9 9:15 PM,Example of such setting in akka-http https://doc.akka.io/docs/akka-http/current/common/timeouts.html#connection-lifetime-timeout,2022/2/10 9:00 AM,1,,(III) Reporting an Enhancement
https://github.com/encode/httpx/discussions/2077,2022/2/9 9:15 PM,"I've escalated it into an issue, since it looks like it's not covered in the docs right now.
See issue #2079 to track this.
You can control the keep alive expiry like this...

Thanks for the feedback - really great prompt to help us document this.",2022/2/10 11:21 AM,2,1,(III) Reporting an Enhancement
https://github.com/encode/uvicorn/discussions/1388,2022/2/23 12:55 PM,"good catch yes @HarrySky , raised as issue
#1389",2022/2/23 1:03 PM,1,1,(I) Reporting a Bug
https://github.com/Gallopsled/pwntools/discussions/1743,2020/12/14 10:35 PM,What type is b? is it an ELF? Maybe this deserves opening an issue?,2020/12/18 8:28 PM,1,1,(IV) Reporting a Clarification Request
https://github.com/google/flax/discussions/1089,2021/3/6 1:22 AM,I think we should be a little careful here to avoid reducing over axes that actually aren't spatial dims.  To me it would make most sense if axis is an constructor argument with default value -1. Feel free to file a PR or issue for this.,2021/3/8 2:22 PM,1,1,(III) Reporting an Enhancement
https://github.com/google/flax/discussions/2080,2021/1/22 3:08 PM,"Hey, thanks for the guide. This is useful.
I found something unintuitive:

params['params'] gives me:

and params.pop('params') gives me a tuple:

Why are they different?
BTW, I found this usage here:

",2021/1/30 4:35 AM,1,,(III) Reporting an Enhancement
https://github.com/google/flax/discussions/2080,2021/1/22 3:08 PM,"Hi @cccntu -- what do you mean by ""different""? pop returns two parts: the variable collection that you popped, and the remaining collections still all grouped together, e.g.:

Maybe the docstring for FrozenDict.pop isn't clear enough? But this is working as intended.
(BTW in your example you wrote params = model.init(rng, dummy_input) -- it should probably be variables = model.init(rng, dummy_input) as parameters are one of possible multiple variable collections)
Does this help? What could we improve in our documentation so that this would be less confusing?",2021/2/1 9:57 AM,2,,(III) Reporting an Enhancement
https://github.com/google/flax/discussions/2080,2021/1/22 3:08 PM,"@avital  Thanks for the reply.
I said different because I expect it to behave like python dict.
But I get it now, since flax/jax is functional, it make sense to return the remaining dictionary. Thanks for the help and the naming suggestion!
I didn't find the doc for FrozenDict from google search and readthedocs search is extremely slow. So I didn't read the doc.
I just found it by searching Github and I think it's clear enough.",2021/2/1 10:17 AM,3,,(III) Reporting an Enhancement
https://github.com/google/flax/discussions/2080,2021/1/22 3:08 PM,"I don't think we even have reference docs for FrozenDict on RTD, we probably should. I filed an issue: #969",2021/2/1 10:21 AM,4,1,(III) Reporting an Enhancement
https://github.com/google/flax/discussions/2080,2021/1/22 3:08 PM,"Hey!
I am very interested in the best practices for BatchNorm (or batch_stats in general I guess) when used inside a pmap. Is the recommendation to use lax.pmean to synchronize them? Are there example available?
Thanks!",2021/3/6 2:50 AM,5,,(III) Reporting an Enhancement
https://github.com/google/flax/discussions/2080,2021/1/22 3:08 PM,"
I am very interested in the best practices for BatchNorm (or batch_stats in general I guess) when used inside a pmap

See the ImageNet example for the canonical example of combining BatchNorm and pmap. There indeed we sync the statistics before evaluation with pmean.",2021/3/8 2:29 PM,6,,(III) Reporting an Enhancement
https://github.com/google/flax/discussions/2080,2021/1/22 3:08 PM,"Since @marcvanzee already provides an answer to ""how to use batchnorm"" in his original post above, I'm only going to cover the question ""when and how to normalize statistics"" asked by @cgarciae and more recently by @laoreja (on an internal forum), and answered above by @jheek and by @levskaya (on an internal forum)
Our examples/imagenet/ uses nn.BatchNorm in the ResNet model:


Then we define a utility function sync_batch_stats()...


...which we then call before evaluating...


...and before writing a checkpoint


Alternatively, we could have specified axis_name='batch' when instantiating nn.BatchNorm in the model code. Then the batch stats would be synced automatically in the layer at every step. This alternative approach is less verbose, but it requires to pass down the axis_name parameter to the model definition, and batch stats are synced at every step (causing some communication overhead).
Syncing would then happen here:

",2022/5/31 9:45 AM,7,,(III) Reporting an Enhancement
https://github.com/google/flax/discussions/2085,2021/12/22 11:36 PM,Linking discussion from Detectron2 facebookresearch/detectron2#3817,2021/12/22 11:39 PM,1,,(III) Reporting an Enhancement
https://github.com/google/flax/discussions/2085,2021/12/22 11:36 PM,"Hi @INF800 -- we'd love to see something like Detectron2 ported to JAX/Flax. (Though I personally don't know almost anything about that project).
What kind of support would you be looking for? Then we can ask around and see if someone can help in the best way.",2021/12/23 2:12 PM,2,,(III) Reporting an Enhancement
https://github.com/google/flax/discussions/2085,2021/12/22 11:36 PM,"
_",2021/12/23 2:35 PM,3,,(III) Reporting an Enhancement
https://github.com/google/flax/discussions/2085,2021/12/22 11:36 PM,"Folks on our GitHub discussion board are pretty helpful, and both folks that work on JAX and Flax, as well as knowledgable community members can help. The upside this way is that other people can benefit from the learning. I propose we start with that, and if you start making progress and would benefit from more intensive support we can see what we can do. How do you feel about that?",2021/12/23 2:37 PM,4,,(III) Reporting an Enhancement
https://github.com/google/flax/discussions/2085,2021/12/22 11:36 PM,"
Folks on our GitHub discussion board are pretty helpful, and both folks that work on JAX and Flax, as well as knowledgable community members can help. The upside this way is that other people can benefit from the learning. I propose we start with that, and if you start making progress and would benefit from more intensive support we can see what we can do. How do you feel about that?

Perfect! I will open up related issues/discussions and  link them to this issue to keep track of them. As said before I will be starting it actively from Feb 2022. Until then will try to understand more about JAX and Detectron2 and you can expect me to open up multiple discussion topics related to JAX :)",2021/12/23 2:43 PM,5,1,(III) Reporting an Enhancement
https://github.com/google/flax/discussions/2085,2021/12/22 11:36 PM,"Great! One possible first step is only to port one particular model in a standalone codebase, such as Mask R-CNN, and see what we need to do from there.",2021/12/23 2:52 PM,6,,(III) Reporting an Enhancement
https://github.com/google/flax/discussions/2085,2021/12/22 11:36 PM,"
Great! One possible first step is only to port one particular model in a standalone codebase, such as Mask R-CNN, and see what we need to do from there.

Makes sense I was planning to do the same. Will update here once I create it.",2021/12/23 2:53 PM,7,,(III) Reporting an Enhancement
https://github.com/google/flax/discussions/2085,2021/12/22 11:36 PM,https://github.com/google-research/scenic is a flax computer vision code base as a reference.,2022/1/4 6:25 AM,8,,(III) Reporting an Enhancement
https://github.com/google/flax/discussions/2085,2021/12/22 11:36 PM,"
https://github.com/google-research/scenic is a flax computer vision code base as a reference.

Thanks. Detectron2 internally uses fvcore https://github.com/facebookresearch/fvcore. Is this project similar to fvcore?",2022/1/4 11:29 AM,9,,(III) Reporting an Enhancement
https://github.com/google/flax/discussions/2085,2021/12/22 11:36 PM,"@INF800 I moved your issue to a ""Show and Tell"" Discussion Thread, which seemed more appropriate. Looking forward to hearing about your progress!",2022/4/27 8:41 PM,10,,(III) Reporting an Enhancement
https://github.com/google/flax/discussions/730,2020/12/12 11:55 PM,Nice catch -- indeed we should switch away from using onp. Feel free to file an issue or pull request. Thanks!,2020/12/13 12:43 AM,1,1,(III) Reporting an Enhancement
https://github.com/google/flax/discussions/738,2020/12/16 2:33 AM,Yes I think you are right. Pooling layers still assume there is a batch dimension. This should be an easy fix. I created an issue for this #739,2020/12/16 9:45 AM,1,1,(IV) Reporting a Clarification Request
https://github.com/home-assistant/frontend/discussions/10484,2021/10/30 7:45 PM,"This is not a frontend discussion about new frontend feature or frontend design, but a core issue.
Please this issue in the issue tracker here:
https://github.com/home-assistant/core/issues
Be sure to check your issue hasn't been reported by someone else already by using the search.
Thanks! __
../Frenck",2021/10/31 11:43 AM,1,1,(II) External Repository
https://github.com/home-assistant/frontend/discussions/10663,2021/11/19 9:08 PM,That is actually a bug. I will create an issue out of this discussion and push a fix (#10666).,2021/11/20 12:34 AM,1,1,(I) Reporting a Bug
https://github.com/home-assistant/frontend/discussions/12339,2022/4/17 5:38 AM,"I opened a GitHub issue

Stating that it is not just no feedback but the original screen reloads. Also on the restore my database doesn't start automatically and this causes recorded issues.
The issue on the screen has been confirmed but no one has been working on a fix.
Not sure how progress can be measured as communication between the HA device and the desktop is lost?",2022/4/17 9:06 AM,1,1,(III) Reporting an Enhancement
https://github.com/home-assistant/frontend/discussions/12397,2022/4/24 6:16 PM,"I have a small variation on colors but I would rather prefer to have some friendly color for this dashboard on energy source:

Ideally colors should be defined at dashboard definition level :
",2022/12/11 5:41 PM,1,,(III) Reporting an Enhancement
https://github.com/home-assistant/frontend/discussions/12397,2022/4/24 6:16 PM,"+1 on this! I have 25+ sources (monitoring each individual breaker) that fit better in this kind of stacked bar graph per hour instead of the ""individual devices"" list below it, because it gives richer hour-to-hour insights on consumption and also cost. Or a 2.0 version of energy monitoring and analysis - the Energy tab has a lot of potential. Thanks for your work :)
",2023/1/6 2:04 PM,2,,(III) Reporting an Enhancement
https://github.com/home-assistant/frontend/discussions/12397,2022/4/24 6:16 PM,"I would like some control too.. In France, there are several tarifs and here is my current display:

It is then very hard to distinguish in the bar chart",2023/2/7 1:39 PM,3,,(III) Reporting an Enhancement
https://github.com/home-assistant/frontend/discussions/12397,2022/4/24 6:16 PM,+1 for a color picker,2023/2/7 1:41 PM,4,,(III) Reporting an Enhancement
https://github.com/home-assistant/frontend/discussions/12397,2022/4/24 6:16 PM,"I've created an issue regarding the problem caused by the current implementation here: #15384
This feature request would solving the issue.",2023/2/7 1:45 PM,5,1,(III) Reporting an Enhancement
https://github.com/home-assistant/frontend/discussions/12397,2022/4/24 6:16 PM,"Nearly a year and the energy features still get no love and yet it's one of the best features (or could be) for me at least.
Every month I read the release notes in anticipation of some enhancements, every month im dissapointed. Such a shame as it really feels like a neglated part of the system that gets overlooked in favour of the latest automation buzz topics",2023/2/7 2:40 PM,6,,(III) Reporting an Enhancement
https://github.com/home-assistant/frontend/discussions/8739,2021/3/28 1:44 PM,might I post a slight nudge here? issue is still very much alive while on 2021.10,2021/10/6 11:52 AM,1,,(IV) Reporting a Clarification Request
https://github.com/home-assistant/frontend/discussions/8739,2021/3/28 1:44 PM,"The scrollbar should not be overlaying the editor. Please create a bug ticket for that. Might be something that has to be fixed upstream actually. Seem platform specific, because it works fine for me on Windows.",2021/10/26 1:20 PM,2,1,(IV) Reporting a Clarification Request
https://github.com/home-assistant/frontend/discussions/8739,2021/3/28 1:44 PM,"ok will do, and just checked, still happening on Desktop Mac, HA 2021.11.0.dev20211026:
",2021/10/26 3:35 PM,3,,(IV) Reporting a Clarification Request
https://github.com/home-assistant/frontend/discussions/8739,2021/3/28 1:44 PM,"I didn't realize there was a place for this on GitHub.
Here's an accompanying feature request I created from the forums.
https://community.home-assistant.io/t/move-reset-to-demo-template-somewhere-else/432132?u=danny2100",2022/7/29 4:35 PM,4,,(IV) Reporting a Clarification Request
https://github.com/horovod/horovod/discussions/2763,2020/12/23 9:52 AM,"@DEKHTIARJonathan, have you run into this issue with XLA as well?  Seems TF is not honoring its GPU visibility rules.",2021/1/5 12:39 AM,1,,(II) External Repository
https://github.com/horovod/horovod/discussions/2763,2020/12/23 9:52 AM,"I'm pretty sure that if you only want memory on GPU0, you need to use CUDA_VISIBLE_DEVICES=""0"" horovodrun ...",2021/1/5 1:42 AM,2,,(II) External Repository
https://github.com/horovod/horovod/discussions/2763,2020/12/23 9:52 AM,"I think the problem is that we need to have visibility into multiple GPUs for Horovod to work, but TensorFlow should not be allocating memory on every GPU when we set tf.config.visible_devices.  Seems this isn't working correctly with XLA in the latest version.",2021/1/11 4:42 PM,3,,(II) External Repository
https://github.com/horovod/horovod/discussions/2763,2020/12/23 9:52 AM,"We had this exact issue a 1.5 years ago. With XLA allocating memory on every GPUs.
Please open an issue on Tensorflow side, tag myself, @nluehr @bas-aarts (for NV side) and @reedwm @sanjoy (for Google side).
Please attach information to reproduce the bug.",2021/1/11 11:00 PM,4,1,(II) External Repository
https://github.com/horovod/horovod/discussions/2763,2020/12/23 9:52 AM,Thanks @DEKHTIARJonathan.  @hetaoaoao can you open the issue on the TensorFlow side?,2021/1/12 2:59 PM,5,,(II) External Repository
https://github.com/horovod/horovod/discussions/2763,2020/12/23 9:52 AM,"Ah, we've got a workaround for this.
Do
os.environ[""TF_XLA_FLAGS""] = ""--tf_xla_auto_jit=2 --tf_xla_enable_xla_devices=true""
instead of
os.environ[""TF_XLA_FLAGS""] = ""--tf_xla_auto_jit=2""
resolves this issues.",2021/1/13 6:27 AM,6,,(II) External Repository
https://github.com/horovod/horovod/discussions/2763,2020/12/23 9:52 AM,"In general, XLA+horovod will not be as beneficial as it could be, due to missing tf2xla horovod kernels (PRs welcome!)
@hetaoaoao

--tf_xla_enable_xla_devices=true

This enables deprecated XLA:GPU devices and generally should not be done, is it possible to provide a clean reproducer for this issue? Generally we advice using jit_compile=True instead of autoclustering (as it's not clear what autoclustering will cluster), but it could be a bit difficult for horovod due to missing tf2xla kernels.",2021/1/13 5:54 PM,7,,(II) External Repository
https://github.com/horovod/horovod/discussions/2763,2020/12/23 9:52 AM,"Wanted to briefly comment on:

I think the problem is that we need to have visibility into multiple GPUs for Horovod to work, but TensorFlow should not be allocating memory on every GPU when we set tf.config.visible_devices. Seems this isn't working correctly with XLA in the latest version.

It isn't required for Horovod to have visibility to multiple GPUs to work, at least, not anymore. Older versions of NCCL (pre 2.4.6), did have this limitation where all GPUs on the node needed to be visible, but that is no longer the case. So a workaround to avoid TF creating a context on each GPU would be to set CUDA_VISIBLE_DEVICES to the local rank so that each process only sees a single GPU. This also requires making script changes to account for this (i.e. replace any device indexing by hvd.local_rank() with a 0 since all processes will just have a single GPU 0 visible).
An example of doing this with OpenMPI would look something like:
",2021/1/22 10:42 PM,8,,(II) External Repository
https://github.com/horovod/horovod/discussions/2763,2020/12/23 9:52 AM,This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.,2021/3/24 12:49 AM,9,,(II) External Repository
https://github.com/horovod/horovod/discussions/2763,2020/12/23 9:52 AM,looking into this,2021/3/24 2:26 PM,10,,(II) External Repository
https://github.com/horovod/horovod/discussions/2763,2020/12/23 9:52 AM,The answer by @romerojosh is indeed the preferred way.,2021/4/28 8:59 PM,11,,(II) External Repository
https://github.com/iterative/dvc/discussions/5208,2021/1/5 3:13 PM,"Hi @raman-rajarathinam!
Currently, we do not have an open issue for that. Could you open one? If we get enough demand for that feature, we definitely would consider that. Also, we are open to contributors pull requests, and can help with development, if one decides to follow this path.",2021/1/6 8:58 AM,1,1,(IV) Reporting a Clarification Request
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"Hi @kskyten
Could you please give us a bit more details? Are you talking about deep learning style computations when a result of each epoch will be saved and then, possible, reused? If so, how do you save the results - as a single file or a set of files in an input directory (like in Pachyderm docs)?",2017/12/5 5:57 PM,1,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"Let's say you have a folder of images and you define a computationally intensive pipeline for them. After having defined this pipeline you acquire new images that you want to process. This corresponds to the inter-datum incrementality in Pachyderm, if I understood correctly.",2017/12/11 12:02 AM,2,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"We are going to implement Dependency to directory #154 which is a little bit related to this incremental feature. But it is not enough.
This is a good scenario. Let's keep this feature request - it will be implemented. We just need to decide a priority.",2017/12/12 7:08 AM,3,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"@dmpetrov , are we there yet or we should keep this open?",2019/2/5 12:05 AM,4,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"@MrOutis Yep, this should work now by using dvc unprotect: https://dvc.org/doc/user-guide/how-to/update-tracked-files
Closing, please feel free to reopen.",2019/2/5 12:09 AM,5,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"Guys, this is actually a request for streaming\micro-batch processing.
Scenario: I have a dir with images and I'd like to process each image with dwt_ll4.py to generate a spectrum matrixes. If new 23 images were added I'd like to run the script only for these 23 images.
It is mostly data engineering scenario, not data science. So, we should think carefully if DVC should handle this or not. But it is still a valid case and it will be especially useful when we implement multi-processing #755.
So, I'm renaming and reopening.",2019/2/5 12:30 AM,6,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"Thanks, @dmpetrov",2019/2/5 12:32 AM,7,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"Hi, has this eventually been implemented ?",2019/11/15 10:53 AM,8,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"Hi @Pierre-Bartet, it have not been yet implemented. Would you find this feature useful? Could you describe your use case?",2019/11/15 1:40 PM,9,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"@pared Use cases equivalent to the one already described:

Scenario: I have a dir with images and I'd like to process each image with dwt_ll4.py to generate a spectrum matrixes. If new 23 images were added I'd like to run the script only for these 23 images.

In fact this is exactly at this point that data version control tools could become really useful because the situation is messier than in the 'vanilla' use case. AFAIK Pachyderm is the only tool with this kind of feature but it is super heavy. I think what is needed is to be able to


Add an empty collection of objects:
$ dvc add --collection  my_collection


Create a pipeline using this collection as a dependency, applying computation.py separately on each object of the collection:
$ dvc run --d  my_collection computation.py


Later add new files to the collection:
$ dvc add new_file(s) --to my_collection


So that a dvc repro would only run on needed files.
The hard part is that:
$ dvc run --d  my_collection computation.py
could both mean:

'apply computation.py separately on each object of the collection' -> If for example we want to substract the mean of each image from each pixel
'apply computation.py on the whole collection' -> If for example we want to substract the global mean of all the images from each pixel

So I guess the '--d' should be replaced by something else to distinguish between those two cases.",2019/11/15 2:46 PM,10,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"
could both mean

'apply computation.py separately on each object of the collection' -> If for example, we want to subtract the mean of each image from each pixel
'apply computation.py on the whole collection' -> If for example, we want to subtract the global mean of all the images from each pixel


I don't think that distinguishing whether to apply a given code on each image or all images should be DVC responsibility. DVC is an abstraction that takes care of tracking code and its dependencies.  But there are too many use cases of DVC (any data science project, so data can range from CSV to folder full of files).
This use case(apply on image vs dataset) assumes that DVC is aware of code logic and dependency structure, while it should not be.
Having said that I think that we could implement this feature (applying on ""new"" data) for directory dependencies, but it would need to be users' conscious decision to use it.
One option could be, for example, flag-like:
dvc run -d modified_folder -o spectrum_matrices_folder --incremental code.py
Implementation won't be that easy though, because we should probably create some temporary dir that would store ""only new"" dependency files, and apply code to this temp dir and append output to already existing output of this stage.
Some notes:

How can we be sure that output md5 is the same as it would be if we just run processing on the whole modified_folder? Does it even matter if the user made a conscious decision to use --incremental?
In the case of code using information about the whole dataset, this feature can produce wrong outputs.
(e.g subtract mean of all images, that case requires running the code on the whole dataset, in other case mean of all images won't be mean of all images, just batch mean)
(At least in the beginning) We would need verification that this option is used for dir dependency

After writing this, it seems to me that my proposition for this solution is wrong since it can easily be misused. Leaving this here for further discussion. Maybe we could implement this as advanced use case but that seems dangerously similar to --outs-preserve. Or maybe someone has a better idea of how it should be done.",2019/11/19 1:21 PM,11,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"@Pierre-Bartet @pared an interesting discussion. I also don't see a way how DVC being completely agnostic to the way code and files are organized now can solve this now. Thinking about the right abstraction for the job, I have first the question back:
Let's imaging we do:
$ dvc run --d my_collection computation.py
How does this script organized internally? How does it read the data from this my_collection?
I'm asking because right now like I mentioned we don't dictate any of that. But when we start doing things incrementally how do pass that delta information to the script? How will it know that it needs to read only certain files from the directory?
@Pierre-Bartet do you have some ideas that comes to your mind?",2019/11/20 4:42 AM,12,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"I've been thinking about it but I see no solution that would not totally change DVC's behaviour, mostly because of what you just said:

when we start doing things incrementally how do pass that delta information to the script?

The behaviour I had in mind was to have the dependencies given as arguments to the scripts (here computation.py) so that dvc run could either:

call repeteadly computation.py file_i
call a single time computation.py folder

But that is indeed a huge deviation from the current dvc behaviour",2019/11/20 9:37 AM,13,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"This is also a feature which I would like to see handled better with DVC if possible. Currently, the only way to avoid expensive re-computation on partial data sets when adding new data is to bypass DVC altogether, execute the processing on only the new files, and then run dvc commit on the results -- which seems rather to detract from the whole point of using DVC in the first place to track changes to datasets. And yet, it must be possible to avoid re-processing tens of thousands of files just because a single new file was added to an input directory.
@Pierre-Bartet, my thoughts for a possible behaviour were also in the same direction as yours, passing [delta] dependencies to the script being run.
A gentler approach along the same lines may be the following:

DVC could maintain an index of filepaths changed since the last commit, for example in a section of the .dvc file of the dependency in question
It's up to the script called by dvc run whether it wants to read and make use of this index to filter the input files, or to ignore the information and process everything as usual
After a successful run, the index is flushed and the hashes re-computed

This is for sure ""advanced"" behaviour and requires users to be aware of the existence of the index. But at least it doesn't mean DVC having to change its behaviour in regard to how it calls commands with dvc run.
I realise this suggestion isn't necessarily entirely thought through, for which I apologise. Please feel free to tear it down where necessary :)",2019/11/21 4:04 PM,14,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"I find this feature really useful __
Not ML related but with ETL is pretty common to do such things.
Having a cache  is not useful if you are still recomputing files.
The simplest scenario that I can imagine is by giving the user a way to tell which files are new, for example:

When you add more files:

Doing dvc ls --outs --new data.dvc would output:

that way the user would iterate over all of those files and run the respective command and then dvc commit data.
The implementation for ls --outs --new would be something like the following:

We could start with a simple implementation and add more features depending on users request, what do you think?

A lot of manual work, but if you want to process everything with a single call, like @Pierre-Bartet suggested in #331 (comment), you can link those files to a new directory and use it as an argument for your script:
",2019/11/21 9:38 PM,15,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"This is especially frustrating now that I tried to implement my own incremental-processing workaround: I simply set an argument to my computation.py which, if true, doesn't touch any input file that already has a corresponding output file in the output.
I realise that this breaks the ability for DVC to know that all outputs were created by the command being run (but I already can't use DVC properly in my case anyway, since the only solution I have to avoid reprocessing all files every time a single file changes in the input is to manually run computation.py outside of DVC and dvc commit the results, which has the same breaking effect).
So I executed my pseudo-incremental version of computation.py on my input, only to discover that DVC automatically removes anything in the output location every time dvc run is called (without warning! -- see #2027 ) __",2019/11/27 6:15 PM,16,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"Hi @markrowan !
DVC deletes those outputs automatically only if it knows that it already has them in the cache, so you would be able to dvc checkout to get them back. We have an unofficial hidden flag for dvc run, that tells dvc to not remove the particular output before running the command. It is called --outs-persist ain CLI and persist: true in dvc-file itself. We don't document it because we are not quite sure if we are okay with how hacky it is and are afraid of people misusing it and then getting unreproducible pipelines __ Please be aware of that, but feel free to give it a try and if you do, please make sure to let us know what you think about it. __",2019/11/27 9:21 PM,17,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"This is a great use-case. I even heard about this requirements for a couple of times outside of our issue tracker like ""can DVC processes only new images?"". It needs to be implemented as a part of DVC.
Challenges
There are some challenges with API and how to align the feature with the current DVC interface and which part goes to code:

""a huge deviation from the current dvc behaviour"" @Pierre-Bartet
""[use case] ... assumes that DVC is aware of code logic and dependency structure"" @pared
""... how DVC being completely agnostic to the way code and files are organized..."" @shcheklein

Solutions
All of the above questions are great. Also, @Pierre-Bartet, @pared and @markrowan pointed to possible solutions. Some of the solutions might align well with DVC design.
Passing files as an argument (append to the args list) to the code is the best protocol between DVC and code that I see for now (I mean the first option with file_i):

The behaviour I had in mind was to have the dependencies given as arguments to the scripts (here computation.py) so that dvc run could either:

call repeteadly computation.py file_i
call a single time computation.py folder


How this can look from command line:

What is important:

DVC needs to understand that it works in ""streaming"" mode and it needs to be signaled to the tool by a separate command (not dvc run) or by a special set of parameters like in the example above --process-dependency/--process-output.
DVC should create output dir for the first run when it was not yet created
DVC should not remove the outputs dir before running/reproducing the commands
Regular dependencies -d myscript.py -d libs/ might also be used
Regular outputs cannot be specified -o logs/ (why not? any useful use case?). I feel like here is the place with another ""deviation"" from DVC.
To make this command reproducible we need to make sure that DVC can get a checksum for each version of input dir. (how to get checksums for dirs? if not data dir? should we limit the command by data dirs?)
Inside the input dir we should be able to work with files, dirs or both.
Store all inputs and all outputs checksums (index from @markrowan comment). Probably the same way we do it now. Based on my understanding, we don't need to store mapping 'input_file_i --> processed_file_i' we just need a ""checksum"" of the entire input dir and each of the outputs.

Open design questions

Do we need a separate command for this like dvc process/stream instead of dvc run
Better option names instead of --process-dependency and --process-output. Related to the previous question.
--recursive option to process all files from the dir. This option is a reason to have a separate command since dvc run does not need it.

Presenting result to users
When the use case will be implemented we need to show a nice looking use case in the documentation or a separate blog post. It's great to have this use case even before the release - it will help driving requirements and test the implementation.
@Pierre-Bartet @markrowan @kskyten could you please help us to define the use-case? The major questions:

Dataset. Which dataset we should use? It should be open, and look natural, not like file_cat.jpg  file_dog.jpg.
Motivation. What kind of processing do we need to apply? If images, we should explain the motivation of not doing this processing on-flight or why the processing result should be stored. Heavy image processing - any examples of this?

If someone can participate or even drive this doc/blog-post activity it would be awesome.
Related issues
For a broader perspective, there are some issues that might be (or might not) related to this one. It would be great is we find some similarities in the scenarios and can reuse this.

#1018 ""build matrix"". Difference: the build matrix has a predefined set of runs (and run parameters) while this issue takes all the files as the set of parameters. In theory, build matrix might be extended to this use case.
#2825 pulling subset of files from a data-dir. It is kind of ""interactive mode"" of working with data folder. @Pierre-Bartet used this interaction-like trick in command $ dvc add new_file(s) --to my_collection
Also, there was a verbal request from a user who asked for the ability to add a file into data-dir without pulling data (for optimization purposes). It is an inversion/push-version of #2825.
ADDED 12/2/19: #755 - parallel job running. It seems like this streamming/processing case is a special case of parallel running.
",2019/12/1 7:33 PM,18,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"

Regular outputs cannot be specified -o logs/ (why not? any useful use case?). I feel like here is the place with another ""deviation"" from DVC.


Yes both the input and the output will be some kind of new 'collection' objects.


To make this command reproducible we need to make sure that DVC can get a checksum for each version of input dir. (how to get checksums for dirs? if not data dir? should we limit the command by data dirs?)


This can be done using hash lists or hash trees.


Inside the input dir we should be able to work with files, dirs or both.


Therefore hash trees. Also trees can help if you want to be able to support folder with a large number of files (I've faced several use cases involving millions of files).

Related issues

Isn't all this also related to parallel processing ? (not a rhetoric question)",2019/12/2 3:38 PM,19,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"


Inside the input dir we should be able to work with files, dirs or both.


Therefore hash trees. Also trees can help if you want to be able to support folder with a large number of files (I've faced several use cases involving millions of files).

Right. We are already using some kind of hashing in DVC. It would be great if the current hashing mechanism would be reused. The existing one might not work for not-data files and dirs.


Related issues

Isn't all this also related to parallel processing ? (not a rhetoric question)

Absolutely! Updated.
It will require an additional command line parameter like --jobs 24 which is another argument for separating this into a separate command to not over pollute dvc run params list.",2019/12/2 6:50 PM,20,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"There is still a sub use case of training on top. For this you both need an old output (a pretrained model) and a set of added files (new inputs), which is essential to some deep learning, esp. images/nlp scenarios.
This, however, complicates things a lot:

an output is reused as a dep,
there is no checksum reproducibility, because the final model depends on how we chunked the data.
",2019/12/5 12:10 AM,21,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"

an output is reused as a dep,


Isn't it already the case ?


there is no checksum reproducibility, because the final model depends on how we chunked the data.


Why ? In the situation you describe, the model is build from all the images, so it is not incremental: the training script must be applied to the whole image folder, not image by image.",2019/12/5 7:55 AM,22,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"
Isn't it already the case ?

Not if you in fact process them 1 by 1, so that f(collection(items)) = collection(f(items)). Or at least you can work that around.

Why ? In the situation you describe, the model is build from all the images, so it is not incremental: the training script must be applied to the whole image folder, not image by image.

You train a model on a set of images, then you add a new batch and you train on a new batch starting from the pretrained model, not from random weights. This will result in a model knowing about images of both batches, but this is not the same as training on a combined set form the start, so we loose checksum reproducibility. This might be, however, close enough and faster to compute.",2019/12/5 8:26 AM,23,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"We can think of the difference as ""do our transform function have this property"":

And also is it a strict = or a good enough ~ for a user.",2019/12/5 8:37 AM,24,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,We should also consider raising the priority. What do you think guys?,2019/12/5 8:46 AM,25,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"
You train a model on a set of images, then you add a new batch and you train on a new batch starting from the pretrained model, not from random weights.

Ok my bad I misunderstood what you meant, so the flow will be like that:

As long as the dependency graph is a DAG there should be no checksum problem. Here maybe what is confusing is that both 'model 1' and 'model 2' could share the same key, for example 'model.pkl', but which one would you choose ? If you choose 'Model 1 + 2', then 'Model 1'  will be inaccessible. It's a problem of hiding an intermediate result, there is no checksum problem here.",2019/12/5 9:05 AM,26,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"By nature of dvc both models will share the same filename, they will go in different git revisions though. Batches also combine into a single dep, in current design out = f(dep), that's it, history of a dep does not affect out, with incremental training it might affect.",2019/12/5 9:15 AM,27,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"Ok now I understand, there is 'currently' no way to distinguish between:

and

But I am not sure to understand what 'currently' means here:

Batches also combine into a single dep

What batches, are they already implemented ? Are we talking about the current DVC status or the possible implementation of incremental situations ?
IMHO the use case you describe already works with DVC: you prepare 'model 1' with the data you have, then when you have more data you build a new 'model 1 + 2' from 'model 1' plus the new data.
But as you said, if there are lots of batches,  maybe some sugar can be added to hide 'model 1' and expose 'Model 1 + 2'.",2019/12/5 9:54 AM,28,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"
What batches, are they already implemented ? Are we talking about the current DVC status or the possible implementation of incremental situations ?

You can add a dir with files into dvc, and then add some files to that dir and dvc add it again. It will have new checksum but same path, so you can rerun a pipeline with dvc repro on the new data, this will involve processing the whole thing of cause.

IMHO the use case you describe already works with DVC: you prepare 'model 1' with the data you have, then when you have more data you build a new 'model 1 + 2' from 'model 1' plus the new data.
But as you said, if there are lots of batches, maybe some sugar can be added to hide 'model 1' and expose 'Model 1 + 2'.

You mean add a new stage to produce a new model? This is a dirty non-scalable workaround) You will need to duplicate everything for that:

So you dup all outs and deps and stages. We can say that in dvc logic the data dep, might not be simply a dir of files, but a collection of batches (or a dir with some history), i.e. an incremental data artifact, then an input of a stage is also not a dir, but a collection of batches, then output will be reproducible, only to reproduce that you need to do:

We will need probably an erase history command too. We still have an out as a dep situation though.",2019/12/5 10:13 AM,29,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"I've never encountered the situation you describe: either the number of batch was small, and indeed I wanted to train Model 1 + 2 using Model 1 + Batch 2, with a tractable number of batch and a need for being able to access Model 1 and model 2 separately, or the number of batch was big enough so that I wanted to retrain on all the batches (not incremental). But indeed your use case exists and it would be a nice feature.
I don't know about the exact DVC internal mechanism, but it seems to me that you (the front user) could write a pipeline stage like this:
f(chunkN, start=f(chunkN-1, start=...))
But under the hood it would be in reality:
",2019/12/5 10:24 AM,30,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"@Suor @Pierre-Bartet either I'm missing something or the case of running the stage on all images + pre-trained model can be solved by #331 (comment) (it's already in DVC but  we don't merge docs for since don't like introducing ""virtual"" cycles into DAGs for now - so consider this semi-official).
The case from the ticket description is and a bunch of comments below is about actual Pachyderm-like incremental processing - when you run your script only on new files.
Just to clarify, which one those have you been discussing?",2019/12/6 6:03 AM,31,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"@shcheklein persist outs might help, we still need two things:

signaling to command which files are new
checking pretrained model existance and checksum as we do for deps
",2019/12/6 7:27 AM,32,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,@shcheklein : Indeed what we've been discussing with @Suor is a different kind of 'incremental',2019/12/6 7:49 AM,33,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"This issue describes our use case as well. We have raw data which is produced continuously. I intended to bin this into e.g. daily chunks, then run multiple stages of processing on each chunk, possibly using the inputs of other stages from the same time bin. My problem is that I don't want to reprocess years worth of data every day when a new file is added to the raw data, but I also don't want to manually create thousands of processing stages for every raw data file and all their children.",2020/1/28 12:26 PM,34,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"I think this depends on the what the DVC think itself to be?
For me it's a data tracking tool in training staging, and data tracking and metrics comparing help me a lot when I make some experiments to the model, after that I use other tools to deploy my model.
So I use DVC as a data tracking tool like git, not a computation engine .I don't know what kind of tool, you guys want it to be",2020/4/18 3:39 AM,35,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"One more case and request - https://discordapp.com/channels/485586884165107732/563406153334128681/718108510671601824

Hi! My current main issue with DVC is the fact that the pipelines are structured with a stage = few inputs -> a few outputs. That works great on some cases, but it fail when I need to apply the same operation on many files (tens of thousands in my case). Eg running a ML model for detecting the keypoints of a person. Basically there is no map operation. Do you know if that is on the roadmap, or if there is a github issue about that?
",2020/6/4 8:14 PM,36,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,So we might have map-style incremental processing and reduce-style one. The map seems like a lot simpler should we separate it?,2020/6/5 8:19 AM,37,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"@Suor it seems to me that both map or reduce would require some general mechanism first - how to apply certain logic only to new files. The way that logic being applied and actual output is being produced seems to be a simpler question to solve (and we even have some hacks like persistent outputs). Unless I'm missing something. Could you clarify, why do you think they are inherently different?",2020/6/6 9:28 PM,38,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"I am the author of the comment above on Discord:

One more case and request - https://discordapp.com/channels/485586884165107732/563406153334128681/718108510671601824

I think it's also interesting to look at that use-case in relation with:

""dvc: consider introducing build matrix"" #1018 (already mentioned)
""How to manage repetitive dvc run commands (like unpacking of many zip files) #1119
""Reconfigurable pipelines"" #1462
""Taking a step back and looking at the big picture"" #3549

A potential different workaround would be to allow pipelines to create pipelines, so a ""master"" pipeline could create N different pipelines (one per file to process), and those would be executed one after the other. This would also allow very flexible workflows with dynamic pipeline reconfiguration based on scripts. ""ML experiments and hyperparameters tuning"" #2799  could be related.  I can't find any issue related to that one, is it hidden or should I create it?",2020/6/9 6:46 PM,39,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,@MatthieuBizien Please feel free to create an issue for that :),2020/6/9 7:15 PM,40,1,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"
I think this depends on the what the DVC think itself to be?
For me it's a data tracking tool in training staging, and data tracking and metrics comparing help me a lot when I make some experiments to the model, after that I use other tools to deploy my model.
So I use DVC as a data tracking tool like git, not a computation engine .I don't know what kind of tool, you guys want it to be

I just want to use it for what its name stands for: ""Data Version Control"". The difficulty is that since we are talking about data, it can be so big that we don't want to actually commit it or have all of it on our computers (otherwise we would just use git and commit / push / pull / clone everything). Going from code (git) to data (dvc) means you want to be able to deal with only a subset of the full repository:

You want to only partially commit the data (just its hash)
You want to be able to have only a subset of the data on your computer (just its hash and a chosen subset of the full files, or even none of the full files)
You want to be able to process only a subset of the data

I don't want it to be a computation engine but that is a direct consequence of this.
If you have to rerun everything on the whole data every time you make the slightest change, IMHO that breaks the purpose of a data version control system i.e. point 3. is the missing feature.",2020/6/10 2:40 PM,41,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"I hope this suggestion adds something to the above thread.
Say I have 1M files in the directory ./data/pre, and a python script process_dir.py which goes over each file in ./data/pre and processes it and creates a file in the same name in a directory ./data/post.  e.g. ./data/pre/123.txt --> ./data/post/123.txt
As we all know, if I define a pipeline:

then dvc repro will erase all content of data/post and re-run the script from scratch if I add or remove even one file from data/pre, which unfortunately means that those 1M files will unnecessarily be processed again - even though we keep cached copies of the outcomes.
suggestion: if we were able to define a rule that connects directly in the DAG pairs of data/pre/X.txt --> data/post/X.txt in the context of the process stage, then when can adjust the process stage in the pipeline as follows:

identify which file-pairs haven't changed and remove those files to a temp dir
run the process stage as you normally would.
move the file-pairs from the temp dir back to their original locations.

It's like we are enhancing the DAG to include more local dependencies (and independencies), between input files and output files.",2020/7/17 7:22 PM,42,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"@jonilaserson the discussion here circles around that in a way. Your use case is however is a subset of whatever we discuss. It also has a workaround employing an undocumented --outs-persist feature, see above.",2020/7/20 9:51 AM,43,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"I'm using DVC for a project which processes continually produces time-series data in a series of steps. I described my use case above a little, but maybe I'll mention how I'm using it now.
My current system wraps DVC in code which produces DVC jobs based on the input data: it scans the input directories, creates a DVC file describing a job for each file that it finds unless a DVC file is already present and then runs DVC repro to compute any steps which aren't yet present.
The benefits of this structure are that, once the wrapper step has run, the repository is a fully valid DVC repository which doesn't need any special tool beyond DVC itself to interact with. In order to make this work, I needed to bin my data into preset chunks and have a way of mapping from inputs to outputs (since those outputs are then used in subsequent steps). In my time-series application, I did this by mandating filenames like ""20200720_stepA_1.csv"".
To bring this functionality into DVC itself, I'd imagine a couple of changes.
Meta jobs
I found the generation of DVC jobs to work quite well. You could imagine a ""meta-job"" which defines how input data should be processed to output data, and can then be used in later steps. Meta jobs can form their own DAG, even if there's no input data yet.
Running a metajob creates normal DVC jobs for each valid combination of input chunks present. A chunk is present if either

it depends on raw files (identified somehow in the metajob config) which are present
it depends on outputs from previous metajobs in the metajob DAG, whose input chunks are all present

Metajobs can also depend on normal DVC jobs/files, in which case the dependency is passed to all generated jobs. All metajobs are run before normal jobs, to generate a set of normal jobs for all available input data. The normal jobs can then be run in the same way as they currently are.
Step to step mapping - inputs
The step-to-step mapping would need to be configurable. This would need to be done such that subsequent steps can use the outputs of previous ones. You'd need to decide ""do I always map a single step output to a single step input?"" I.e. if my input source (call it ""stepA"") has data like this:

And ""stepB"" depends on ""stepA"", should ""stepB""  be called three times (for the three days, with all inputs for a given day passes as inputs to stepB), six times (for each file, passed individually) or once (easier implemented by passing the whole folder, as in the current version of DVC).
You might achieve this by e.g. defining a regex for inputs. For stepB you might store the regex ^(\d{8})_stepA_\d.csv$ in your step config. This matches all the desired inputs.
For case 2 (stepB should be called six times), this would be enough.
For case 1 (stepB should be called three times, with grouped inputs) you might also specify

where this tells DVC to group by the contents of capture group 1 in the regex (i.e. the timestamp).
Step to step mapping - outputs
The outputs would also need defining. ""stepB"" might only have a single output, with the form $1_stepB_0.csv. This is a regex replacement string, and should resolve to a specific, single filename for any of the inputs which match the input regex.
Input passing
Since your steps are being called with different inputs each time, you'll also need some way of passing these inputs to the command that's being called. That might involve a substitution token in the command, like python process_files.py %INPUT_1% or, for a variable-length list of input files, python process_files.py %INPUTS_1% with an additional field input_1_format: ""-f %INPUT% "", resulting in a call like python process_files.py -f file1.csv -f file2.csv -f file3.csv.
That's a bit ugly right now, I'm sure some thought could make it more elegant.
Summary
That's a bit of a brain-dump and I'm sorry if it's not totally coherent. I thought I'd document my experience with adding this kind of functionality on in case it informs the requirements for adding this into DVC itself.
I'd summarise my suggestion by:

Define metajobs which can generate DVC jobs for batches of available input data
Let these metajobs identify which input data they should be called with, and what output this step should produce in response
Have metajobs generate normal DVC jobs for all possible combinations of inputs (according to the metajobs' specs)
Process the resulting network of DVC jobs in the normal way, committing the both metajob DVC files and the generated DVC files to the repo (metajobs would contain a hash of all the input filenames / output dvc jobs).
",2020/7/20 10:01 AM,44,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"I am late to this party, but I think that a better way to deal with this would be to start with a file containing names of files to be processed.
A processing step would look at this inventory file and compare it to the inventory file recording files processed (letting that file survive would be a change). All files mentioned in the inventory file and not mentioned in the processed inventory would require incremental processing. The output of the processing step would be a new output inventory to be used in the next incremental step.
Version controlling the input, processed inventory and output files would be done outside of the context of the processing step rather than marking them as dependencies or outputs of the processing step. Only the input inventory would be a dependency and only the output inventory would be an output of the step.  Back fill could be triggered by a (version controlled) change to the processed inventory.
This approach also allows for the relationship between input files and output files to not be one-to-one. This is useful if a sketch of all files processed in a single batch is put out as a single file. Since sketches are typically much smaller than the overall data, large numbers of sketches can typically be combined non-incrementally for global aggregates.
The only extensions here would be

a capability to build an input inventory from a directory (this could be a processing step with the directory as an input and the results of ls as the output)
a capability to declare an incrementally updated state output that is read at the beginning of a processing step and checked in after the step (this might just be done with an explicit check-in after the processing step completes if DVC is too opinionated about deleting old output files).
a capability to check in all new files in an output directory. Again, this could easily be done explicitly rather than automagically.

It would be desirable if memoization were possible. Thus if some branch somewhere has processed the same input batch with the same code, we should be allowed to assume that the outputs will be the same and simply check them out. The effect of this would be that back-fill with a trivial new version of a processing step that actually doesn't change semantics (think formatting or comment changes) could proceed nearly instantaneously.  Likewise, if you have a new version of a DAG you want to stage, those aspects of work that are identical to the production version could be short-circuited by checking out the output files from the production runs.
Does this make sense?",2021/8/24 9:05 PM,45,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5917,2017/12/5 2:38 PM,"Additional discussion here: https://discuss.dvc.org/t/need-to-build-non-ml-data-pipeline-is-dvc-good-fit/849/8
Net-net, I think that this can be done by allowing small state files for processing steps and a helper that updates a ""new files"" output. These are not a circular dependency since they

do not compromise the topological sort for task ordering
are unwound by the version control on the state

As such, reproducibility and idempotency are not compromised.
Further, there is no bright line between data preparation or engineering and machine learning. Speaking from a LOT of experience, getting both right and both integrated is really crucial and DVC could really shine as an integrated path for both tasks. Speaking based on recent conversations in $dayjob, Pachyderm will eat DVC's lunch without something like this.",2021/8/25 3:21 PM,46,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,"@casperdcl , I'm not sure how much benefit would bring, giving that it is not that hard to create a docker image for DVC: docker run --name dvc -ti python pip install dvc && docker container commit --change 'CMD [""dvc""]' dvc dvc
Also, testing this would be the same as testing DVC on a linux machine (or at least, it should be)
I doubt that users want to use it as a base image, since it doesn't provide anything else than DVC.
I'd prefer to not maintain this one, to be honest",2019/11/10 7:37 PM,1,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,"I would also argue, that when doing some data science stuff in docker, its probably easier to install DVC in your own image, rather than try to adjust DVC image to you requirements (like installing TF/pytorch/...).",2019/11/11 12:46 PM,2,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,"@pared that was my point about


also would make it easier for end-users to incorporate into their own docker images


as in people could copy-paste from our docker file into theirs...
I assumed it's more complex than just a pip install to get all the features (at least some apt-get installs as well?)",2019/11/11 12:50 PM,3,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,"@casperdcl ok, I didn't quite get it.

as in people could copy-paste from our docker file into theirs...

That would surely help to build custom image.",2019/11/11 12:52 PM,4,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,"@casperdcl Hm, apt-gets would depend on the base image that you are using. If it is absolutely bare then yeah, you will need to install python and whatnot. But for regular things like ubuntu you don't have to install anything special, except, I guess, git. We have a docker image that we are using for testing here https://github.com/iterative/dvc-test/blob/master/docker/ubuntu/16.04/Dockerfile . Not sure if we still need to install libffi explicitly _",2019/11/11 1:33 PM,5,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,"@efiop the setup.py file seems to imply more deps are required - I was referring to a full pip install dvc[all,ssh_gssapi,tests]",2019/11/11 2:58 PM,6,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,@efiop can confirm libffi not required on ubuntu:18.04,2019/11/11 4:11 PM,7,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,"@casperdcl Ah, got it. yeah, gssapi requires some dev tools to compile stuff as well as tests, so the dockerfile for that would be more complicated. We could provide it in the docs maybe? I'm not quite sure about building and testing it. When used for regular tests, it would always run linux inside, instead of running on the host system, which is a problem, as we already have a lack of native-testing on windows and osx, and that might prevent us from discovering bugs when developing. Though a nice thing about it is that you don't have to setup a test env on your machine, that is true __",2019/11/11 5:35 PM,8,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,"Yes I did start making a few flavours of docker images for testing (alpine, ubuntu LTS, 2.7, 3.6 etc) ages ago which are probably sitting in a git stash on one of any number of machines. maybe.
Now I just use a conda env for dvc testing.",2019/11/11 5:39 PM,9,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,btw totally fine with this issue being closed - don't actually have any strong opinions about it.,2019/11/11 10:41 PM,10,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,"@casperdcl No reason to close it. Docker images(or at least dockerfiles) would be nice to have, for sure. __",2019/11/11 10:55 PM,11,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,"
Provide docker images

I just came here looking exactly for that.
Every time I see a comment like:
""It's highly recommended using virtual environment or pipx (on Python 3.6+) to encapsulate your local environment.""
I instantly go looking for a docker file for me to easily test the software.
That is because I use different software (mostly R), and don't use python outside docker (because python environment libraries change a lot, and nobody seems to agree which one is best - conda, virtualenv, pyenv, pipenv etc - which, to complicate further, have different functionality).",2019/11/18 3:54 PM,12,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,"@nettoyoussef Thanks for the feedback! Do you need pre-built images, or a Dockerfile in our docs would do?",2019/11/18 9:39 PM,13,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,"@casperdcl thank you for this idea!
I agree with @pared and @MrOutis that it is easy to create your own docker image and it might create additional supporting overhead for us.
However, prebuild docker gives value to users and @nettoyoussef showed some example. It can attract users' attention and improve usability despite a simple implementation.
But then documentation plays the major role. Can we make a good documentation page or even a small blog post that explains the motivation behind using docker image instead of installed tool and when it is needed? Why don't we start with doc/blog-post and then implement the docker image.",2019/11/19 6:44 AM,14,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,"
@nettoyoussef Thanks for the feedback! Do you need pre-built images, or a Dockerfile in our docs would do?

Thank you for being so helpful.
Personally, a Dockerfile would suffice. The community, however, maybe would benefit more from a pre-built image.
Instead of building one from Ubuntu, you could make your life easier and, e.g., start from a miniconda image. I think this can be easy to automate, and maybe you can even delegate this to other teams - a partnership with rocker for example.
Since from what I read DVC is not attached to any particular library/language it also makes sense to separate concerns, i.e., you can use the same DVC image with any project, instead of installing it with any particular environment.
It also makes easier to implement it in existing projects - since you don't have to rebuild the images just to try it.",2019/11/19 10:12 AM,15,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,"Here's an initial draft to add to DVC's docs a section about using Docker: iterative/dvc.org#811
Feel free to edit it accordingly __",2019/11/22 6:23 PM,16,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,"After several iterations trying to provide useful information for Docker users, there's no agreement in what should be that info and the way we should present it (e.g. provide an image? docs are enough?)
Let's keep the discussion open for now :)
Thanks a lot, @casperdcl , @shcheklein , @jorgeorpinel , @efiop for reviewing the previous efforts.
If you could dump your opinion on this one it would help a lot to reach a conclusion.",2019/11/26 6:27 PM,17,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,"Well, like you said in iterative/dvc.org#811 (comment)

The only essential parts are FROM python and RUN pip install dvc

So I don't see the point of providing such a simple Dockerfile that anyone familiar with Docker can easily create. Maybe just a small section in the installation guide to provide Docker tips such as using python:3.7 and dvc[all].",2019/11/26 8:09 PM,18,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,"There are two DVC-docker images for CI/CD project which are going to be maintained:

https://hub.docker.com/repository/docker/dvcorg/dvc-cml
https://hub.docker.com/repository/docker/dvcorg/dvc-cml-gpu

The docker files code is here (gpu PR is not merged yet): https://github.com/iterative/dvc-cml
Does it make sense to extend these images to cover the needs of this issue? What needs to be added or changed in the images?",2020/3/29 5:53 AM,19,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,"maybe I'm missing something but it looks like they're using index.js (node) rather than the Dockerfile (docker). Seems like the GH Action should really use the docker image (e.g. https://github.com/casperdcl/covid-19-box).
On a related note I like where this is heading https://github.com/iterative/dvc-cml/wiki/Tensorflow-Mnist-for-Github-Actions",2020/3/29 4:00 PM,20,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,@casperdcl it is using docker files. Index.js is here just support GH users who don__ want or cannot use docker. You can find it in the workflow files.,2020/3/29 9:11 PM,21,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,"Right. Seems a bit odd to provide a nodejs action for public use via the standard uses:  syntax, but in our workflow use our own docker version. Unrelated to this issue (#2774) though.",2020/3/29 10:08 PM,22,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,@casperdcl what would be your suggestions for that project? How to organize it in the right way?,2020/3/31 5:46 AM,23,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,"
In action.yml, use Dockerfile
Move as much of the other non-essential root clutter to subdirs
The Dockerfile's entrypoint itself can use node and/or any other software that users demand support for
In our workflow,

use node/black/flake8/etc directly to run linting/tests (as currently)
uses: ./ to run/test the (docker) action



Advantages:

a single CI run of our provided action installs and uses/tests everything (docker wraps node, etc.)
local installs and our workflow tests can continue to manually install prerequisites and use just node (as currently)
both cloud (other people's workflows as well as our own) and local installs can use the convenient docker wrapper/action (with all of its advantages such as dependency management & reproducability)

Surely should discuss this in an issue on that repo though?",2020/3/31 9:22 AM,24,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,"@casperdcl

Move as much of the other non-essential root clutter to subdirs

you mean prettier configs, etc, etc?

The Dockerfile's entrypoint itself can use node and/or any other software that users demand support for

could you elaborate?

uses: ./ to run/test the (docker) action

same here, could you elaborate?",2020/4/1 12:00 AM,25,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,"
you mean prettier configs, etc, etc?

er, just a general principle removing as much as possible. Some tools expect files to be in the root so we're mostly stuck there, ofc.

you mean prettier configs, etc, etc?

It's cumbersome for us to maintain multiple, well, entrypoints to our actual code. If we want to support both docker and directly running in node, it's best to have docker be a thin wrapper around node (i.e. in the Dockerfile, use ENTRYPOINT npm, CMD run or similar).
This way we can use the docker wrapper for the action. Thus running the action will test our docker wrapper as well as the underlying entrypoint. The additional advantage is that all deps are guaranteed installed in the docker container.",2020/4/2 6:17 PM,26,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,"I feel that I'm still missing something :)
Docker entrypoint for the image we provide already does this, right? It already runs Node. And image itself has JS bundle pre-installed.
There are no very strong reason to support direct docker-less action, but it's a separate topic.",2020/4/2 10:57 PM,27,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,"yes I was making several minor points, I think we're all missing small things but nothing major :)",2020/4/2 11:11 PM,28,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,"Hi! we are pushing to use the code through Docker, the main reasons are:

Complexity abstraction (The container acts as a wrapper of the whole stack)
User experience is the same (or very close) in Gitlab and Github
Stack is preinstalled so its faster to execute
Less friction and ready to go for GPU
The image  will also act as a self runner, again, with the same user experience in Gitlab and Github.

The MAIN reason why the js action is maintained is because there is no way MACOS or WINDOWS can run specific native tools in docker. So if a user would be using i.e. CoreML with Xcode the only way to make this work available for them is through the purely Github Js action and only in Github",2020/4/6 5:30 PM,29,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,"Hi, we're using the dvcorg/cml image, but it's creating a pain point that there are no version tags, only latest. It would be great if images were tagged by version so we could pin it and enforce the same version as in local dev environments.",2021/1/4 12:15 PM,30,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,"Hi, @hsharrison. Could you please mention your issue in the CML's repo, specifically on iterative/cml#217? This way, it'll be easier and faster for you. Thanks.",2021/1/4 12:30 PM,31,1,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,"__ @hsharrison feel free to open a ticket there. Could you please provide also whats your pain point?
We decided to not tag it (despite that we have already a ticket for that created by me) since we always try to do CML backwards compatible.",2021/1/4 2:22 PM,32,,(II) External Repository
https://github.com/iterative/dvc/discussions/5934,2019/11/10 6:15 PM,"My mistake, sorry for the noise.",2021/1/4 2:24 PM,33,,(II) External Repository
https://github.com/iterative/dvc/discussions/6876,2021/10/27 2:58 AM,"Definitely a bug on our side. Need to take a closer look. In the mean time, this works fine for you, right? Just visually looks odd?",2021/10/27 10:25 PM,1,,(I) Reporting a Bug
https://github.com/iterative/dvc/discussions/6876,2021/10/27 2:58 AM,Create an issue for it?,2021/10/30 12:59 AM,2,1,(I) Reporting a Bug
https://github.com/iterative/dvc/discussions/7877,2021/5/27 9:47 AM,"_ It's an interesting idea. I'm not sure it's a high priority, but having more human-readable names seems like it would be nice. There are at least a couple complications, like the fact that experiment names should be unique, which this doesn't guarantee, and there can be multiple -S/--set-param values passed, but there are probably workarounds.
One potential downside is that if a user is tuning the same parameter across many experiments, the first part of each experiment name will look the same, which could make the table hard to read and mean that more characters are needed to apply or otherwise reference a specific experiment.",2021/5/27 7:14 PM,1,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/7877,2021/5/27 9:47 AM,"Also quick note. Experiments are not always about changing parameter values. They are also about changing data and/or code. (It's not reflected well in the table and should be improved, but it's a separate story).
Btw, how do we guarantee uniqueness now if I modify a comment in a python file that is not even part of the pipeline and run an experiment again?",2021/5/27 7:33 PM,2,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/7877,2021/5/27 9:47 AM,"I also had considered this in the past. But didn't found a good answer to it.
The main difficulty of this is exp names, good representative names for each experiment are not easy to get. There are several ways to achieve it.
1 . Let users give names, but they may not willing to do so.
2. Autogenerate by some rules, quite hard for there might be serval params difference between exps. Which one is most important? The most representative names might change after the users do some additional experiments to make things even worse.
3. Train a naming model for this task, and let users amend it.  (I recommend this one)",2021/5/28 8:22 AM,3,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/7877,2021/5/27 9:47 AM,"IMHO some basic heuristics may work:


I don't think users will change more than two parameters per
experiment. These can be considered exception.


Any pipeline changes in dvc.yamls can also be detected but experiment management probably will rely more on --set-param than updating the pipeline. For a parameter in the form of model.param=value, the experiment name may be like exp-param=value-66dc. For two parameters, like exp-param1=value1-param2=value2-4cc3 and more than two parameters, only the suffix hash value may change. The user is expected to make a decision on these experiments and dvc exp apply before proceeding.


Changes in code and data files can be tracked by the first 4 character of their hash value, e.g., if the user modified src/mymodel.py and it has a new hash value, the new experiment name may be similar to exp-mymodel-12cd-77db, mymodel-12cd being the new hash value of the file.


It may not be feasible to track code/text files not included in dvc.yaml.


We have pipeline/parameter elements from HEAD and we also have corresponding elements in the current experiment, either modified by --set-param or by manually changing the DVC files. It should be possible to get a diff between these.",2021/5/28 7:47 PM,4,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/7877,2021/5/27 9:47 AM,"
Btw, how do we guarantee uniqueness now if I modify a comment in a python file that is not even part of the pipeline and run an experiment again?

That's a good question but probably if something is not the part of the pipeline, it's out of scope for change detection. I'll test this.",2021/5/28 7:49 PM,5,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/7877,2021/5/27 9:47 AM,"
I don't think users will change more than two parameters per
experiment. These can be considered exception.

Yes, we do not change serval parameters one time, but we might change param(a) in the first exp then param(b) in the second, and finally, the last exp might have serval changed params. This is what I do in the past.",2021/5/30 4:01 AM,6,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/7877,2021/5/27 9:47 AM,"I don't think improved naming requires having a solution for every type of experiment. As @iesahin mentioned, current behavior could still be the default in edge cases.
I'd be more concerned whether any solution that requires checking for uniqueness could slow things down.
For comparison, wandb chooses random human-readable names like valiant-oath-1 presumably because they are easier to read and remember than random strings.",2021/5/31 1:45 AM,7,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/7877,2021/5/27 9:47 AM,"A few questions:

do we want (and do we guarantee now) names to be globally unique (e.g. if multiple people start pushing/pulling them)
how do we after all generate names now if pipeline files stay the same (assuming other changes in the workspace)


For comparison, wandb chooses random human-readable names like valiant-oath-1 presumably because they are easier to read and remember than random strings.

I like the idea of using random human readable names. Alternative here could be something that Sentry does - it names errors like this:

it keep suffix simple and short. Since they don't expect 1000s of them - it works nicely.",2021/5/31 2:03 AM,8,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/7877,2021/5/27 9:47 AM,"
Yes, we do not change serval parameters one time, but we might change param(a) in the first exp then param(b) in the second, and finally, the last exp might have serval changed params.

This is a good point.
Does the results between these two differ:
1:

2:

As far as I know, exp and exp2 are identical. However if we remove  dvc exp apply in the first one, they are different. In that case param1 of exp2 is identical with param1 of HEAD.
So it might be better to track differences in param.yaml against HEAD instead of -S parameters in naming.
In this case, you are right @karajan1001, the user may be changing more than 2 parameters but I think it may still be possible to get most recently changed two parameters.",2021/5/31 12:57 PM,9,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/7877,2021/5/27 9:47 AM,"
I'd be more concerned whether any solution that requires checking for uniqueness could slow things down.

Uniqueness is already checked at the end, when the generated experiment name coincides with the directory name. I don't know the implementation details but it shouldn't have an effect on speed.

For comparison, wandb chooses random human-readable names like valiant-oath-1 presumably because they are easier to read and remember than random strings.

Docker uses such names for containers as well but from user POV, I think having experiments named like _units=512-activation=tanh_ is more desirable than persevering-plum-11. The latter is certainly easier to implement, though.",2021/5/31 1:08 PM,10,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/7877,2021/5/27 9:47 AM,"To chime in on this: I have just been looking to see if there was an option to tweak the 'exp-' prefix for experiments. Being able to do this could allow for better grouping of experiments to reflect changes of a significant params such as if you have a 'model_type' param for experiments when comparing architectures.
The experiment name would then still end with the hash.",2021/9/22 10:37 AM,11,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/7877,2021/5/27 9:47 AM,"@JamesQuirk Just making sure you are at least aware that you can manually name your experiments with dvc exp run -n if you want to group experiments like that. I can see how it would be nice to infer your preferred grouping, but wanted to make sure you know it's at least possible __ .",2021/9/22 3:01 PM,12,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/7877,2021/5/27 9:47 AM,"
@JamesQuirk Just making sure you are at least aware that you can manually name your experiments with dvc exp run -n if you want to group experiments like that. I can see how it would be nice to infer your preferred grouping, but wanted to make sure you know it's at least possible __ .

Yes I have seen that. But that changes the whole name doesn't it? So the custom name would need to account for uniqueness..?",2021/9/22 4:18 PM,13,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/7877,2021/5/27 9:47 AM,"Correct @JamesQuirk, so it's possible to group experiments but all the naming burden falls to the user.
If I understand, you would like to do something like give multiple experiments the same name and have dvc append some unique id to the end of each one?",2021/9/22 8:23 PM,14,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/7877,2021/5/27 9:47 AM,,2021/9/22 8:37 PM,15,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/7877,2021/5/27 9:47 AM,"@dberenbaum yes, that's what I was thinking.

Could you

?

This is a valid option but there is still chance that a random number (of finite length) could have already been used which introduces inconveniences with handling that. Using the start of the hash would be better - as dvc already does.",2021/9/23 5:06 PM,16,,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/7877,2021/5/27 9:47 AM,Makes sense as a nice feature to have. I've extracted it into a new issue: #6680.,2021/9/23 8:16 PM,17,1,(III) Reporting an Enhancement
https://github.com/iterative/dvc/discussions/7877,2021/5/27 9:47 AM,"@JamesQuirk another option might be:

which guarantees unique names for experiments taking longer than 1 second :)",2021/9/27 10:27 AM,18,,(III) Reporting an Enhancement
https://github.com/microsoft/AirSim/discussions/3844,2021/7/1 8:48 PM,"hi @jconde42,
I don't think it's a desired behavior.
Also, it's seems like the same behavior reproduce when spawning from settings.json in different position than (0,0,0).
The reason is when you call simGetVehiclePose(), it's actually calling to PawnSimApi::getPose and the inner function calls to NedTransform::toLocalNed, but in this case you want to call NedTransform::toGlobalNed.
Maybe it worth to open an issue or you can make a PR so the maintainers confirm this is not the expected result.",2021/7/12 8:31 AM,1,1,(IV) Reporting a Clarification Request
https://github.com/microsoft/AirSim/discussions/3844,2021/7/1 8:48 PM,"See my comment here. I will discuss with my team whether we want to change this behavior, but it appears this may be by design. You can work around this by using the simGetObjectPose() API.",2022/1/11 11:49 AM,2,,(IV) Reporting a Clarification Request
https://github.com/microsoft/nni/discussions/4526,2022/2/2 9:50 AM,"I believe NNI v2.6 has improved the visualization.
If upgrading NNI doesn't work for you, I believe there might be some bugs, please submit an issue.",2022/3/10 8:20 AM,1,1,(IV) Reporting a Clarification Request
https://github.com/microsoft/Recognizers-Text/discussions/2881,2022/3/3 9:01 PM,"Thanks for looking into alternatives for a solution.
In principle, there is no problem with leveraging a different regex engine. The two main issues would be performance and maintainability.
Regarding perf, a simple benchmark replacing the current engine with the new one across all languages should provide enough evidence if the change has prohibitive cost.
Regarding maintainability, it all boils down to:

its license and
how feature complete the alternative is and how active its community is.

We don't want to bet on an engine that's going to be abandoned soon or won't have bug fixes. Wrapping the new engine and only using it where necessary help mitigate this to an extent.
License-wise, we took a look at the suggested engine repo and it lacks a clear license definition for it. I've opened an issue there about it. Let's see what they say.",2022/3/4 8:33 AM,1,1,(III) Reporting an Enhancement
https://github.com/microsoft/Recognizers-Text/discussions/2881,2022/3/3 9:01 PM,"@mrussek, com.florianingerl.util.regex has added the missing license in their repo and it's MIT. Would you want to try to wrap it for the necessary Japanese cases? I'd recommend running the perf test mentioned above before that to make sure there's no major issue.",2022/3/7 10:33 AM,2,,(III) Reporting an Enhancement
https://github.com/mu-editor/mu/discussions/1351,2021/3/5 10:15 PM,"tl;dr: I managed to get coloured output in the REPL and would really like if someone else could try it and give me some feedback.
Using the latest version of friendly (formally known as friendly-traceback), I managed to get coloured output in Mu's REPL working.

I am planning to change the default ""light"" style I use so that the background would be white (instead of pale grey) and probably use a colour scheme more similar to IPython's default used by Mu.
The QtConsole used by Mu has a ""bug"" in that a flag is hard-coded to prevent bold from being ever set by users writing Python code. I have reported this bug (jupyter/qtconsole#472). [1]  To see the difference, I edited the code for Mu installed on my computer, and the result looks like the following:

With the pygments style I currently use, it does not make a huge difference. However, I plan to modify the style so that the any Python code inside text is in bold, so that they would stand out more. This will work in Jupyter notebooks but not in the QtConsole until the bug is fixed.
If one wants to use the ""run"" button instead of importing in the REPL, no coloured output is possible. I am wondering if it would be possible to change the ""widget"" used for output so that it would support ANSI escape codes for colouring, like the QtConsole currently does.
[1]  At some point, if no one else do it, I will try to submit a PR (simply changing a flag value from False to True). However, I currently have 5 different non-conda Python versions installed on my system (to do tests, ensuring that friendly works with Python 3.6 to 3.10) and am leery of installing a conda-based version as it messed up with my other versions in the past.",2021/3/8 12:32 PM,1,,(IV) Reporting a Clarification Request
https://github.com/mu-editor/mu/discussions/1351,2021/3/5 10:15 PM,"Hi @aroberge - just wanted to acknowledge your input.
Regarding the widget used for output when the ""Run"" button is clicked: That's a home grown widget (for various reasons that currently escape me, we can't use the QtConsole widget for this). So the good news is someone could add the ANSI escape code handling. The bad news is someone would have to add the ANSI escape code handling. Please remember that everyone involved in Mu is a volunteer and nobody gets paid for this, so everything is done on a best effort basis. I realise this isn't helpful for you, so please don't be disheartened. A first step for this to move forward would be for you to create an issue for it so we (as Mu devs) can triage and discuss the best way to move forward (and please don't hesitate to join in with the discussion).
Thank you... and it's wonderful to see all your hard work on friendly coming together. It's a really great piece of work..! __",2021/3/10 5:07 PM,2,1,(IV) Reporting a Clarification Request
https://github.com/mu-editor/mu/discussions/1351,2021/3/5 10:15 PM,"In case anyone is interested, when used in Mu's REPL, friendly now supports themes with backgrounds that blend in with the background for each of Mu's three themes.  You can see screen captures at the bottom of page https://aroberge.github.io/friendly-traceback-docs/docs/html/mu_repl.html
This has only been tested on Windows; hopefully it works correctly on other platforms.",2021/3/29 9:25 PM,3,,(IV) Reporting a Clarification Request
https://github.com/napalm-automation/napalm/discussions/1405,2021/3/23 11:18 AM,Hey @Mondhund - this looks like a bug. Would you open an issue with all the required details?,2021/3/23 11:50 AM,1,1,(IV) Reporting a Clarification Request
https://github.com/networkx/networkx/discussions/5270,2022/1/18 10:39 PM,"This seems like a good idea to me.
I guess it should go in the module edgebfs.py.   Add the function name to the file doc/reference/algorithms/traversal.rst to connect the new function to the documentation.
:}
Thanks!",2022/1/29 3:41 AM,1,,(IV) Reporting a Clarification Request
https://github.com/networkx/networkx/discussions/5270,2022/1/18 10:39 PM,"@Talos878 I have created an issue to track this #5295, do tag the issue when you submit a PR, or you can use the issue to ask more questions about it. Thanks!",2022/2/2 12:53 PM,2,1,(IV) Reporting a Clarification Request
https://github.com/networkx/networkx/discussions/5270,2022/1/18 10:39 PM,"Hi @dschult,
bfs_edge calls generic_bfs_edges to run bfs, however in edge_bfs, the code for bfs is written inside this function. Is the change expected to break edge_bfs into two functions?",2022/2/26 9:41 AM,3,,(IV) Reporting a Clarification Request
https://github.com/networkx/networkx/discussions/5270,2022/1/18 10:39 PM,"Sorry for being MIA, @JatinSharma I have a PR that I will submit now that breaks the function but the way the code was originally written, splitting it into two comes out kinda unclean. I have had some nerve damage problems the last few weeks so I haven't been able to get around to it.
This is the branch in my forked github: https://github.com/Talos878/networkx/tree/feature-issue5270
I am can make a pull request but I would recommend someone looking over the code before submission for sure, because the generic function call pattern is just slightly different from how the generic functions work in other examples and I think it could be improved.",2022/2/26 5:31 PM,4,,(IV) Reporting a Clarification Request
https://github.com/networkx/networkx/discussions/5270,2022/1/18 10:39 PM,"Whatever you guys need to get access to what I have done so far and improve it, just let me know",2022/2/26 5:32 PM,5,,(IV) Reporting a Clarification Request
https://github.com/nicolargo/glances/discussions/1959,2021/11/25 3:59 PM,How do you configure your InfluxDB data source in Grafana ?,2021/11/26 11:06 AM,1,,(IV) Reporting a Clarification Request
https://github.com/nicolargo/glances/discussions/1959,2021/11/25 3:59 PM,"Ok reproduced...

The dashboard looks not compliant with Flux request... :(",2021/11/26 1:26 PM,2,,(IV) Reporting a Clarification Request
https://github.com/nicolargo/glances/discussions/1959,2021/11/25 3:59 PM,"This one is better:

So need an hard and long work to migrate, i just open an issue #1960 to track this.",2021/11/26 2:03 PM,3,1,(IV) Reporting a Clarification Request
https://github.com/nicolargo/glances/discussions/1959,2021/11/25 3:59 PM,"Under progress...
",2021/11/27 9:38 AM,4,,(IV) Reporting a Clarification Request
https://github.com/nicolargo/glances/discussions/1959,2021/11/25 3:59 PM,"Done !
Available in: https://github.com/nicolargo/glances/blob/develop/conf/glances-grafana-flux.json

",2021/11/28 9:47 AM,5,,(IV) Reporting a Clarification Request
https://github.com/nicolargo/glances/discussions/1959,2021/11/25 3:59 PM,Also a simple stack based on you Docker-compose: https://github.com/nicolargo/docker-influxdb2-grafana-glances,2021/11/28 10:18 AM,6,,(IV) Reporting a Clarification Request
https://github.com/NVIDIA/NeMo/discussions/3026,2021/10/20 5:23 PM,"Dali currently does not support tarred dataset support, so in an hpc env where network communication is non negligible, it is advised to use tarred dataset. On the other hand, when you want speed of training on a single machine or single node training, Dali will be much better as long as disk is available locally so there is not much network bandwidth used",2021/10/20 6:32 PM,1,,(III) Reporting an Enhancement
https://github.com/NVIDIA/NeMo/discussions/3026,2021/10/20 5:23 PM,"Nice, great to hear!
Would there be any benefit using Dali on a single machine w/ multiple vs. a single GPU and whether the dataset is tarred or not?
On a similar note; have you potentially come across the following error when using Dali on multiple GPUs?

Where X and Y are GPU ids.
This happened on a 8x V100 machine w/ PyTorch 1.9.1, NeMo 1.3.0, and Python 3.8 on Ubuntu 20.04.
Can open an issue if you can reproduce.",2021/10/21 2:00 AM,2,1,(III) Reporting an Enhancement
https://github.com/onnx/onnx/discussions/3152,2020/12/7 12:10 PM,This is a converter issue. Please open an issue in converter repo https://github.com/onnx/keras-onnx/issues,2021/1/5 11:43 PM,1,1,(II) External Repository
https://github.com/orgs/python-poetry/discussions/3929,2021/4/12 7:04 PM,"Looks like they release only eggs for 1.0.2. However, 1.0.1 has a tarball and should work. Maybe try poetry add get-docker-secret@1.0.1 and raise an issue on the project perhaps.",2021/4/15 4:33 PM,1,1,(II) External Repository
https://github.com/orgs/twbs/discussions/30688,2020/4/29 6:17 PM,"Nope the words here are intentional and correct. There was a PR about this, and this would be more appropriate as an issue and not a discussion :).",2020/5/3 4:52 PM,1,1,(III) Reporting an Enhancement
https://github.com/orgs/twbs/discussions/30833,2020/5/14 7:53 PM,"Please open an issue with a reduced test case (please read and follow the issue template).
FWIW, your second code block is useless: href is for links (so either <a>  or <link>).",2020/5/15 7:39 AM,1,1,(IV) Reporting a Clarification Request
https://github.com/orgs/twbs/discussions/30833,2020/5/14 7:53 PM,"Without knowing more about your setup, this likely has something to do with how you've setup Bootstrap and your project. Make sure the JS is included, your HTML correct, etc.",2020/5/15 7:54 PM,2,,(IV) Reporting a Clarification Request
https://github.com/orgs/twbs/discussions/31618,2020/9/9 3:54 PM,"nice catch @coliff __
IMO it should be an issue",2020/9/9 4:39 PM,1,,(IV) Reporting a Clarification Request
https://github.com/orgs/twbs/discussions/31618,2020/9/9 3:54 PM,I just went to open an issue now and see that one was opened yesterday (#31616) - which looks like it has a PR (currently unmerged) #31115,2020/9/10 6:24 AM,2,,(IV) Reporting a Clarification Request
https://github.com/orgs/twbs/discussions/31618,2020/9/9 3:54 PM,@coliff IIRC the issue was fixed in #30928. Please try the latest main branch to confirm.,2020/9/10 8:59 AM,3,,(IV) Reporting a Clarification Request
https://github.com/orgs/twbs/discussions/31618,2020/9/9 3:54 PM,"thanks @XhmikosR  - just tested this with the main branch JS now and it's hugely improved... but there's still a slight flicker when you hover over the edges of the paths of the SVG. I made a new CodePen to show. (it flickers when you scroll off or on to the twitter bird within the square)
https://codepen.io/coliff/pen/wvGmpaE",2020/9/10 10:16 AM,4,,(IV) Reporting a Clarification Request
https://github.com/orgs/twbs/discussions/31618,2020/9/9 3:54 PM,"True, not sure what the cause is, though. Maybe @tkrotoff has any ideas.",2020/9/14 6:21 AM,5,,(IV) Reporting a Clarification Request
https://github.com/orgs/twbs/discussions/31618,2020/9/9 3:54 PM,"Also, better make a new issue. Discussions are not meant to be used for such things.",2020/9/14 6:27 AM,6,1,(IV) Reporting a Clarification Request
https://github.com/orgs/twbs/discussions/31618,2020/9/9 3:54 PM,"@XhmikosR @coliff I don't think there is a solution here.
If you remove everything Bootstrap related and just keep regular title=""..."" you get the same issue: https://codepen.io/tkrotoff/pen/XWdYgVP
It seems like when hovering the SVG background it creates a tooltip, then when hovering over SVG <path> it destroys previous tooltip and creates another => flickering


Chrome 85: ""bug""
Firefox 80: tooltip (title=""..."") works differently so the ""bug"" is not applicable
WebKit 2.28.4 (via GNOME Web 3.28.6) : no ""bug"", it works fine
",2020/9/14 8:17 AM,7,,(IV) Reporting a Clarification Request
https://github.com/orgs/twbs/discussions/31618,2020/9/9 3:54 PM,"i'll hazard a guess that adding something like pointer-events:none to the SVG will make it ""transparent"" to mouse events and allow the tooltip stuff to work correctly",2020/9/14 11:55 AM,8,,(IV) Reporting a Clarification Request
https://github.com/orgs/twbs/discussions/31618,2020/9/9 3:54 PM,Please make a new issue. We can't track discussions.,2020/9/14 12:04 PM,9,,(IV) Reporting a Clarification Request
https://github.com/orgs/twbs/discussions/31618,2020/9/9 3:54 PM,Issue: #31646,2020/9/14 7:33 PM,10,,(IV) Reporting a Clarification Request
https://github.com/orgs/twbs/discussions/31618,2020/9/9 3:54 PM,Locking this since the issue is now open. Please punt further comments there :).,2020/9/14 8:48 PM,11,,(IV) Reporting a Clarification Request
https://github.com/orgs/twbs/discussions/32623,2020/12/27 4:28 PM,"RTL dist CSS files are post-processed from LTR dist CSS files, meaning that you first need to make your custom build (dropping components) from Sass sources for LTR, then run RTLCSS by yourself to output the RTL files.
This is explained in our docs __ut might probably be made clearer_ and mostly depends on Sass customization. Feel free to open an issue or a PR if you have any improvement to suggest :)",2021/1/4 1:56 PM,1,1,(III) Reporting an Enhancement
https://github.com/payloadcms/payload/discussions/70,2021/2/16 4:17 AM,"I was able to recreate the bug also!

I'm looking in to this issue right now. I assume it has to do with the rich text field. I've opened an issue for the bug here: #71",2021/2/16 1:46 PM,1,1,(I) Reporting a Bug
https://github.com/pybind/pybind11/discussions/3506,2021/11/24 2:29 PM,"Two things.


This does look like a bug, and it isn't immediately obvious to me what is happening here.  The copy address being wrong is almost certainly the issue, but why it is wrong is not obvious.


Your binding code isn't correct for what you're trying to do; what you have here is an owned reference which requires a little extra binding work to tell pybind about how to handle it:



That reference_internal does two things:

it makes pybind reference the returned value without taking ownership.
it tells pybind that the return reference is something that is managed as part of the parent, so it applies a keep-alive that keeps the parent alive as long as something in Python is still referencing a child.
",2021/11/28 12:51 PM,1,,(I) Reporting a Bug
https://github.com/pybind/pybind11/discussions/3506,2021/11/24 2:29 PM,"Thanks @jagerman,
After noticing this issue, I started to use reference_internal policy, but yet wanted to understand the source of the issue.
I'll open a bug regarding this topic.",2021/11/29 6:15 AM,2,1,(I) Reporting a Bug
https://github.com/pycaret/pycaret/discussions/1231,2021/5/6 6:30 PM,"@pit9921 Not yet. Feel free to log an issue and we will tag it as an enhancement.
Thanks for suggesting. Looks like a great project and integration opportunity.",2021/5/11 1:24 AM,1,1,(III) Reporting an Enhancement
https://github.com/pycaret/pycaret/discussions/1830,2021/11/9 8:01 PM,"@brunobarella - Sorry, I had to delete the comment from the FAQ to keep it clean. I made an issue out of it instead.
You will need to make the model sktime compatible. Here are the extension examples from sktime. Once you make it compatible with sktime, you can add the model to pycaret's time series module. Hope that helps.",2021/11/9 8:04 PM,1,1,(IV) Reporting a Clarification Request
https://github.com/pycaret/pycaret/discussions/2039,2022/1/9 12:00 PM,@avryzhov Can you please open an issue on this? That may be a more appropriate place to answer this question.,2022/1/14 3:19 PM,1,1,(IV) Reporting a Clarification Request
https://github.com/pycaret/pycaret/discussions/2443,2022/4/19 2:41 PM,"@debdarsan Good observation. I am glad someone is examining these in detail :)
The idea with CdsDt models was that even if the model is stationary, performing detrending (with default order 1) would likely not harm as the result would still be stationary. One could argue that in this case, the order should be 0. My problem with using ADF test to make any automated decisions like this is that ADF test is a low-power test and can give false results more often than expected.
Also, another argument for this would be that for example AR(1) with a high value of phi (say 0.95) can be modeled as both stationary and non-stationary models (in an automated system) without any further information about the process generating the data. This would likely produce similar fit statistics. Predictions will however be different (with one reverting to mean and the other just predicting the last point forward, but an automated system would have no way of knowing this without human interference).
But your comments are fair. Maybe this model's functionality needs to be improved further taking into account the stationarity (even if it means using the ADF test). I will move this discussion into an Issue and we can continue hashing it out there.",2022/5/8 4:51 PM,1,1,(IV) Reporting a Clarification Request
https://github.com/pycaret/pycaret/discussions/2443,2022/4/19 2:41 PM,@ngupta23 Any update on this?,2022/7/20 2:41 PM,2,,(IV) Reporting a Clarification Request
https://github.com/pycontribs/jira/discussions/1043,2021/5/16 12:49 AM,"I'd quite like to move away from passing strings into arguments when an object could be passed instead. e.g.

Would become

Would be a pretty big change from a user perspective, but I feel like this will make things more robust long term for both sides.
The user workflow may change from:
providing the email/username/accountId to the function
to:
searching for the user using the email/username, then passing the resulting User object into the function
We could provide some helper methods that may make this less painful:
",2021/5/21 7:30 PM,1,,(III) Reporting an Enhancement
https://github.com/pycontribs/jira/discussions/1043,2021/5/16 12:49 AM,making a better segregation between jira server and jira cloud,2021/8/28 11:00 AM,2,,(III) Reporting an Enhancement
https://github.com/pycontribs/jira/discussions/1043,2021/5/16 12:49 AM,"Not something that is functionally relevant but while looking through the package it would help if things like the comments were in a consistant manner, In client.py for example the 3 following styles are used (as well as some functions not commented at all)



Each of the above are for functions/generators that take arguments and have a return value.
Typing seems to be missing in places (or at least is not obvious). Improving typing may help.
Guessing this would come down to a general code clean up in general.",2021/11/1 9:06 PM,3,,(III) Reporting an Enhancement
https://github.com/pycontribs/jira/discussions/1043,2021/5/16 12:49 AM,"I think it would be great for Insight access, this is something that I am looking at implementing if it is a possibility (discussion in a currently open issue I created)",2021/11/1 9:12 PM,4,1,(III) Reporting an Enhancement
https://github.com/pycontribs/jira/discussions/1043,2021/5/16 12:49 AM,"Some general file structure would be great the main file client.py is enormous
perhaps move more functions to the resources and away from the jira client and split the resources.py file in a file per resource",2022/10/4 2:35 PM,5,,(III) Reporting an Enhancement
https://github.com/pycontribs/jira/discussions/1043,2021/5/16 12:49 AM,"I think we should also rethink the way we are testing things. It's hard for people to add tests, its hard to run them.",2022/12/4 8:32 PM,6,,(III) Reporting an Enhancement
https://github.com/pycontribs/jira/discussions/1043,2021/5/16 12:49 AM,"another feature proposal => historical issues
for example give me the issue at day x (for example you 'd like to know how the story points of a story changed over time or the assignee or other things)",2022/12/4 10:46 PM,7,,(III) Reporting an Enhancement
https://github.com/pycontribs/jira/discussions/1367,2022/4/25 1:50 PM,"I believe the right format: f""[~accountId:{your_user_accountId}]"", but might be worth checking an issue where there is a user already in the description and see what is shown",2022/5/7 2:08 PM,1,1,(IV) Reporting a Clarification Request
https://github.com/pydata/xarray/discussions/4861,2021/2/4 9:43 AM,Thanks for your report. I opened a new issue with this - I think it's more appropriate there. Unfortunately there seems to be no possibility to directly move a discussion over to the issues.,2021/2/11 9:35 AM,1,1,(III) Reporting an Enhancement
https://github.com/pydata/xarray/discussions/5167,2021/4/16 6:26 AM,@pydata/xarray thoughts? Do we have a policy? We can discuss on the call tomorrow.,2021/5/11 9:09 PM,1,,(II) External Repository
https://github.com/pydata/xarray/discussions/5167,2021/4/16 6:26 AM,we decided to document the process in xarray-contrib/xarray-contrib. In short: open a issue on that repo to request the migration.,2021/5/16 10:53 AM,2,1,(II) External Repository
https://github.com/pydata/xarray/discussions/5842,2021/10/7 9:38 AM,That definitely seems like something we should warn about! Perhaps even raise an error. Could you raise an issue with a minimal example? Also do you know what happens if you feed scipy.interpolate.interpn any NaNs?,2021/10/7 4:38 PM,1,1,(III) Reporting an Enhancement
https://github.com/pydata/xarray/discussions/6375,2022/3/17 1:55 PM,"The primary reason is that cftime.datetime objects do not implement an isocalendar method (see datetime.date.isocalendar for more details).  You could consider raising an issue in the cftime repo.  If they did, it would make it pretty easy to enable in xarray.",2022/3/18 9:30 PM,1,1,(II) External Repository
https://github.com/pyenv/pyenv/discussions/2228,2022/1/27 7:20 AM,where are the brilliant engineers that have an answer to this?,2022/1/31 11:37 PM,1,,(IV) Reporting a Clarification Request
https://github.com/pyenv/pyenv/discussions/2228,2022/1/27 7:20 AM,"If you have a problem, file an issue and follow the issue template for basic troubleshooting steps.",2022/2/1 4:22 PM,2,1,(IV) Reporting a Clarification Request
https://github.com/PyGithub/PyGithub/discussions/1790,2020/12/17 9:22 AM,"Currently, managing auto-merge is not included in the Github API. You may want to open an issue with Github to request this feature",2021/5/18 4:19 PM,1,1,(II) External Repository
https://github.com/PyGithub/PyGithub/discussions/1790,2020/12/17 9:22 AM,"Currently, managing auto-merge is not included in the Github API. You may want to open an issue with Github to request this feature",2021/5/18 4:19 PM,2,1,(II) External Repository
https://github.com/pymc-devs/pymc/discussions/5066,2021/10/9 2:49 PM,"I now see that there is now an OrderedProbit distribution as well, which isn't in the docs yet. So I guess any discussion can encompass OrderedProbit and OrderedLogistic",2021/10/10 9:43 AM,1,,(III) Reporting an Enhancement
https://github.com/pymc-devs/pymc/discussions/5066,2021/10/9 2:49 PM,"Maybe I am missing something, but couldn't you get the second parametrization by just fixing the first cutpoint to zero?
I am not entirely sure why you would want to do that though.
Is there something wrong with this?:

You need to make sure though that you only add an intercept to the model if the cutpoints have only n-1 degrees of freedom.
So maybe something like this?
",2021/10/11 7:46 AM,2,,(III) Reporting an Enhancement
https://github.com/pymc-devs/pymc/discussions/5066,2021/10/9 2:49 PM,"Thanks @aseyboldt
I finally had time to look at this again. So far, good progress on simple models. I am working through 1 group, 2 groups, then metric predictor examples, which is the same approach as the Kruschke chapter on this topic.
My only problem so far is constraining the cutpoints:

If you have time, I've got a notebook on this here https://github.com/drbenvincent/ordinal-regression/blob/main/ordinal%20logistic%20regression.ipynb. It's Model 3 which involves the constraint on cutpoints which ends up failing.",2021/10/24 6:30 PM,3,,(III) Reporting an Enhancement
https://github.com/pymc-devs/pymc/discussions/5066,2021/10/9 2:49 PM,"Ok. So we've made progress in that the issue is not about parameterisation of OrderedLogit or OrderedProbit. So in one way this discussion could be done.
That said, as @aseyboldt mentioned, some consideration to the priors could be given. I've worked up a notebook using the very latest v4 code, with OrderedProbit. Full example notebook here.
The basic issue seems to be how you deal with too many degrees of freedom. We have K levels of the data, but the model has K+1 degrees of freedom, theta_1,... , theta_{K-1}, mu, sigma.
The method that Krushcke uses is to constrain the lower and upper outpoints. A PyMC implementation is here but this is old and clunky and doesn't utilise OrderedProbit which is new. By constraining the first and last outpoints, the model should now have K-1 degrees of freedom.

The posteriors are sensible in terms of their values, but we have major divergence issues

I tried the approach outlined by @aseyboldt, which is to fix the first outpoint to zero, and use a Dirichlet distribution for the unknown outpoints. I think this then has a total of K-1 degrees of freedom because the Dirichlet will sum to 1?

Again, OK inferences in terms of numerical values, but still crazy divergence issues.

I'd be grateful for pointers:

am I on the right path?
are the models actually fine, and it's just a v4 issue?
Do the unknown outpoint parameters need to be ordered? I think they do, but adding transform=pm.distributions.transforms.ordered to the Uniform in the first model doesn't resolve divergences. I've not tried this, but if ordering would help with the Dirichlet, then maybe could calculate cumulative sum of these variables. Can Aesara do that?

If I've left out any important details, see here for full notebook example.
EDIT: Wrapping the Dirichlet variables in aesara.tensor.extra_ops.cumsum results in zero divergences

But the posteriors over unknown outpoints are suspect
",2021/11/14 6:03 PM,4,,(III) Reporting an Enhancement
https://github.com/pymc-devs/pymc/discussions/5066,2021/10/9 2:49 PM,"Created an issue, proposing a new distribution which would be very useful here #5215",2021/11/20 11:27 PM,5,1,(III) Reporting an Enhancement
https://github.com/pymc-devs/pymc/discussions/5066,2021/10/9 2:49 PM,https://journals.sagepub.com/doi/full/10.1177/2515245918823199,2021/12/7 3:35 AM,6,,(III) Reporting an Enhancement
https://github.com/pymc-devs/pymc/discussions/5066,2021/10/9 2:49 PM,https://mc-stan.org/docs/2_23/stan-users-guide/ordered-logistic-section.html,2021/12/7 3:35 AM,7,,(III) Reporting an Enhancement
https://github.com/pymc-devs/pymc/discussions/5066,2021/10/9 2:49 PM,@drbenvincent I just posted to the Discourse forums about the Kruschke-style ordered probit model here before actually seeing this thread and your latest notebook. The approaches are very similar.,2022/9/12 12:54 PM,8,,(III) Reporting an Enhancement
https://github.com/pymc-devs/pymc/discussions/5066,2021/10/9 2:49 PM,"Hi everyone - joining this thread late after struggling hard with ordinal data!
I've been working through the examples above as well as @drbenvincent's great notebooks to try and get a handle on things, but I am still very confused. I'm looking to use the same approach Kruschke uses in DBDA2 to estimate the latent mean and scale of an ordinal set of data to do some inferences on that. I've been using OrderedProbit and have been trying to use the same approach Kruschke uses by pinning the left and right extreme cutpoints, and estimating the mean, scale, and remaining cutpoints. Like the notebooks, I've been using the example dataset from DBDA2, OrdinalProbitData-1grp-1.csv, which is stated in the book as having a latent mean of 1 and scale of 2.5.
I've been using the following parameterisation (forgive hard-coding of values) which results in relatively sensible estimates (but not of the mean), but with severe divergences, and requires starting values to not crash:

`
Divergences aside, these look reasonable for the cutpoints and sigma, but not really for the mean (eta). The posterior predictive also looks very reasonable here.

Using the constrainedUniform implementation, the divergences disappear as @drbenvincent states, but now the estimates of the mean and scale are very different from 1 and 2.5, and the cutpoints are no longer on the scale of the responses:


I'm probably missing something fundamental here about OrderedProbit, but I'm not sure why having the cutpoints on their cumulative probability scale helps so much, or why the eta and sigma parameters never seem to quite reflect the values stated in DBDA2.
Any pointers are massively appreciated from this struggling Bayesian ____",2022/11/28 5:18 PM,9,,(III) Reporting an Enhancement
https://github.com/pymc-devs/pymc/discussions/5066,2021/10/9 2:49 PM,"Getting a bit of a handle on this and realised something of a basic mistake on my part. I'm still a bit vague on the use of the constrainedUniform distribution above but its clear the cutpoints are sensible. The reason the mean and scale are different from Kruschke's example is I think because OrderedProbit requires the data to start from 0 and not 1. So it makes sense that the underlying normal distribution would have different parameters, even if it gives rise to the same pattern of responses (e.g., same count of zeros as there are ones in the observed data, etc).
I guess for most purposes this doesn't matter too much. If the goal is to compare latent distributions to one another the relative difference is important, but I can imagine there are maybe some situations were it would be important to estimate the latent parameters on the precisely observed units of the data, which OrderedProbit won't allow. Am I right in thinking this or am I still missing something fundamental?",2022/11/29 1:57 PM,10,,(III) Reporting an Enhancement
https://github.com/pymc-devs/pymc/discussions/5066,2021/10/9 2:49 PM,"I now see that there is now an OrderedProbit distribution as well, which isn't in the docs yet. So I guess any discussion can encompass OrderedProbit and OrderedLogistic",2021/10/10 9:43 AM,11,,(III) Reporting an Enhancement
https://github.com/pymc-devs/pymc/discussions/5066,2021/10/9 2:49 PM,"Maybe I am missing something, but couldn't you get the second parametrization by just fixing the first cutpoint to zero?
I am not entirely sure why you would want to do that though.
Is there something wrong with this?:

You need to make sure though that you only add an intercept to the model if the cutpoints have only n-1 degrees of freedom.
So maybe something like this?
",2021/10/11 7:46 AM,12,,(III) Reporting an Enhancement
https://github.com/pymc-devs/pymc/discussions/5066,2021/10/9 2:49 PM,"Thanks @aseyboldt
I finally had time to look at this again. So far, good progress on simple models. I am working through 1 group, 2 groups, then metric predictor examples, which is the same approach as the Kruschke chapter on this topic.
My only problem so far is constraining the cutpoints:

If you have time, I've got a notebook on this here https://github.com/drbenvincent/ordinal-regression/blob/main/ordinal%20logistic%20regression.ipynb. It's Model 3 which involves the constraint on cutpoints which ends up failing.",2021/10/24 6:30 PM,13,,(III) Reporting an Enhancement
https://github.com/pymc-devs/pymc/discussions/5066,2021/10/9 2:49 PM,"Ok. So we've made progress in that the issue is not about parameterisation of OrderedLogit or OrderedProbit. So in one way this discussion could be done.
That said, as @aseyboldt mentioned, some consideration to the priors could be given. I've worked up a notebook using the very latest v4 code, with OrderedProbit. Full example notebook here.
The basic issue seems to be how you deal with too many degrees of freedom. We have K levels of the data, but the model has K+1 degrees of freedom, theta_1,... , theta_{K-1}, mu, sigma.
The method that Krushcke uses is to constrain the lower and upper outpoints. A PyMC implementation is here but this is old and clunky and doesn't utilise OrderedProbit which is new. By constraining the first and last outpoints, the model should now have K-1 degrees of freedom.

The posteriors are sensible in terms of their values, but we have major divergence issues

I tried the approach outlined by @aseyboldt, which is to fix the first outpoint to zero, and use a Dirichlet distribution for the unknown outpoints. I think this then has a total of K-1 degrees of freedom because the Dirichlet will sum to 1?

Again, OK inferences in terms of numerical values, but still crazy divergence issues.

I'd be grateful for pointers:

am I on the right path?
are the models actually fine, and it's just a v4 issue?
Do the unknown outpoint parameters need to be ordered? I think they do, but adding transform=pm.distributions.transforms.ordered to the Uniform in the first model doesn't resolve divergences. I've not tried this, but if ordering would help with the Dirichlet, then maybe could calculate cumulative sum of these variables. Can Aesara do that?

If I've left out any important details, see here for full notebook example.
EDIT: Wrapping the Dirichlet variables in aesara.tensor.extra_ops.cumsum results in zero divergences

But the posteriors over unknown outpoints are suspect
",2021/11/14 6:03 PM,14,,(III) Reporting an Enhancement
https://github.com/pymc-devs/pymc/discussions/5066,2021/10/9 2:49 PM,"Created an issue, proposing a new distribution which would be very useful here #5215",2021/11/20 11:27 PM,15,,(III) Reporting an Enhancement
https://github.com/pymc-devs/pymc/discussions/5066,2021/10/9 2:49 PM,https://journals.sagepub.com/doi/full/10.1177/2515245918823199,2021/12/7 3:35 AM,16,,(III) Reporting an Enhancement
https://github.com/pymc-devs/pymc/discussions/5066,2021/10/9 2:49 PM,https://mc-stan.org/docs/2_23/stan-users-guide/ordered-logistic-section.html,2021/12/7 3:35 AM,17,,(III) Reporting an Enhancement
https://github.com/pymc-devs/pymc/discussions/5066,2021/10/9 2:49 PM,@drbenvincent I just posted to the Discourse forums about the Kruschke-style ordered probit model here before actually seeing this thread and your latest notebook. The approaches are very similar.,2022/9/12 12:54 PM,18,,(III) Reporting an Enhancement
https://github.com/pymc-devs/pymc/discussions/5066,2021/10/9 2:49 PM,"Hi everyone - joining this thread late after struggling hard with ordinal data!
I've been working through the examples above as well as @drbenvincent's great notebooks to try and get a handle on things, but I am still very confused. I'm looking to use the same approach Kruschke uses in DBDA2 to estimate the latent mean and scale of an ordinal set of data to do some inferences on that. I've been using OrderedProbit and have been trying to use the same approach Kruschke uses by pinning the left and right extreme cutpoints, and estimating the mean, scale, and remaining cutpoints. Like the notebooks, I've been using the example dataset from DBDA2, OrdinalProbitData-1grp-1.csv, which is stated in the book as having a latent mean of 1 and scale of 2.5.
I've been using the following parameterisation (forgive hard-coding of values) which results in relatively sensible estimates (but not of the mean), but with severe divergences, and requires starting values to not crash:

`
Divergences aside, these look reasonable for the cutpoints and sigma, but not really for the mean (eta). The posterior predictive also looks very reasonable here.

Using the constrainedUniform implementation, the divergences disappear as @drbenvincent states, but now the estimates of the mean and scale are very different from 1 and 2.5, and the cutpoints are no longer on the scale of the responses:


I'm probably missing something fundamental here about OrderedProbit, but I'm not sure why having the cutpoints on their cumulative probability scale helps so much, or why the eta and sigma parameters never seem to quite reflect the values stated in DBDA2.
Any pointers are massively appreciated from this struggling Bayesian ____",2022/11/28 5:18 PM,19,,(III) Reporting an Enhancement
https://github.com/pymc-devs/pymc/discussions/5066,2021/10/9 2:49 PM,"Getting a bit of a handle on this and realised something of a basic mistake on my part. I'm still a bit vague on the use of the constrainedUniform distribution above but its clear the cutpoints are sensible. The reason the mean and scale are different from Kruschke's example is I think because OrderedProbit requires the data to start from 0 and not 1. So it makes sense that the underlying normal distribution would have different parameters, even if it gives rise to the same pattern of responses (e.g., same count of zeros as there are ones in the observed data, etc).
I guess for most purposes this doesn't matter too much. If the goal is to compare latent distributions to one another the relative difference is important, but I can imagine there are maybe some situations were it would be important to estimate the latent parameters on the precisely observed units of the data, which OrderedProbit won't allow. Am I right in thinking this or am I still missing something fundamental?",2022/11/29 1:57 PM,20,,(III) Reporting an Enhancement
https://github.com/pymc-devs/pymc/discussions/5237,2021/12/3 11:45 AM,"Yeah, I think this is quite confusing, if we can remove them that would be ideal.",2021/12/3 12:06 PM,1,,(IV) Reporting a Clarification Request
https://github.com/pymc-devs/pymc/discussions/5237,2021/12/3 11:45 AM,We could start deprecating warnings for args and kwargs in V3 and remove the LoosePointFunc in V4,2021/12/4 9:16 AM,2,,(IV) Reporting a Clarification Request
https://github.com/pymc-devs/pymc/discussions/5237,2021/12/3 11:45 AM,"More importantly, these properties/methods always compile a new aesara function which is quite slow if one wants to evaluate a model many times.
We might want to rename them to something like model.compile_logp to make this obvious and hint that this shouldn't be repeatedly invoked but cached once and then reused.
Similarly to how we have recompute_initial_point that indicates this is a costly operation.",2021/12/4 3:25 PM,3,,(IV) Reporting a Clarification Request
https://github.com/pymc-devs/pymc/discussions/5237,2021/12/3 11:45 AM,"This is done, right?",2022/1/7 8:27 AM,4,,(IV) Reporting a Clarification Request
https://github.com/pymc-devs/pymc/discussions/5237,2021/12/3 11:45 AM,"No, but we can open an issue",2022/1/7 10:49 AM,5,1,(IV) Reporting a Clarification Request
https://github.com/pymc-devs/pymc/discussions/5237,2021/12/3 11:45 AM,"Yeah, I think this is quite confusing, if we can remove them that would be ideal.",2021/12/3 12:06 PM,6,,(IV) Reporting a Clarification Request
https://github.com/pymc-devs/pymc/discussions/5237,2021/12/3 11:45 AM,We could start deprecating warnings for args and kwargs in V3 and remove the LoosePointFunc in V4,2021/12/4 9:16 AM,7,,(IV) Reporting a Clarification Request
https://github.com/pymc-devs/pymc/discussions/5237,2021/12/3 11:45 AM,"More importantly, these properties/methods always compile a new aesara function which is quite slow if one wants to evaluate a model many times.
We might want to rename them to something like model.compile_logp to make this obvious and hint that this shouldn't be repeatedly invoked but cached once and then reused.
Similarly to how we have recompute_initial_point that indicates this is a costly operation.",2021/12/4 3:25 PM,8,,(IV) Reporting a Clarification Request
https://github.com/pymc-devs/pymc/discussions/5237,2021/12/3 11:45 AM,"This is done, right?",2022/1/7 8:27 AM,9,,(IV) Reporting a Clarification Request
https://github.com/pymc-devs/pymc/discussions/5237,2021/12/3 11:45 AM,"No, but we can open an issue",2022/1/7 10:49 AM,10,,(IV) Reporting a Clarification Request
https://github.com/pypa/setuptools/discussions/3145,2022/3/2 8:07 PM,Maybe worth raising an issue over at https://github.com/pypa/packaging/issues,2022/3/14 12:04 PM,1,1,(II) External Repository
https://github.com/pypa/setuptools/discussions/3145,2022/3/2 8:07 PM,"
pypa/packaging#520
https://stackoverflow.com/questions/11887762/how-do-i-compare-version-numbers-in-python

I went with
",2022/5/7 7:08 AM,2,,(II) External Repository
https://github.com/pytest-dev/pytest/discussions/7800,2020/9/26 7:51 PM,Also see pytest-dev/py#218,2020/9/26 8:17 PM,1,,(IV) Reporting a Clarification Request
https://github.com/pytest-dev/pytest/discussions/7800,2020/9/26 7:51 PM,let's continue the discussion in the py issue __,2020/9/26 10:38 PM,2,1,(IV) Reporting a Clarification Request
https://github.com/pytest-dev/pytest/discussions/8089,2020/11/30 6:42 PM,"Hi,
Following up, I now noticed this seems to happen only when passing mutable objects to metafunc paramertize.
If we take my example above and change in pytest_generate_tests confs to:
confs = [('key1', 'val1'), ('key2', 'val2')]
Then it runs properly (same output as 5.3.5 version), but passing mutable object would cause the issue I mentioned.
Originally I passed a dict (real configuration is also a dict), but changing the above working example from tuple to list would also cause the issue, due to list being mutable:
confs = [['key1', 'val1'], ['key2', 'val2']]
Do you think it's a bug in newer pytest versions (since it worked before), or is it the expected behaviour for mutable object in paramertization and I should change how we load the configuration?
Thanks,
Idanjc",2020/12/1 4:32 PM,1,,(IV) Reporting a Clarification Request
https://github.com/pytest-dev/pytest/discussions/8089,2020/11/30 6:42 PM,"I agree that the pytest 5.3.5 seems like the better one. The mutable thing is very odd. This is probably a bug, I'll try to look into it when I get a chance. I'll open an issue referencing this so we can track it.
Edit: #8102",2020/12/5 8:11 PM,2,1,(IV) Reporting a Clarification Request
https://github.com/pytest-dev/pytest/discussions/9802,2022/3/21 11:39 AM,"
Hi quick question, is it by design that raising an exception in a pytest_unconfigure(...) hook exits 1 ? whereas the pytest_configure(...) exits 3 INTERNAL_ERROR ?

Not sure. I would expect both to return INTERNAL_ERROR actually. The discrepancy might be accidental.

i'll advised in favour of inside the session instead, i.e we need to do stuff on a runtime environment that when setup may work, but when torn down later may be problematic and or not possible

Hmm I would suggest using configure/unconfigure for pytest specific stuff, like managing some data structure used by your plugin, while leaving session start/end for other external services (not pytest related). From your use case seems like session start/finish might make more sense then.",2022/3/22 10:13 AM,1,,(IV) Reporting a Clarification Request
https://github.com/pytest-dev/pytest/discussions/9802,2022/3/21 11:39 AM,"Interesting @nicoddemus; with a simple example:

results in:

when adding:


I had a look over the code and _ensure_unconfigure(...) isn't as well guarded; so I assumed it was by design; is there a chance you think that is maybe an oversight? Happy to convert to an issue if you think it has any merit; i'm still not quite sure.",2022/3/22 10:45 AM,2,,(IV) Reporting a Clarification Request
https://github.com/pytest-dev/pytest/discussions/9802,2022/3/21 11:39 AM,"
is there a chance you think that is maybe an oversight?

That's a part of the code which I wasn't around when introduced so I can't say for sure, but I think it is definitely possible. @RonnyPfannschmidt do you have any insights here?",2022/3/22 10:48 AM,3,,(IV) Reporting a Clarification Request
https://github.com/pytest-dev/pytest/discussions/9802,2022/3/21 11:39 AM,opened: #9808 for more indepth discussions and investigation.,2022/3/22 1:01 PM,4,1,(IV) Reporting a Clarification Request
https://github.com/scikit-learn/scikit-learn/discussions/19279,2021/1/26 11:05 AM,"Thanks for the report @odedbd . Just a note: since you're calibrating a pre-fitted model, you should be careful to calibrate the pipeline on different data from the one that was used to train it - i.e. pipeline.fit and clf_isotonic.fit should not both use fake_features (I understand this is a minimal bug report that does not necessarily reflect actual usage so feel free to ignore)
@glemaitre @lucyleeow @ogrisel This looks like a legitimate issue. From what I can tell in predict_proba we can remove the call to check_array (we don't need it, the data should properly be validated in the base estimator's predict method) and replace X.shape[0] with _num_samples(X). Thoughts?
@lesteve here's an instance where converting to an issue would be helpful ;)",2021/1/27 9:11 AM,1,1,(I) Reporting a Bug
https://github.com/scikit-learn/scikit-learn/discussions/19502,2021/2/19 11:45 AM,Yes we should but we need to wait for numpy and scipy to provide their own wheels first. I opened an issue to track related github issues in parent projects here: #19137.,2021/2/19 1:55 PM,1,1,(IV) Reporting a Clarification Request
https://github.com/scikit-learn/scikit-learn/discussions/19624,2021/3/5 12:13 PM,"Sounds similar to #19279
I opened #19637 to keep track of the issue",2021/3/7 10:10 AM,1,1,(IV) Reporting a Clarification Request
https://github.com/scikit-learn/scikit-learn/discussions/19909,2021/4/17 10:19 AM,"oh, I wanted to make an issue of this. Did not know what was this discussion thing, sorry wrong place. But I can't seem to delete this thread so I let it as is and hope this gets some attention.",2021/4/17 10:20 AM,1,1,(III) Reporting an Enhancement
https://github.com/scikit-learn/scikit-learn/discussions/19947,2021/4/21 10:27 AM,"This is an issue on the KerasRegressor side that is probably not passing our estimator check and is therefore not totally compatible. I would advise to raise an issue in there issue tracker or check for related issues:
https://github.com/keras-team/keras/issues?q=is%3Aissue+is%3Aopen+clone+scikit-learn",2021/4/22 8:45 PM,1,1,(II) External Repository
https://github.com/scikit-learn/scikit-learn/discussions/20651,2021/8/1 7:02 PM,"As you see in the snippet of code of the RandomForestRegressor, we prefer to use threads as a backend while the BaggingRegressor will use loky by default. Indeed, it seems that this is not the best setting in the current benchmark even if we release the GIL in the decision trees. Here, are some additional benchmarks script to spot the effect of the backend.

",2021/8/3 7:25 AM,1,,(IV) Reporting a Clarification Request
https://github.com/scikit-learn/scikit-learn/discussions/20651,2021/8/1 7:02 PM,"On GNU/Linux, one can have a look at the way threads are scheduled and identify if the GIL gets locked using perf(1) jointly with viztracer as described in this blog post (thank you @maartenbreddels!).
Using this setup on this script:

by running:

One  get several reports, which can be visualized with Perfetto.
Summary of threads interaction with the GIL
In what follows:

the first PID annotated with * correspond to the process main thread
the last 3 PIDs correspond to threads spawned by multiprocessing.pool.ThreadPool to respectively handle workers, tasks and results.
the others correspond to ones of the pool for the tasks (hence executing user code in parallel)

I have not been able to get results for n_jobs=8
For n_jobs=2:

For n_jobs=4:

Zooming on the kernel's scheduler profiling (exported in schedtracer.json), we see that threads are waiting for the GIL:
Overview:

Zoom:

Probably, some Python code prior to the Cython implementation takes the GIL in _parallel_build_trees, in BaseDecisionTree.fit or even after in Cython in _build_pruned_tree_ccp and subsequent functions which do not explicitly release the GIL and likely are interacting with Python objects.",2021/8/3 10:44 AM,2,,(IV) Reporting a Clarification Request
https://github.com/scikit-learn/scikit-learn/discussions/20651,2021/8/1 7:02 PM,I'm going to convert back this discussion to an issue such that we investigate the core reason for the GIL to no be released.,2021/8/3 1:12 PM,3,1,(IV) Reporting a Clarification Request
https://github.com/scikit-learn/scikit-learn/discussions/21631,2021/11/11 1:13 AM,Could you please paste the output of your script and what it should look like?,2021/11/12 10:33 AM,1,,(IV) Reporting a Clarification Request
https://github.com/scikit-learn/scikit-learn/discussions/21631,2021/11/11 1:13 AM,"I think I found one of the problems of the interpretation and it lies on the inconsistency between decision_function() and predict().
I have updated the gist (https://gist.github.com/math-a3k/572fa2e9228fbbe2b3fa8471250e0327) where it is shown that the output of predict() (right graph for the plane) is not consistent with the output of decision_function() (left graph for the plane):


(x1, x3), (x3, x4), (x2, x3), (x3, x5) are consistent
(x1, x2), (x1, x4), (x1, x5) (x2, x4), (x4, x5) are not consistent

This seems to be a bug and renders the conditional decision function useless or not possible of interpretation due to unknown result.
@adrinjalali, do you agree to escalate this as an issue?",2021/12/10 8:07 AM,2,1,(IV) Reporting a Clarification Request
https://github.com/scikit-learn/scikit-learn/discussions/21670,2021/11/15 7:26 AM,"Hi @sajanraj,
Can you craft a minimal bug report for this problem?
This will help us better solve it.",2021/11/15 7:36 AM,1,1,(IV) Reporting a Clarification Request
https://github.com/scikit-learn/scikit-learn/discussions/22042,2021/12/21 10:24 AM,"
However, from my understanding each time the forests are trained from scratch in this scenario, since the original rf object is cloned

This is correct and this is what makes it impossible to make actually use warm_start in the grid-search.
You can open an issue. Basically, I am not aware of a simple trick to solve this problem. I think that we could only solve if cloning would behave differently when warm_start=True to not clean the fitted attribute.",2021/12/21 12:14 PM,1,1,(IV) Reporting a Clarification Request
https://github.com/scikit-learn/scikit-learn/discussions/23212,2022/4/25 4:13 PM,"scikit-learn-intelex is another project managed by Intel.
You should report issues on their issue tracker instead.",2022/4/26 9:19 AM,1,1,(II) External Repository
https://github.com/scikit-learn/scikit-learn/discussions/23212,2022/4/25 4:13 PM,"As mentioned by @jjerphan, we are not maintaining nor developing scikit-learn-intelx.
@nilslacroix I would be interested to know if you installed the package on purpose? As far that I know, conda is kind of raising a warning advertising scikit-learn-intelx but I never saw an automatic install thought.",2022/4/26 1:31 PM,2,,(II) External Repository
https://github.com/scikit-learn/scikit-learn/discussions/23212,2022/4/25 4:13 PM,"As already mentioned, we are not maintaining that package on the main conda package, nor are we the ones giving advice to people to install that package. This is not a scikit-learn core issue, and you should take it to the people maintaining those packages.
We have always worried about people being confused with that package, but since we have no control over it, we can't remove that suggestion.
You should ALWAYS install the package from pypi or conda-forge if you want us to support what you have installed. The main channel is not us.",2022/10/24 10:03 AM,3,,(II) External Repository
https://github.com/sktime/sktime/discussions/1009,2021/6/21 4:18 PM,There is a PR #625,2021/6/21 5:38 PM,1,,(III) Reporting an Enhancement
https://github.com/sktime/sktime/discussions/1009,2021/6/21 4:18 PM,not for K谩lm谩n filter though? That would be a nice first issue #1011,2021/6/21 8:11 PM,2,1,(III) Reporting an Enhancement
https://github.com/sktime/sktime/discussions/1508,2021/10/12 3:49 AM,"Yes, it seems like this is backwards? My naive user expectation would be MAPE default being symmetric=False.
@RNKuhns, FYI, have a look at this",2021/10/12 8:12 PM,1,,(III) Reporting an Enhancement
https://github.com/sktime/sktime/discussions/1508,2021/10/12 3:49 AM,"@RNKuhns has offboarded and not replied to this.
I have moved this to issues as a bug report, so we can check it and deal with it there:
#1986",2022/2/4 7:40 PM,2,1,(III) Reporting an Enhancement
https://github.com/sktime/sktime/discussions/1659,2021/11/27 10:55 PM,"Yes, this should be the right way to do this.
Looks like a bug in MeanAbsoluteScaledError.
Opened a bug report here: #2001",2022/2/6 8:16 PM,1,1,(IV) Reporting a Clarification Request
https://github.com/sktime/sktime/discussions/1815,2021/12/31 3:47 PM,"Thanks for raising this, @Sinnaeve!
This seems like a bug - would you be able to open an issue and also paste the simplest possible code that reproduces this, plus what you expect to happen instead?
Regarding series-to-primitive transformers applied to multivariate series, there is discussion in this issue here:
#1719
It麓s not clear how the correct output should be formatted (but it should not be what you get).
Would appreciate your opinion on the options.",2021/12/31 6:46 PM,1,1,(IV) Reporting a Clarification Request
https://github.com/sktime/sktime/discussions/1815,2021/12/31 3:47 PM,"This is now resolved in the newest release, the return has your expected format, and future multivariate transformers will comply with that too:
#1826",2022/2/4 7:34 PM,2,,(IV) Reporting a Clarification Request
https://github.com/sktime/sktime/discussions/2267,2022/3/21 6:04 PM,"@GrzegorzRut, this is an interesting question.
I looked into the imputer, and indeed the mean and median seen in transform is used.
This is ok in a time series classification setting, since entire series are either completely in the training set, or the test set.
As you say, however, correctly, this is not ok if you do forecasting - the algorithm is not supposed to use any information about the future, this can lead to information leakage and over-optimistic evaluation.
FYI @aiwalter.
I've added leakage free versions of mean/median in #2269, and opened an issue for more complex methods in #2270 (e.g., forecaster_fit, together with the naive forecaster this supports a number of common methods).",2022/3/21 9:51 PM,1,1,(III) Reporting an Enhancement
https://github.com/sktime/sktime/discussions/854,2021/5/2 3:28 PM,"Hm, I need to have a look at this when I have more time. Also pinging @big-o who I believe originally implemented it.
Regarding the ""isolation of components"" idea, I very much like this - though it should be noted that there should also be a shorthand for the composite, and it may well be that it is more efficient to implement the composite as a whole, similar to time series forest etc.",2021/5/2 10:26 PM,1,,(III) Reporting an Enhancement
https://github.com/sktime/sktime/discussions/854,2021/5/2 3:28 PM,"@mloning I have not started implementing this. Sure, if new contributor wants to do it, then please go ahead. I would be happy to review/help/collaborate with them if they wish.",2021/6/1 5:28 PM,2,,(III) Reporting an Enhancement
https://github.com/sktime/sktime/discussions/854,2021/5/2 3:28 PM,We created an issue here #922,2021/6/3 6:18 PM,3,1,(III) Reporting an Enhancement
https://github.com/sqlalchemy/sqlalchemy/discussions/5837,2021/1/7 1:12 AM,"@Chise1
you can define dependency that provides the session and use it within the handlers.

EDIT: added imports, but dude you can create it any way you want, just pointed that Dependency() is the way to go.",2021/1/7 7:15 AM,1,,(II) External Repository
https://github.com/sqlalchemy/sqlalchemy/discussions/5837,2021/1/7 1:12 AM,Thank you!,2021/1/7 7:16 AM,2,,(II) External Repository
https://github.com/sqlalchemy/sqlalchemy/discussions/5837,2021/1/7 1:12 AM,"Where is SessionLocal ?
I can't found it in document or package.",2021/1/7 7:20 AM,3,,(II) External Repository
https://github.com/sqlalchemy/sqlalchemy/discussions/5837,2021/1/7 1:12 AM,Please give me a complete example.,2021/1/7 7:22 AM,4,,(II) External Repository
https://github.com/sqlalchemy/sqlalchemy/discussions/5837,2021/1/7 1:12 AM,"@Chise1 This is really a question and request for the FastAPI project, not SQLAlchemy. I recommend you ask the question in one of their groups, and update this Issue with the solution for the benefit of others.",2021/1/7 4:35 PM,5,1,(II) External Repository
https://github.com/sqlalchemy/sqlalchemy/discussions/6507,2021/5/18 11:19 PM,issue is at #6511 and we welcome PRs to get this started.,2021/5/19 2:42 PM,1,1,(III) Reporting an Enhancement
https://github.com/sqlalchemy/sqlalchemy/discussions/6976,2021/9/2 4:34 PM,"hi -
it looks like you are creating a union somewhere even though this is not shown in your line above.  Nothing has changed as far as the public facing version of this API.  for further assistance, please supply adequate detail what you are doing, thanks.",2021/9/2 5:26 PM,1,,(I) Reporting a Bug
https://github.com/sqlalchemy/sqlalchemy/discussions/6976,2021/9/2 4:34 PM,"sorry, this is not expected, will open a bug.",2021/9/2 5:34 PM,2,1,(I) Reporting a Bug
https://github.com/sqlalchemy/sqlalchemy/discussions/7333,2021/11/16 4:49 PM,"hey there -

The creation of the columnstore index fails.

this is vague. can you be more specific ?

Is this expected to be supported?

The page you linked does not refer to any SQL syntax for this ""columnstore"" feature so I dont know what it looks like, however  SQLAlchemy does not currently have any syntax that can ""create"" a ""columnstore"" index if there is special SQL syntax required.
However, your example as written doesn't illustrate any kind of ""columnstore"" index being created, it is reflecting a Table object from some particular database, and the most that would happen as far as indexes there is that you'd get back some Index() objects that look like normal indexes, there would be no state within that Python object that suggests ""columnstore"", so other than ""my new table doent have a columnstore index on it"", which would be expected, I am not aware of what other kind of ""failure"" would be happening (such as a stack trace).",2021/11/16 6:24 PM,1,,(III) Reporting an Enhancement
https://github.com/sqlalchemy/sqlalchemy/discussions/7333,2021/11/16 4:49 PM,I think an issue would be better for this,2021/11/17 6:31 PM,2,1,(III) Reporting an Enhancement
https://github.com/sqlalchemy/sqlalchemy/discussions/7879,2022/3/31 7:02 PM,"not expexcted at all, can you please post a bug report with a proper MCVE including sample model, sample statement, sample data?  thanks.",2022/3/31 7:06 PM,1,1,(I) Reporting a Bug
https://github.com/streamlink/streamlink/discussions/4105,2021/10/19 5:50 PM,"#3210
Twitch has, as expected, made new changes after their source code has been leaked a few weeks ago.
New access token request headers were added in #4086, but this, as expected as well, stopped working too, at least for non-preroll ads.
The --twitch-disable-ads parameter still seems to be able to filter out ads, but there's one HLS segment with the purple screen which doesn't get caught by it, so the purple screen appears before the stream output stops for filtering out the ads. It's possible that some timestamps are set differently now or that they are using different values for annotating the ad segments. Without seeing the actual HLS playlist contents, this can't be fixed.",2021/10/19 7:34 PM,1,,(I) Reporting a Bug
https://github.com/streamlink/streamlink/discussions/4105,2021/10/19 5:50 PM,"I'm turning this discussion post into an issue thread now, so that this plugin issue can be properly tracked and fixed, and so that people can actually see it in the issue tracker, because there will be lots of duplicates otherwise. Please don't open discussions for actual issues next time, thanks.
edit:
Discussions can't be turned into issues like the other way around, so I'm opening a new issue instead. I will lock this discussion here now.
New plugin issue here:
#4106",2021/10/19 7:35 PM,2,1,(I) Reporting a Bug
https://github.com/streamlink/streamlink/discussions/4298,2022/1/16 12:58 PM,"Seems to be a problem analyzing #EXT-X-BYTERANGE lines which don't have byte offset.
You may need to make this an issue report.
For example, hls_audio_160k_v4.m3u8 has these #EXT-X-BYTERANGE lines.

And streamlink is setting these Range headers for HTTP GET requests.
",2022/1/18 6:14 AM,1,1,(IV) Reporting a Clarification Request
https://github.com/tiangolo/fastapi/discussions/2751,2021/2/3 10:15 PM,"Maybe it would be better to write it in an issue that would guide you to follow the template, provide a complete, self-contained example code, etc. That way me or others can help you better.",2022/11/10 5:29 PM,1,1,(IV) Reporting a Clarification Request
https://github.com/tiangolo/fastapi/discussions/2757,2021/2/5 12:02 PM,"Hmm, not sure I understand what you mean. Maybe it would be better to ask in an issue following the template, that will guide you to structure the question and build a minimal, self-contained example with what you need or what you have in mind. That will help me/us help you better.

Sorry for the long delay! __  I wanted to personally address each issue/PR and they piled up through time, but now I'm checking each one in order.
",2022/11/10 6:28 PM,1,1,(IV) Reporting a Clarification Request
https://github.com/tiangolo/fastapi/discussions/2993,2021/3/26 6:17 AM,"I have two suggestions (depending on if you want your model in the body or query)
Body
Essentially we're creating a dummy class that skips all validation and saves it for your dependency injection to handle

Query

You're still having to handle your validation logic yourself as a try-except (mainly because it is application-specific), but you'll get your documentation with it this way
If this helped then could you mark it as answered? If not then happy to discuss further __",2021/9/29 5:26 AM,1,,(IV) Reporting a Clarification Request
https://github.com/tiangolo/fastapi/discussions/2993,2021/3/26 6:17 AM,"I think it would probably be better to ask in a GitHub issue, following the template that will guide you to structure the question in a way that makes it easier to understand your intention and need, to be able to help you better. And also providing a self-contained, minimal, reproducible, example that I can copy-paste to replicate it.

Sorry for the long delay! __  I wanted to personally address each issue/PR and they piled up through time, but now I'm checking each one in order.
",2022/11/27 7:48 PM,2,,(IV) Reporting a Clarification Request
https://github.com/tiangolo/fastapi/discussions/2993,2021/3/26 6:17 AM,"You can create a custom exception handler for the ValidationError and modify the behavior of the validation error to return the list of good and bad objects and their errors.
Here's an example of how you can implement it:

In this example, the custom exception handler will be called whenever a ValidationError is raised. It will loop over the list of objects, validate each object using Pydantic, and separate the good objects from the bad ones. The good objects will be uploaded to the database, and the response will include the list of good and bad objects and their errors, if any.
This approach allows you to validate the objects, separate the good and bad ones, and upload the good ones to the database all in one go, while still providing a clean and well-documented API using Pydantic's request models.",2023/2/6 11:32 PM,3,,(IV) Reporting a Clarification Request
https://github.com/tiangolo/fastapi/discussions/3970,2021/10/1 7:13 AM,"@elrik75 I don't think there's much that can happen in this forum (discussions). If you would like to suggest something maybe you could create an issue and add some helpful suggestions to other projects' governance. Possibly following a similar (but less strict) path to the psf as that has obviously turned out well with the BFD (Guido) and core contributors.
I imagine @tiangolo has already put a lot of thought into this already as running these big projects takes a lot of time and investment. Something that often goes unrewarded and prevents you from doing more cool things because you need to worry about maintenance.",2021/10/3 9:59 AM,1,1,(III) Reporting an Enhancement
https://github.com/tiangolo/fastapi/discussions/3970,2021/10/1 7:13 AM,"I was already worried about the situation in June and tiangolo's response increased my concern about the sustainability of the project.
https://twitter.com/sraimbault/status/1403327590039969796
In the meantime (around 5 months), the number of PR and issues has doubled.
BTW: I didn't use SQLModel in my projects because I'm concerned about the maintenance state.",2021/10/6 1:36 PM,2,,(III) Reporting an Enhancement
https://github.com/tiangolo/fastapi/discussions/3970,2021/10/1 7:13 AM,"GitHub recently announced Merge Queues. This seems perfect for FastAPI where traditionally @tiangolo has been the only maintainer.
From my understanding you ""merge"" pull requests into a queue, which you can then merge all together. Indicated by the following screenshot it seems like you can allow someone access to add a pull request into a queu without allowing them access to merge directly into the main branch..

This means that (potentially) Tiangolo could grant the most active members that he trusts permission to use this feature, and then coordinate these merges into the main branch every now and then.",2021/11/1 11:51 AM,3,,(III) Reporting an Enhancement
https://github.com/tiangolo/fastapi/discussions/3970,2021/10/1 7:13 AM,Some discussion of this here: https://news.ycombinator.com/item?id=29471609,2021/12/7 7:13 PM,4,,(III) Reporting an Enhancement
https://github.com/tiangolo/fastapi/discussions/3970,2021/10/1 7:13 AM,"I agree completely with the premise. @tiangolo clearly is very capable and competent at creating tools that are useful and well built, but that is not enough.
FastAPI and friends needs an (ideally democratically governed) organization around it to move it forward. Something like Pallets for Flask.",2021/12/7 7:44 PM,5,,(III) Reporting an Enhancement
https://github.com/tiangolo/fastapi/discussions/3970,2021/10/1 7:13 AM,"Is there a vision somewhere for this project? I did find some info in the docs that points to a sponsorship: https://github.com/sponsors/tiangolo
It has a couple of different prices/tiers: but seems to focus on helping customers (which is fine I guess, but this doesn't help in maintaining the issues and open PR's.) For me, most of the sponsorship info, was new and I will discuss it with some of my customers.
I think that a lot of Flask people switched to FastAPI because it's excellent for building Rest API's. Maintaining the code will be more and more important in this stage of the project. So some info about the roadmap and organisation behind FastAPI would be handy.
Probably good to start an organisation + open discussion for this.",2021/12/7 8:27 PM,6,,(III) Reporting an Enhancement
https://github.com/tiangolo/fastapi/discussions/3970,2021/10/1 7:13 AM,"There is a new issue that discusses the future of FastAPI: #4263
This ticket can be closed?",2021/12/8 1:31 PM,7,,(III) Reporting an Enhancement
https://github.com/tiangolo/fastapi/discussions/3970,2021/10/1 7:13 AM,"Hey! Thanks a lot for your interest.
Numbers
Let's start with the numbers. I think you might be evaluating the number of issues and PRs with a different/biased point of view, here's how.
Most of the issues are actually questions, and not bugs. And I use issues for questions because those allow imposing a bit of structure that can help users, me, and any of you here that also help. Additional to that, I don't close issues once I or someone answers them, I feel that would be a bit rude (although maybe practical). I wait for the original poster to close them or I mark them to be closed later by a bot. Many of those questions are already answered and I haven't had the time to mark/close them. But that's what counts for the biggest chunk of the ""issues open"". Also, some of the issues are just a place to handle some admin, for example, there's an issue for each one of the languages being translated, and I wrote a bot that comments there to let participants to know there's a new translation to review. Those are not many, but still, another chunk of ""issues"" that are not really issues and are not expected to be ""closed"".
Now, about PRs, a big chunk of the PRs open are just translations. I can't merge them until I get 2 approving reviews from native speakers. So they just stay there for a while. And I can't force people to come and help reviewing translations for their language.
Then, there are many PRs that I would have an easier time re-implementing them myself than updating the code from the PR, maybe they add extra things not relevant to the current PR, or maybe they implement it in a way inconsistent with the rest of the code, etc. But I try to put an effort into updating the original PR instead of just discarding and re-writing. That also makes the process a bit slower.
Issues and PRs to handle
It's true I do have a bunch of issues and PRs to review across the projects (not just in FastAPI).
But as I personally review and in most cases fine-tune and update each one of the PRs (if you check the history, almost no PR is directly merged, most of them require updates) it's taking me a bit to handle them all, but I'm on it.
For the same reason, I can't just give permissions to others to simply merge PRs. An important part of what has worked with FastAPI is that I have personally and very carefully handled it all, the best way I can. I can't renounce to that now, at least not yet, and risk the codebase quality. I would probably give permissions to others (and I have done it in the past), after several non-trivial PRs that don't need any change from me. But that doesn't happen frequently. And still, even after some trusted approvals, I would try to review each PR myself before merging.
Short Term Future
I even changed my working structure to optimize for more open source. I didn't get the chance to work as much as I hoped for last year. I'm finishing a very large migration to FastAPI. This will also result in documentation around that process and how to handle compatibility with other frameworks and async/sync code. But I'm already arranging to compensate it this year soon that I finish that migration, and I'll spend a lot of my working time this next quarter or two on FastAPI and friends.
During this time, I'll also get the chance to see many contributions from others, and who knows, maybe I'll feel more confident about giving extra permissions to some others.
Conversations like this one
Sadly, new issues and new discussions like this one asking why the other issues are not solved, don't really help, as they just add another issue for me to read and take care of.
It also doesn't help to comment or send me private messages or emails telling me to handle one specific issue. That becomes another message I have to handle on top of the thousands I receive from GitHub notifications for issues and PRs.
In the same way, asking me to find new maintainers doesn't really help me, because it just becomes another task you are asking me to carry out. It's also not something that I can myself go out and find. I wouldn't go and ask people to come and help for free, while at the same time I have never seen their work, in particular here, or I have seen only very little. It's also not a matter of people simply volunteering to be maintainers if they have never contributed a non-trivial PR (or very few). None of those options are really enough for me to give them permissions.
But again, as I get the chance to review PRs, maybe I'll find some active contributors with impeccable code and reviews that I would feel confident about giving them more access.
Recent Work
I'm prioritizing the work that can have the most impact.
Recently I was helping a bit with AnyIO and Trio, as AnyIO is used underneath by FastAPI (and it requires double compatibility with asyncio and Trio) and all that could end up used by you and your projects, even if you didn't know about it. That's not even visible in my projects, but you would still benefit from that work. For example, helping fix support for contextvars when executing synchronous tasks in a thread worker from an async context. You might end up needing all that in your projects, even without knowing, because it could be used by third party libraries you use. And these improvements make sure everything will simply work correctly underneath without you having to worry too much about it.
I was also working on a couple of small things for Pydantic, that would be used by SQLModel and FastAPI.
Before that, I released SQLModel, as I had the code, the ideas, and everything mostly ready, and people seemed to be needing something like it and no one was able to make it, so I spent the time to finish a first version that people could start exploring, before jumping to the next most impactful thing to do.
The same way, I just released Asyncer a couple of days ago, to help the projects that need to work with concurrent code and that need to mix async and sync code, which I would think is a very strong use case for FastAPI.
Roadmap
I have several things that I want to work on, but my roadmap is flexible, as while working on one thing I could end up finding that there's something with high impact that I could do, and if it's worth it, I might just do that instead of a previously fixed plan that was made based on suppositions.
I currently don't have investors or similar, so I don't have to force myself to meet some product or marketing deadlines, or to figure out how to monetize something, etc. I can focus on whatever seems like what would have the most impact. Even if that means working on a third party open source library that isn't even mine, but still feels like the right thing to do. I can do that now. That's also why the roadmap is not very fixed.
As an example, I want it to be easier for people to work with async code. To run concurrent tasks, to be able to mix sync code with async code but reducing all the confusion around threads, thread workers, event loops, contextvars, thread locals, etc. That includes a lot of documentation I want to write. And it also ended up including building Asyncer, to be able to have a good developer experience with autocompletion, inline type errors, etc.
All that work on Asyncer started as PRs to Trio and AnyIO, and then in Asyncer itself, which is this tiny library to let me (and you if you want) use that API design, while those PRs are evaluated in Trio and AnyIO themselves. But the realization that it would make sense to make it its own tiny library, even if temporary, was last month, and then I finished it (almost all of it) during the break.
All that to say that I feel it's an example of the benefits of my flexible roadmap and focusing on the resulting impact.
Come and Help me Maintain
The word ""maintain"" and ""maintainer"" probably means different things to each one of you, and each one of you probably measures it in different ways.
If you want to see faster progress, there are several ways to help, they are all documented here: https://fastapi.tiangolo.com/help-fastapi/
One of the things that consume time the most for a maintainer is handling issues created by others.
Many issues are incomplete questions. If you can go and check them, and if you can write a simple, minimal, self-contained example that shows the actual issue (or shows how to solve the user's question), that's normally the biggest chunk of time and you would be saving me from doing it myself. Then, you would be maintaining FastAPI. If it's actually a bug, I can probably reuse your example as a test case, and that's probably the biggest part of the work.
If you go and help them and they close those issues, that's a lot of minutes (in some cases hours) that you save me, and that I can then dedicate to review the other issues and PRs. That's work that a maintainer has to do. Wanna do it? I would be most grateful! Any of you can do it.
You can also review PRs yourself. But have in mind that adding a comment of ""I have this problem too, merge this soon"" doesn't really help if you are not really reviewing the code, trying it in your project, and confirming that it indeed solves your use case. And if you did all that, please mention it.
In some way, here's me asking you all to be maintainers for FastAPI.
FastAPI People
A lot of this work is already done by a bunch of people. Not many, but a few very dedicated and helpful volunteer people.
For example, @Kludex is one of the most helpful people here, always helping others, and always with a supportive and friendly attitude.
That's why I created FastAPI People, and the FastAPI Experts. Those are the people that have helped maintain FastAPI, helping others with their questions: https://fastapi.tiangolo.com/fastapi-people/#experts
Do you have open issues? Go check it. Are they solved? Then please close them. Help me maintain this.
On the other hand, overly critical, aggressive, and demanding comments like those from @stephane only drain me, make me sad, and take out the energy I should be spending in working on this instead of arguing. At the same time, none of those users show up in FastAPI People, which means that none of them are helping FastAPI, helping maintain it, answering questions in issues, reviewing PRs, etc.
But for the rest of you, thanks a lot for your support and understanding. __",2022/1/7 7:47 PM,8,,(III) Reporting an Enhancement
https://github.com/tiangolo/fastapi/discussions/3970,2021/10/1 7:13 AM,"I hope everyone is doing well. I just want to share some of my own thoughts after reading through this thread. I have used FastAPI for a couple of projects and definitely hope to use it more. I really do like this project and want it to succeed. I think it goes without saying that everyone in this thread feels the same way.
I specifically want to focus on one pain point I currently have with FastAPI and its development: optics. I am not the most experienced developer, but I think a key component for any new project to take off is community sentiment. More specifically, it needs to viewed favourably by the community of developers that may eventually use the project. Recently there was a thread on r/python titled ""Django or Flask and why?"" After scrolling though the comments, I was excited to see someone say FastAPI! It really does seem that those who use the project instantly become advocates for it. Now the unfortunate part, a reply to that polarizing suggestion to use FastAPI:

I wish people would stop recommending this. Or that people knew how to vet an open source project. Because this project isn__ actively maintained, and its developer has shown an.. interesting approach to dealing with the open source community.
His last statement, after months of inactivity and being unreachable (while being the sole maintainer of FastAPI), was that he does not plan or wish to enable people other than him to actively maintain it. People tried to reach out to him about the maintenance issue for a while, but this was all they got, and after that, he disappeared again.
(Same is true for all his other projects. He creates them, maintains them for a couple of weeks / months, heavily adversities them and gets them sponsors by using his platform and reach, and then pretty much abandons them)
So while FastAPI may have had some good ideas, it doesn__ seem like the project has a future.

Obviously, this commenter was ill-informed. That should definitely be obvious at this point. In fact, a reply to the comment pointed this out and even mentioned this exact GH discussion. To me, this comment is strictly a symptom of the aforementioned optics pain point. In this case, a user that would have otherwise liked to try out FastAPI after reading the Reddit thread may have been instantly put off because others have replied declaring the project dead on arrival. Presumably these responders have viewed the GH page some time before, saw the overwhelming amount of issues and open PRs, and thought ""oh well."" Even if they were more critical at assessing the project they would notice things like:

infrequent merges
non-shrinking amount of PRs and issues
a barrage of new issues that are not even tagged

I do not wish to come across as potentially having all the answers, nor someone beating the same drum as others above. I merely would like to present that the Python community does not see FastAPI in the light I believe it should. We have to be honest and realize this likely comes with a great cost. There are a myriad of potential users and contributors that are not gravitating towards Fast API. Whether that is a function of the issue count, PR count, or community influence is irrelevant. There needs to be something put in place to ensure the community knows this project is not only active, but also fantastic! I have no doubt that with some of the smartest developers around lurking here and a very intelligent, skillful creator, this problem can be remedied.
N.B. Please do not try to find the commenter on Reddit and harass them. It is not a bad take and solely indicative of a problem we can solve.",2022/2/9 12:41 AM,9,,(III) Reporting an Enhancement
https://github.com/tox-dev/tox/discussions/1810,2021/1/13 9:52 AM,"
I guess that making tox4 more relaxed about broken plugins would buy us more time to migrate them

You're correct on this. We should probably warn but otherwise, ignore for the first 3 months of public release. Please create an issue for it.",2021/1/13 9:59 AM,1,1,(III) Reporting an Enhancement
https://github.com/tox-dev/tox/discussions/1810,2021/1/13 9:52 AM,@ssbarnea so did you define these plugins within requires I assume?,2021/1/16 8:45 AM,2,,(III) Reporting an Enhancement
https://github.com/tox-dev/tox/discussions/1812,2021/1/13 9:57 AM,"You're correct, please create an issue for it. There really should be a button to transform it into an issue...",2021/1/13 10:03 AM,1,1,(III) Reporting an Enhancement
https://github.com/tox-dev/tox/discussions/1812,2021/1/13 9:57 AM,#1825,2021/1/16 8:32 AM,2,,(III) Reporting an Enhancement
https://github.com/tox-dev/tox/discussions/1812,2021/1/13 9:57 AM,"tox4.0.0a4 is out and addresses this request, please give it a try if you can https://tox.readthedocs.io/en/rewrite/changelog.html#v4-0-0a4-2021-01-16",2021/1/16 6:31 PM,3,,(III) Reporting an Enhancement
https://github.com/vyperlang/vyper/discussions/2346,2021/4/11 2:36 AM,"I made an issue for this, but honestlly you don't need to do that check. Both arrays are ""static arrays"" meaning they cannot be less than 50 in length, so the length check is kind of unnecessary.
Still, it should be a thing you can do: #2347",2021/4/11 3:22 AM,1,1,(IV) Reporting a Clarification Request
https://github.com/WeblateOrg/weblate/discussions/5331,2021/2/4 6:36 AM,"It is definitely not supported right now. The support we would need parser and serializer in the translate-toolkit first.
You can file an issue for adding support for that in https://github.com/translate/translate/issues, please include links to the specification of the format there (I hope it exists).
Honestly, I don't think anybody will volunteer to implement this. If you need this feature, and you are unable to contribute the code, you should consider funding the development, see https://weblate.org/en/support/",2021/2/4 7:55 AM,1,1,(II) External Repository
https://github.com/WeblateOrg/weblate/discussions/6360,2021/7/30 1:27 PM,"
How can I insert a zero width space in weblate's editor other than copy&pasting it from somewhere else?

You can add it to the visual keyboard.",2021/8/2 2:49 PM,1,,(III) Reporting an Enhancement
https://github.com/WeblateOrg/weblate/discussions/6360,2021/7/30 1:27 PM,"
Would it be possible for weblate to highlight zero width spaces in the editor, like it does for linebreaks?

It should be possible, feel free to open issue for that.",2021/8/2 2:50 PM,2,1,(III) Reporting an Enhancement
https://github.com/WeblateOrg/weblate/discussions/6360,2021/7/30 1:27 PM,"
Would it be possible for weblate to preserve this character as xml entity?

The serialization is implemented using translate-toolkit and it's behavior varies depending on the file format.",2021/8/2 2:50 PM,3,,(III) Reporting an Enhancement
https://github.com/WeblateOrg/weblate/discussions/6376,2021/8/3 1:50 PM,"This is limitation of current implementation of some formats in Weblate (plain text, HTML, ODF and IDML).",2021/8/5 9:05 PM,1,,(I) Reporting a Bug
https://github.com/WeblateOrg/weblate/discussions/6376,2021/8/3 1:50 PM,@nijel is there any chance that this bug will be fixed in the near future? __,2021/9/9 9:07 AM,2,1,(I) Reporting a Bug
https://github.com/WeblateOrg/weblate/discussions/6673,2021/10/15 7:00 AM,"Bug, filed as #6674",2021/10/15 7:07 AM,1,1,(I) Reporting a Bug
https://github.com/WeblateOrg/weblate/discussions/7023,2021/12/29 9:40 AM,Also asked at #7024,2022/1/7 1:42 PM,1,1,(IV) Reporting a Clarification Request
https://github.com/WeblateOrg/weblate/discussions/7041,2022/1/2 11:49 PM,"This is a bug in Weblate, please follow up at #7048",2022/1/3 12:14 PM,1,1,(I) Reporting a Bug